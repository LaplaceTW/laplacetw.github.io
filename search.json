[{"title":"Google Apps Script 與 Hololive (?)","url":"/google-apps-script-with-hololive/","content":"這是關於~~DD仔~~堅持用GAS解決問題的過程。<!--more-->\n\nTL;DR\n- HoloDDer：[連結](https://script.google.com/macros/s/AKfycbywEBw2_-AJ5I04qP1EiVUyzWzxRuZEnHTqJeF7hrj8QRQ_bmTWv6R1aZKGXdY-7ddh/exec)\n- 專案原始碼：[https://github.com/laplacetw/HoloDDer](https://github.com/laplacetw/HoloDDer)\n\n<img src=\"https://raw.githubusercontent.com/laplacetw/HoloDDer/main/image/demo.gif\" width=80%/>\n\n---\n時間過得飛快，我第一次用GAS寫點什麼是2019年中的時候，之後就沒怎麼接觸，而現在已經2022了，然後疫情依然持續。大概一個多月前~~逐漸越D越多的我~~突然覺得，YouTube直播點來點去好麻煩，開很多分頁也不是什麼理想的做法，PTT西洽還有人直接開一堆瀏覽器視窗排列在桌面...。總之，這讓我開始思考如何把想看的直播都弄在同一個畫面上這件事，而且要自動載入，不要工人智慧自己輸入網址(´_ゝ`) 所以我就做了關鍵字搜尋，看看有沒有什麼YT多開工具，就是出現了好幾個可以讓你自己輸入多個網址的頁面，嗯，蒸蚌，顯然這不是我要的。\n\n然後就想說自己寫吧，在查了一些資料後，跟GAS很不熟的我發現它竟然可以輸出HTML，儘管內建的各項API服務都有每日使用額度限制(workspace帳號的quota多於一般帳號)，但對我的目標需求而言很夠用，所以就決定試試了。不過，似乎是因為「想透過頻道確認是否直播中」這樣的~~單蠢~~單純想法，所以一開始使用了YouTube Data API來嘗試做出雛形，結果很快就悲劇了இдஇ 原來透過API進行搜索是相當昂貴的請求，這每天的扣打只有10,000個單位，做一次搜尋就要消耗100單位，~~我們DD仔隨便都監視數十個頻道~~這點扣打肯定是不夠用的啊，所以就不打算用API了。\n\n![](https://i.imgur.com/QCWkue4.png)\n\n~~程式要寫直播也是要看~~到這裡大概過了一週的時間，然後發現已經有很厲害的網站了：[HoloTools](https://hololive.jetri.co/)、[Holodex](https://holodex.net/)，介面賞心悅目，功能更是豐富。不過，人家是專業的~~我是客家的~~，還是讓我繼續往下探索Google Apps Script可以做到什麼程度吧。在這當下要解決的問題就是，我如何能根據口袋~~裡那張油油的~~名單去確認並取得目前進行中的直播網址，在做了一些嘗試、繞了一大圈後，我終於回想(?)起來有官方網站(ゝ∀･)b 這樣就好辦了，直接用UrlFetchApp.fetch()就能拿到schedule。\n\n![](https://i.imgur.com/lFeAcuP.png)\n\n於是就這樣拼拼湊湊出一個可以根據我寫死在script裡的名單去確認並全部排列顯示的頁面。但還是有很多問題，像是名單寫死要更新就得重新部署，頻道頭像的URL也是同樣情況，如果頻道有更新頭像就會失效，而手動加入的影片則使用預設頭像...於是我有一個~~大膽的~~想法：如何透過影片連結取得頻道名稱、頭像等資訊？寫過Python crawler可能直呼簡單，不過，我現在只有UrlFetchApp.fetch()可以用...JS渲染想都別想。Embedded YouTube iframe就更別說了，瀏覽器手裡掐著CORS，iframe裡面的東西只能遠觀不可褻玩。於是又瞎嘗試了一番、繞了好大一圈，還是只能從UrlFetchApp.fetch()回傳的raw data去挖挖看裡面有啥了。接著就是不斷嘗試的過程，說實話想直接在Paas寫crawler來串接(／‵Д′)／~ ╧╧ 但這樣我就認輸咧？爬不到的資料實在讓人很不甘心，終於就在我感到心累~~想跑去YouTube看VT精華~~的時候，發現在某個script tag裡面有個叫ytInitialData的變數儲存著JSON格式字串，我要的數據就在這裡面！可是，看得到吃不到，哭啊！UrlFetchApp.fetch()回傳的raw data不知何故，某些符號是呈現ASCII Hex的編碼形式，例如左大括號(curly brackets)就變成「\\x7b」，然後又嘗試了一番試圖decode仍是無功而返，決定直接取代處理，因為~~我心累想跑去看VT精華了~~它們會導致JSON.parse()莫名解析失敗，同樣內容多次測試，解析失敗的位置都不同...歸剛欸！\n\n所以我說 r 到底有什麼問題R ? ↓\n\n![](https://i.imgur.com/kcrMdBc.png)\n\n後來決定用Regex取出我要的那一段，JSON.parse()就過了...終於啊(´_ゝ`)\n\n![](https://i.imgur.com/Xvh7S6K.png)\n\n取得頻道資訊的問題解了，後來我就乾脆做了一個可以使用Google帳號登入的公開部署版本，把個人偏好設定與頻道頭像URL透過另外兩個Apps Script同步儲存在spreadsheet和local storage，如此保證失效的頻道頭像URL能得到更新，也很節省UrlFetchApp.fetch()的使用quota，至於個人使用的版本就只有在local storage儲存偏好設定與頻道頭像URL等數據。其實後來還有考慮要把聊天室也嵌入頁面，但實際測試就跟在YouTube頁面一樣糟，大量的留言會造成頁面響應延遲，~~因為直播要開始了所以~~其他過於細節的部分太雜亂就省略吧。\n\n![](https://raw.githubusercontent.com/laplacetw/HoloDDer/main/image/setting.png)\n\n<br>跨年的時候還在想如何拿資料，整排都預設頭像囧 ↓\n\n<img src=\"https://imgur.com/vje5r37.gif\" width=80%/><br><br>\n\nRef.\n- [Overview of Google Apps Script](https://developers.google.com/apps-script/overview)\n- [Quotas for Google Services](https://developers.google.com/apps-script/guides/services/quotas)\n- [Best Practices: Separate HTML, CSS, and JavaScript](https://developers.google.com/apps-script/guides/html/best-practices#code.gs)\n- [Google-Apps Script | Blogger 調校資料庫](https://www.wfublog.com/search/label/%E9%9B%BB%E8%85%A6-%20Google-Apps%20Script?&max-results=5)\n- HTML Parser for Google Apps Script\n  - [Cheerio](https://github.com/tani/cheeriogs)\n  - [Document](https://cheerio.js.org)","tags":["google apps script","spread sheet"],"categories":["Google"]},{"title":"WebRTC getUserMedia( )在行動裝置上的異常行為","url":"/webrtc-getusermedia-constraints/","content":"發生了令人感到非常沮喪的事，所以來更新吧(?)<!--more-->\n\n>Never trust the f\\*\\*king verbal job offer, NEVER.\n\n本來打算在整個研究結束後，再來整理關於編寫PWA(Progressive Web App)過程中的各種問題，不過那可能還要好些時間...而且我開始以筆記軟體為主，畢竟寫作相對耗時。昨日整理研究紀錄(就只是類似流水帳的東西)，正好是關於在行動裝置瀏覽器上拍攝影片的問題，於是我仔細測試了一下並做記錄。\n\n在iOS Safari錄製影像時，無論裝置為直向或橫向拍攝，影片寬高都會符合constraints設定，但畫面顯示會異常，裝置直向時顯示橫向、裝置橫向時顯示直向。在[stackoverflow](https://stackoverflow.com/a/62598616)有相關討論提到：\n\n- getUserMedia()在行動裝置上會有一些奇怪的行為，無論是iOS或Android\n- 或許是因為瀏覽器的出現早於可旋轉畫面的裝置，因而瀏覽器的設計思維是橫向模式(寬 > 高)\n\n測試結果如下，video rotation是指相對於拍攝畫面而言。\n\nconstraints<br>width x height|device orientation|display<br>width x height|video rotation\n:---------------------------:|:----------------:|:-----------------------:|:-------------:\n             320 x 240       |    portrait      |         240 x 320       |  -90 degrees\n             320 x 240       |    landscape     |         320 x 240       |    0 degrees\n             240 x 320       |    portrait      |         320 x 240       |  -90 degrees\n             240 x 320       |    landscape     |         240 x 320       |    0 degrees\n\n![](https://i.imgur.com/7jJaabj.png)\n\n\n我在CodePen寫了簡單的測試實例：[WebRTC constraints test on mobile](https://codepen.io/laplacetw/pen/BaZRMrm)\n從互換的寬高設定和裝置方向變化來觀察顯示畫面：\n\nportrait|landscape\n:----------------------------------:|:-----------------------------------:\n![](https://i.imgur.com/oz556WP.gif)|![](https://i.imgur.com/2YmR8DB.gif)","tags":["pwa","webRTC"],"categories":["Web Dev"]},{"title":"N200RE_V3無線路由器韌體更新","url":"/update-firmware-mini-wireless-router/","content":"今日調整了無線路由器的擺放位置<!--more-->，進了管理後台看看就順手想更新韌體，想說買來使用到現在從沒更新過韌體。\n\n結果啊...台灣官網產品頁面已經移除了N200RE(V3/V4)，只剩下N200RE_V5，這是要人去哪下載韌體？🥲\n\n查看了英文官網產品頁面，發現依然保留著舊款的N200RE(V3/V4)，明顯和N200RE_V5是被區分為不同型號的產品，也因此得以下載到較新的韌體。\n\n載點連結：\n- [N200RE (V3/V4) Fireware Download](https://www.totolink.net/home/menu/detail/menu_listtpl/download/id/158/ids/36.html)\n- [N200RE_V5 Fireware Download](https://www.totolink.net/home/menu/detail/menu_listtpl/download/id/204/ids/36.html)\n\n\n![](https://i.imgur.com/NpcVRAV.png)\n\n\n\b即便做了很多事情，過去半年幾乎是沒動力寫點什麼，從自己的研究進度log來看，6月開始著手開發PWA、跑實驗到現在，明顯感覺到自己的近視度數增加了不少...希望能快點結束。","tags":["IoT","wireless"],"categories":["Daily"]},{"title":"更換日光燈具為LED燈具","url":"/replace-fluorescent-light-fixture-with-LED/","content":"前陣子發現日光燈管出現偶發閃爍，接著亮度開始衰減後，想説要換掉舊燈具<!--more-->，然後就這麼拖過了幾個禮拜，終於在上週末衝去寶家買了LED山形燈具和燈管回來，立刻著手更換！\n\n＊<span style=\"color:red;\">安全至上，務必先進行斷電，而非僅關閉電燈開關。</span>\n\n移除燈管後，用老虎鉗鬆開燈具中央的膠頭螺絲，\b以移除燈具上蓋。\n![](https://i.imgur.com/oQPsoic.jpg)\n\n移除上蓋後的日光燈具，可見到燈座上的電容、啟動器、安定器等。\n![](https://i.imgur.com/cu2A9XK.jpg)\n![](https://i.imgur.com/bcOMEMn.jpg)\n\n接著斷開燈座與火線、中性線之間的連結，這舊燈座有快速接頭，\b左右轉一轉，稍微用點力就能拔得下來。拔出兩條電線後就可以鬆開固定螺絲，將燈座卸下來啦。\n![](https://i.imgur.com/yMq8mwV.jpg)\n\n換上新的LED燈具，和舊式日光燈具比起來，少了安定器等雜七雜八的元件與線路，整個燈座非常輕薄。快速接頭會標示N/L，火線/中性線各接一邊即可，萬萬不可插同一邊啊，會悲劇。\n![](https://i.imgur.com/oaWjNNQ.jpg)\n\n燈座安裝完成後，鎖好上蓋、裝上LED燈管就完成啦。啵亮～而且新燈管消耗功率僅有日光燈管的一半。\n![](https://i.imgur.com/Oav4WXv.jpg)\n\n\n\n＊推薦參考影片：[宅水電-DIY更換T8 LED山形吸頂燈](https://youtu.be/z_SF2z5aQFs)","tags":["DIY"],"categories":["Daily"]},{"title":"如何確認開機隨身碟的Windows版本？","url":"/tools-check-win-bootable-usb-version/","content":"最近要幫友人的新電腦安裝作業系統，於是找了找手邊的隨身碟，但有段時間沒使用，也記不得裡頭的版本...<!--more-->\n\n然後我就去Google這個問題啦，原來只需要使用「部署映像服務與管理」(Deployment Imaging and Management, DISM)命令列工具就行了。\n\n將開機隨身碟連接電腦，然後以Admin權限啟動Windows CMD或PowerShell並執行以下命令：\n{% codeblock lang:sh %}\n$ dism /Get-WimInfo /WimFile:E:\\sources\\Boot.wim /index:1\n{% endcodeblock %}\n＊請自行代入開機隨身碟在您電腦上的磁碟機代號。\n\n如此就可以看到作業系統版本號了⬇︎\n![](https://i.imgur.com/oaEQdAn.png)\n\n\nmurmur：研究進度壓力山大，好幾個月沒時間更新部落格了...連翻譯完的論文也擱著，只能寫點小小的筆記😞\n但是我很努力在前進著！\n\nRef.\n- [Win10 ISO on USB - any way to check version?](https://pressf1.pcworld.co.nz/showthread.php?140641-Win10-ISO-on-USB-any-way-to-check-version)\n- [MS Doc - 什麼是DISM?](https://docs.microsoft.com/zh-tw/windows-hardware/manufacture/desktop/what-is-dism)\n- [Wikipedia - Windows版本歷史](https://zh.wikipedia.org/wiki/Microsoft_Windows#Windows版本歷史)","tags":["windows","boot usb"],"categories":["Tools"]},{"title":"資訊隱藏：Cat Command","url":"/stegano-hide-data-in-image-with-cat-cmd/","content":"閱讀某文章時提到有些老司機會把車票(?)隱藏在圖片(.jpg)中，覺得蠻有趣的<!--more-->，沒想過cat(concatenate)指令做這件事XD\n\n因為[JPEG的二進位檔為'0xFFD8'起始、'0xFFD9'結尾](https://www.media.mit.edu/pia/Research/deepview/exif.html#JpegMarker)，'0xFFD8'代表SOI(Start of image)，'0xFFD9'代表EOI(End of image)。即使將其他數據與其合併，圖片預覽程式在讀取二進位檔時遇到'0xFFD9'就會認為圖片已讀取完畢，因而無視後面的數據。\n![](https://i.imgur.com/yg6KnRX.png)\n\n\b然後我在MacOS和Windows 10都試了試：\n\nUnix-like\n{% codeblock lang:sh %}\n$ cat test.jpg secret.zip > hide.jpg\n{% endcodeblock %}\n\nWindows\n{% codeblock lang:sh %}\n$ type test.jpg secret.zip > hide.jpg\n{% endcodeblock %}\n\n合併後得到的檔案看起來依然是一張圖片，但其實和原圖比對，檔案大小是有增加的。\n將副檔名改為.zip後解壓縮，就能得到被合併進去的隱藏檔案。\n![](https://i.imgur.com/NqvpQYT.png)\n\n\n覺得很有趣所以紀錄一下。😄","tags":["data hiding"],"categories":["Steganography"]},{"title":"React Native 開發環境設置","url":"/react-native-env-setup/","content":"\b\b因為有跨行動平台的需求，我在幾個解決方案之間考量：<!--more-->\n- [Flutter](https://zh.wikipedia.org/wiki/Flutter)\n- [React Native](https://zh.wikipedia.org/wiki/React_Native)\n- [Xamarin](https://zh.wikipedia.org/wiki/Xamarin)\n\n基於我對Dart和C#都不甚理解，亦考量各\b框架的活躍度，因而選擇先試試React Native。\n\n### MacOS (for iOS)\nReact Native官方文件所列出的工具需求：\n\n1. Node.js 12+\n{% codeblock lang:sh %}\n$ brew install node\n{% endcodeblock %}\n＊為了[將Node.js更新到12+](ttps://laplacetw.github.io/hexo-err-invalid-arg-type)真的是折騰了些時間，有使用Hexo框架寫部落格的人可別直接安裝最新版啊。\n\n2. Watchman\n{% codeblock lang:sh %}\n$ brew install watchman\n{% endcodeblock %}\n\n3. CocoaPods\n{% codeblock lang:sh %}\n$ sudo gem install cocoapods\n{% endcodeblock %}\n\n4. Xcode 10+\n從[App Store](https://apps.apple.com/tw/app/xcode/id497799835)下載，然後在偏好設定中安裝Xcode Command Line Tools和模擬器。\n![](https://i.imgur.com/TVozuay.png)\n![](https://i.imgur.com/M0FX6FG.png)\n\n5. React Native CLI\n毋需安裝，官方文件建議使用Node.js附帶的npx來存取最新版本：\n>React Native has a built-in command line interface. Rather than install and manage a specific version of the CLI globally, we recommend you access the current version at runtime using npx, which ships with Node.js. With npx react-native <command>, the current stable version of the CLI will be downloaded and executed at the time the command is run.\n\n以上的工具都準備好了之後，就可以來建立我們的第一個React Native專案了：\n{% codeblock lang:sh %}\n$ npx react-native init MyFirstApp\n{% endcodeblock %}\n![](https://i.imgur.com/lWhdK1l.png)\n\n專案資料夾⬇︎\n![](https://i.imgur.com/uXqvhWQ.png)\n\n\n編譯iOS App：\n{% codeblock lang:sh %}\n$ cd MyFirstApp\n$ npx react-native start\n$ npx react-native run-ios\n{% endcodeblock %}\n\n編譯過程約12分鐘。\n我並不打算在MBA上安裝Android Studio來為難它。\n\n![](https://i.imgur.com/o1TmwfY.png)\n\n### Linux (for Android)\n＊Manjaro Linux\n\nReact Native官方文件所列出的工具需求：\n\n1. Node.js 12+\n{% codeblock lang:sh %}\n$ pacman -S nodejs npm\n{% endcodeblock %}\n\n2. Java Development Kit 8+\n＊安裝的JDK為開源的Open JDK，而非Oracle JDK。\n{% codeblock lang:sh %}\n$ sudo pacman -S jre-openjdk-headless jre-openjdk jdk-openjdk openjdk-doc openjdk-src\n\n$ java -version\nopenjdk version \"15.0.2\" 2021-01-19\nOpenJDK Runtime Environment (build 15.0.2+7)\nOpenJDK 64-Bit Server VM (build 15.0.2+7, mixed mode)\n{% endcodeblock %}\n\n3. Android development environment\n\n    - Install Android Studio\n    從[官網下載](https://developer.android.com/android-studio/download)並解壓縮。\n    進到解壓縮後的資料夾中執行studio.sh來安裝Android Studio需要的元件(需要一些時間)：\n    {% codeblock lang:sh %}\n    $ ./bin/studio.sh\n    {% endcodeblock %}\n\n    ![](https://i.imgur.com/99DiggT.png)\n    ![](https://i.imgur.com/MXGG6Ma.png)\n\n    Configure -> Create Desktop Entry可以在launcher建立捷徑。\n    亦可直接將Android Studio釘選在桌面工具列 / Latte Dock。\n\n    - Install the Android SDK\n    雖然安裝Android Studio的時候就會一起安裝最新版本的Android SDK，但官方文件提到React Native需要Android 10 SDK這個版本。\n    \n    Configure -> SDK Manager\n    \n    SDK Platform分頁 -> Show Package Details -> 勾選Android 10(Q)底下的 :\n        - Android SDK Platform 29\n        - Intel x86 Atom_64 System Image\n\n    \b\n    SDK Tools分頁 -> Show Package Details -> 勾選版本29.0.2\n\n    上述項目勾選後點選Apply進行下載安裝(需要一些時間)。\n\n    - Configure the ANDROID_HOME environment variable\n    React Native Tools為了以native code編譯App，需要設定一些環境變數。\n    >Add the following lines to your $HOME/.bash_profile or $HOME/.bashrc(if you are using zsh then ~/.zprofile or ~/.zshrc) config file:\n    export ANDROID_HOME=$HOME/Android/Sdk\n    export PATH=$PATH:$ANDROID_HOME/emulator\n    export PATH=$PATH:$ANDROID_HOME/tools\n    export PATH=$PATH:$ANDROID_HOME/tools/bin\n    export PATH=$PATH:$ANDROID_HOME/platform-tools\n    \n    >.bash_profile is specific to bash. If you're using another shell, you will need to edit the appropriate shell-specific config file.\n\n    設定完成後確認環境變數設置：\n    {% codeblock lang:sh %}\n    $ echo $ANDROID_HOME\n    $ echo $PATH\n    {% endcodeblock %}\n\n4. Watchman\n從Github[下載最新版本](https://github.com/facebook/watchman/releases/latest)並解壓縮。\n進到解壓縮後的資料夾中：\n{% codeblock lang:sh %}\n$ sudo mkdir -p /usr/local/{bin,lib} /usr/local/var/run/watchman\n$ sudo cp bin/* /usr/local/bin\n$ sudo cp lib/* /usr/local/lib\n$ sudo chmod 755 /usr/local/bin/watchman\n$ sudo chmod 2777 /usr/local/var/run/watchman\n{% endcodeblock %}\n\n5. React Native CLI\n毋需安裝，官方文件建議使用Node.js附帶的npx來存取最新版本：\n>React Native has a built-in command line interface. Rather than install and manage a specific version of the CLI globally, we recommend you access the current version at runtime using npx, which ships with Node.js. With npx react-native <command>, the current stable version of the CLI will be downloaded and executed at the time the command is run.\n\n以上的工具都準備好了之後，就可以來建立我們的第一個React Native專案了：\n{% codeblock lang:sh %}\n$ npx react-native init MyFirstApp\n{% endcodeblock %}\n\n專案資料夾⬇︎\n![](https://i.imgur.com/EEBL9Cj.png)\n\n編譯Android App：\n＊必須先建立並啟動Android Studio模擬器\n>If you have recently installed Android Studio, you will likely need to create a new AVD. Select \"Create Virtual Device...\", then pick any Phone from the list and click \"Next\", then select the Q API Level 29 image.\n\n![](https://i.imgur.com/K7o4Ay3.png)\n\n{% codeblock lang:sh %}\n$ cd MyFirstApp\n$ npx react-native start\n$ npx react-native run-android\n{% endcodeblock %}\n\n編譯過程僅數十秒。\n\n![](https://i.imgur.com/c4zxh1X.png)\n\n\n### Ref.\n- [React Native - Setting up the development environment](https://reactnative.dev/docs/environment-setup)\n- [Node.js - Installing Node.js via package manager](https://nodejs.org/en/download/package-manager)\n- [How to install Java on Manjaro Linux](https://linuxconfig.org/how-to-install-java-on-manjaro-linux)\n- [Watchman - Installation](https://facebook.github.io/watchman/docs/install.html)\n- [npx是什麼? 跟npm差在哪?](https://medium.com/itsems-frontend/whats-npx-e83400efe7f8)\n- [npx相關指令教學](https://www.ruanyifeng.com/blog/2019/02/npx.html)","tags":["react","react native","mobile app"],"categories":["React"]},{"title":"Node.js版本更新、Hexo部署更新失敗","url":"/hexo-err-invalid-arg-type/","content":"平時會用到Node的時候就只有用Hexo寫部落格，自己對它是非常陌生的，但最近要寫React Native，然後就發現不得了的事情<!--more-->：Node.js版本過舊無法使用React Native -> MacOS版本過舊無法更新Node.js...窩的老天鵝呀。\n\n於是我就先把MBA從Catalina直接上Big Sur，然後開始折騰如何更新Node.js。我不大記得當初如何在Mac上安裝Node.js的，但應該不是透過Homebrew，因為我無法透過它直接upgrade or uninstall，而用Homebrew直接安裝了新版後，在terminal用指令查Node.js版本依然是舊版。爬文測試後發現要手動移除再用Homebrew重新安裝：\n{% codeblock lang:sh %}\n$ rm /usr/local/bin/node\n$ rm /usr/local/bin/npm\n$ rm /usr/local/bin/npx\n$ rm /usr/local/lib/node_modules\n\n$ brew install node\n{% endcodeblock %}\n\n＊因為會移除node_modules資料夾，所以我先把hexo-cli資料夾移出，更新完Node.js再丟回去。\n\n好啦，OS更新了，Node.js也更新了，然後呢？然後我發現Hexo部署更新失敗...窩的老天鵝呀。😭\n{% codeblock lang:sh %}\nFATAL Something's wrong. Maybe you can find the solution here: https://hexo.io/docs/troubleshooting.html\nTypeError [ERR_INVALID_ARG_TYPE]: The \"mode\" argument must be integer. Received an instance of Object\n{% endcodeblock %}\n\n去Hexo的官網看看[troubleshooting](https://hexo.io/docs/troubleshooting.html)在留言發現有相關討論，這竟然是因為Node.js版本太新...看來我只能降版：\n{% codeblock lang:sh %}\n$ brew search node\n==> Formulae\nheroku/brew/heroku-node    node-sass                  nodebrew\nlibbitcoin-node            node@10                    nodeenv\nllnode                     node@12                    nodenv\nnode                       node@14\nnode-build                 node_exporter\n\n$ brew install node@12\n{% endcodeblock %}\n\n降版安裝了node@12後，Homebrew提示此版本是「keg-only」，仔細看它的安裝路徑是在/usr/local/opt裡，Homebrew也不會為其建立system link。所以我得手動將node@12路徑加入環境變數，而hexo-cli移動到其根目錄下的/lib/node_modules後也必須手動加入環境變數：\n{% codeblock lang:sh %}\n$ echo 'export PATH=\"/usr/local/opt/node@12/bin:$PATH\"' >> ~/.zshrc\n$ echo 'export PATH=\"/usr/local/opt/node@12/lib/node_modules/hexo-cli/bin:$PATH\"' >> ~/.zshrc\n{% endcodeblock %}\n\n搞定。\n\n\nRef.\n- [修復 npm 的漫漫長路](https://khiav223577.github.io/blog/2017/09/24/修復-npm-的漫漫長路/)\n- [有趣的 Homebrew 命名邏輯](https://wildjcrt.pixnet.net/blog/post/29182044-the-naming-logic-from-homebrew)","tags":["hexo","github pages","nodejs"],"categories":["Hexo"]},{"title":"資訊隱藏：竄改偵測與復原","url":"/stegano-tamper-recovery/","content":"在這學期的資訊隱藏課程內容中，我認為這是最有趣的<!--more-->，利用事先藏入彩色影像中的隱密資訊，竟然可以偵測出遭到竄改的區域，甚至進行一定程度的復原，這好像有點神奇...&nbsp;&nbsp;😲\n\n#### 資訊嵌入\n藏入的隱密資訊其長度為36-bit，由16-bit authentication data加上20-bit recovery data所組成。生成這36-bit資訊的過程有些繁瑣：\n\n1. 生成global feature：將影像摘要資訊以MD5生成128-bit hash value，依序分割為8段、每段16-bit進行XOR運算。\n2. 將影像分割為2x2的不重疊區塊，然後做區塊映射：其結果將用來隱藏recovery data，也就是將目標區塊的復原資訊藏在映射區塊。\n3. 生成local feature：將2x2區塊每個像素之RGB各取5-bit最大有效位元(MSB)，再加上1-bit偶校驗(Even Parity)組成該像素的feature data，然後將4\b組feature data和區塊的row index、column index進行XOR運算。\n4. 生成authentication data：將global feature與2x2區塊的local feature進行XOR運算。\n5. 生成recovery data：計算2x2區塊的像素RGB平均值並轉換色彩空間至YCbCr，將Y加上Cb、Cr各取6-bit MSBs組成20-bit復原資訊。\n\n根據區塊映射之結果，將映射區塊的authentication data加上目標區塊的recovery data，組合成36-bit隱密資訊並嵌入至映射區塊。嵌入方式為自2x2映射區塊中，從每個像素點之R、G、B各取3-bit最低有效位元(LSB)來使用。\n\n＊舉例來說，假設目標區塊A的index為(3, 4)，其映射區塊為B(2, 1)，則要嵌入至區塊B的36-bit隱密資訊 = 區塊B的16-bit authentication data + 區塊A的20-bit recovery data。因此，在影像遭到竄改而導致區塊A毀損，而區塊B完好如初的情況下，就可以從區塊B取出復原資訊來修復區塊A。\n\n![](https://i.imgur.com/VTzHSXG.png)\n\n#### 竄改偵測\n要知道經過上述處理的影像是否遭到竄改，可透過找出真正的global feature以比對出可能遭到竄改的區域：\n\n1. 將影像分割為2x2的不重疊區塊，提取出嵌入於區塊中的16-bit authentication data。\n2. \b\b\b提取global feature：生成區塊的local feature並和authentication data進行XOR運算。\n3. 統計所有區塊提取出的global feature，出現頻率最多次的即為真正的global feature。\n4. 比對所有區塊的global feature，就能劃分出可能遭到竄改的區域。\n\n![](https://i.imgur.com/eY5kQvd.png)\n\n#### 影像復原\n透過上述的竄改偵測，若確認影像遭到竄改，可利用嵌入其中的recovery data來嘗試復原影像：\n\n1. 確認竄改區域，定位被竄改區塊的區塊映射位置。\n2. 比對global feature檢查映射區塊是否也遭到竄改，以確認recovery data的可用性。\n3. 若映射區塊並無遭到竄改，則提取映射區塊中的20-bit recovery data，還原YCbCr(Cb、Cr捨棄的2-bit LSBs補0)並將色彩空間轉換回RGB，以此RGB值來復原被竄改的區塊。\n4. 若映射區塊亦遭到竄改，在recovery data不可用的情況下，就只能使用其所有相鄰區塊的像素平均值來修復了。\n\n![](https://i.imgur.com/ffgTaAQ.png)\n\n＊原始碼連結：[Github](https://github.com/laplacetw/stegano/blob/main/tamper-recovery.py)\n＊測試影像來源：[unsplash](https://unsplash.com/photos/IuDN1alE1GE)、[unsplash](https://unsplash.com/photos/1oAUMHQk7fY)","tags":["python","data hiding"],"categories":["Steganography"]},{"title":"資訊隱藏：離散小波轉換","url":"/stegano-distributed-wavelet-transform/","content":"單純以LSB的方式嵌入秘密資訊的方式雖簡單又易實現，但載體影像卻難以抵抗各種攻擊。<!--more-->所以接續上篇來寫能抵抗破壞的數位浮水印，只修過一學期相關課程的菜雞我呢，雖然在寫課程作業期間也找了論文來輔助參考，但也算不上系統性的學習相關知識，想從艱困的預算中編列購買相關書籍來研讀的費用啊&nbsp;&nbsp;😶\n\n[維基百科](https://zh.wikipedia.org/wiki/數位浮水印)對數位浮水印的描述：\n>數位浮水印，是指將特定的資訊嵌入數字訊號中，數位訊號可能是音訊、圖片或是影片等。若要拷貝有數位浮水印的訊號，所嵌入的資訊也會一併被拷貝。數位浮水印可分為浮現式和隱藏式兩種，前者是可被看見的浮水印(visible watermarking)，其所包含的資訊可在觀看圖片或影片時同時被看見。一般來說，浮現式的浮水印通常包含著作權擁有者的名稱或標誌。電視台在畫面角落所放置的標誌，也是浮現式浮水印的一種。\n\n>隱藏式的浮水印是以數位資料的方式加入音訊、圖片或影片中，但在一般的狀況下無法被看見。隱藏式浮水印的重要應用之一是保護著作權，期望能藉此避免或阻止數位媒體未經授權的複製和拷貝。隱寫術(Steganography)也是數位浮水印的一種應用，雙方可利用隱藏在數位訊號中的資訊進行溝通。數位相片中的註釋資料能記錄相片拍攝的時間、使用的光圈和快門，甚至是相機的廠牌等資訊，這也是數位浮水印的應用之一。某些檔案格式可以包含這些稱為「metadata」的額外資訊。\n\n而數位浮水印的嵌入方式，除了空間域，還有頻率域，也就是將影像轉換至頻率域再進行嵌入。高頻訊號較不易為人眼所察覺，低頻訊號較能抵抗攻擊，在嵌入時可視需求作取捨。\b\n\n我以一階[哈爾小波轉換](https://zh.wikipedia.org/wiki/哈爾小波轉換)來進行測試，影像將被分割為LL、HL、LH、HH四個頻帶，其中LL即為能量最為集中的低頻帶，人類視覺對此部分的變化較靈敏。然後將浮水印分割為上下兩個部分，上半部在空間域進行嵌入，下半部則嵌入頻率域的HH頻帶，來看對攻擊的抵抗能力。\n\n\b空間域嵌入、頻率域嵌入和還原結果⬇︎\n![](https://i.imgur.com/lvk5KXs.png)\n將影像去除中央128x128的區域後的還原結果⬇︎\n![](https://i.imgur.com/Ixe4Fl5.png)\n將影像去除中央二個方框區域後的還原結果⬇︎\n![](https://i.imgur.com/gW8uUS6.png)\n\n可以明顯的看出，將影像去除128x128的區域後，嵌入於空間域的浮水印只剩渣&nbsp;&nbsp;🤣 &nbsp;&nbsp;而去除方框區域後的浮水印還原結果也能看到白色框線的粗細對比。真的蠻有趣的啊😲\n\n＊原始碼連結：[Github](https://github.com/laplacetw/stegano/blob/main/dwt.py)\n＊測試影像來源：[unsplash](https://unsplash.com/photos/r2nJPbEYuSQ)","tags":["python","data hiding"],"categories":["Steganography"]},{"title":"Github：basic auth using a password to Git is deprecated","url":"/sofdev-github-token-auth-needed/","content":"推送更新後收到Github官方的通知信，內容說到以密碼為執行Git操作的基本身份認證方式已經要棄用了<!--more-->，要使用者改用Access Token。\n\n通知信中給了一個連結：[Token authentication requirements for Git operations](https://github.blog/2020-12-15-token-authentication-requirements-for-git-operations/)\n\n>Workflows affected\n- Command line Git access\n- Desktop applications using Git (GitHub Desktop is unaffected)\n- Any apps/services that access Git repositories on GitHub.com directly using your password\n\n>The following customers remain unaffected by this change:\n\n>- If you have two-factor authentication enabled for your account, you are already required to use \n- token- or SSH-based authentication.\n- If you use GitHub Enterprise Server, we have not announced any changes to our on-premises offering.\n- If you maintain a GitHub App, GitHub Apps do not support password authentication.\n\n重點就是呢，2021/08/13以前，以密碼為執行Git操作的身份認證方式都還能正常使用，不過還是趕緊改用Access Token吧，生成後要記得設定存取權限，然後將Git密碼改成Access Token就行了。\n![](https://i.imgur.com/ZkeH708.png)\n＊[How do I update the password for Git?](https://stackoverflow.com/questions/20195304/how-do-i-update-the-password-for-git)\n\n以下是Github官方文件對於Access Token的一些操作說明：\n- [Creating a personal access token](https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token)\n- [Caching your GitHub credentials in Git](https://docs.github.com/en/github/using-git/caching-your-github-credentials-in-git)\n- [Updating credentials from the macOS Keychain](https://docs.github.com/en/github/using-git/updating-credentials-from-the-macos-keychain)","tags":["git","github"],"categories":["Software Dev"]},{"title":"資訊隱藏：最低有效位元","url":"/stegano-least-significant-bit/","content":"\b這學期修了很有趣的課程，我覺得隱寫術這個詞還蠻中二的。<!--more-->\n\n[維基百科](https://zh.wikipedia.org/wiki/隱寫術)對於隱寫術的描述：\n>隱寫術是一門關於資訊隱藏的技巧與科學，所謂資訊隱藏指的是不讓除預期的接收者之外的任何人知曉資訊的傳遞事件或者資訊的內容。隱寫術的英文叫做Steganography，來源於特裡特米烏斯的一本講述密碼學與隱寫術的著作Steganographia，該書書名源於希臘語，意為「隱秘書寫」。\n\n>一般來說，隱寫的資訊看起來像一些其他的東西，例如一張購物清單，一篇文章，一篇圖畫或者其他「偽裝」\b(cover)的訊息。隱寫的資訊通常用一些傳統的方法進行加密，然後用某種方法修改一個「偽裝文字」(covertext)，使其包含被加密過的訊息，形成所謂的「隱秘文字」(stegotext)。例如，文字的大小、間距、字體，或者掩飾文字的其他特性可以被修改來包含隱藏的資訊。只有接收者知道所使用的隱藏技術，才能夠恢復資訊，然後對其進行解密。\n\n\b\b\b現代的隱寫術是利用數位媒介作為載體，例如影像、聲音以及影片。載體檔案相對隱秘檔案的數據量越大，隱藏後者就越容易。或許是和授課者的專業領域有關，這學期的課都是以影像作為載體使用。\n\n我想最低有效位元(LSB，Least Significant Bit)應該是最簡單的方法吧，透過將秘密資訊嵌入影像像素的LSB，其對影像的修改程度非常細微，達到肉眼無法察覺的程度。而在嵌入資訊前，對影像進行了量化處理，量化值(Ｌ)的大小對影像品質也有著相對的影響。\n\n![](https://i.imgur.com/lg0WsNO.png)\n\n對於嵌入秘密資訊後的影像，再次以同樣的量化值進行處理，以前者減去後者的像素值，就能萃取出嵌入的秘密資訊。實際上在課程作業有用了算數編碼對秘密資訊加密後再嵌入，但自己在實作上的結果並不穩定，得再花點時間找資料研究思考。而最低有效位元的方式雖然簡單，卻也相當脆弱，影像如果被壓縮過，嵌入的資訊也會遭到破壞...。因此在後續的課程也學習到一些進階的方式，令菜雞我覺得很厲害。\n\n下面的測試影像藏入了這段文字：\n>After billions of dollars and a decade of work, NASA's plans to send astronauts back to the moon had a new setback on Saturday. A planned eight-minute test firing of the four engines of a new mega rocket needed for the moon missions came to an abrupt end after only about a minute.As engineers disentangle what went wrong, the first launch of the rocket is likely to slip further into the future, and NASA astronauts may have to wait longer before setting foot on the moon again.\n\n藏入一段文字後的影像，量化值越大，峰值訊噪比就越低\b⬇︎\n![](https://i.imgur.com/vUFXa1i.png)\n\n＊原始碼連結：[Github](https://github.com/laplacetw/stegano/blob/main/lsb.py)\n＊測試影像來源：[unsplash](https://unsplash.com/photos/r2nJPbEYuSQ)","tags":["python","data hiding"],"categories":["Steganography"]},{"title":"GANs in Action Ch2：VAE","url":"/data-sci-gans-in-action-ch2/","content":"範例程式研讀。<!--more-->\n\n＊TensorFlow 2.x 動態圖機制Eager Mode可能會導致範例程式拋出SymbolicException錯誤，需手動關閉：\n{% codeblock %}\ntf.compat.v1.disable_eager_execution()\n{% endcodeblock %}\n\n### 超參數與自訂函式\n- 超參數epsilon_std是在sampling()裡面所使用，但keras.backend.random_normal的參數stddev(標準差)預設值就是1.0。\n\n- sampling()會在編碼器的結構中接收參數：平均值和對數變異數(z_mean, z_log_var)，返回取樣自平均值=z_mean且標準差=$ \\sqrt {z\\\\_log\\\\_var} $之常態分佈的隨機數值陣列，也就是Z(潛在空間，latent space)。\n\n- vae_loss()負責在VAE訓練過程接收參數：實際值(原始影像)及預測值(解碼器生成影像)來計算Loss，返回二元交叉熵(binary cross entropy)與相對熵(relative entropy)的和。\n\n{% codeblock lang:py%}\n# defining the key parameters\nbatch_size = 100\noriginal_dim = 784  # MNIST: 28 * 28\nlatent_dim = 2\nintermediate_dim = 256\nepochs = 5\nepsilon_std = 1.0\n\ndef sampling(args: tuple):\n    # we grab the variables from the tuple\n    z_mean, z_log_var = args\n    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=epsilon_std)\n    return z_mean + K.exp(z_log_var / 2) * epsilon\n\n# defining the losses\ndef vae_loss(x: tf.Tensor, x_decoded_mean: tf.Tensor):\n    # cross entropy\n    xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n    # relative entropy\n    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n    vae_loss = K.mean(xent_loss + kl_loss)\n    return vae_loss\n{% endcodeblock %}\n\n### 變分自編碼器模型\n- Encoder：輸入影像，輸出平均值、對數變異數、潛在空間。\n\n- Decoder：輸入潛在空間，輸出生成影像。\n\n{% codeblock lang:py %}\n# defining the encoder\nx = Input(shape=(original_dim,), name=\"input\")\nh = Dense(intermediate_dim, activation='relu', name=\"encoding\")(x)\n# mean of the latent space\nz_mean = Dense(latent_dim, name=\"mean\")(h)\n# log variance of the latent space\nz_log_var = Dense(latent_dim, name=\"log-variance\")(h)\nz = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\nencoder = Model(x, [z_mean, z_log_var, z], name=\"encoder\")\nencoder.summary()\n\n# defining the decoder\ninput_decoder = Input(shape=(latent_dim,), name=\"decoder_input\")\ndecoder_h = Dense(intermediate_dim, activation='relu', name=\"decoder_h\")(input_decoder)\nx_decoded = Dense(original_dim, activation='sigmoid', name=\"flat_decoded\")(decoder_h)\ndecoder = Model(input_decoder, x_decoded, name=\"decoder\")\ndecoder.summary()\n\n# defining the VAE\n# encoder return: [z_mean, z_log_var, z]\noutput_combined = decoder(encoder(x)[2])\nvae = Model(x, output_combined, name=\"VAE\")\nvae.summary()\nvae.compile(optimizer='rmsprop', loss=vae_loss)\n{% endcodeblock %}\n\n### 模型訓練\n- VAE的輸出也是影像，所以fit()的Y參數要輸入影像資料而非數據標籤。\n\n{% codeblock lang:py %}\n# load data\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\nx_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))  # (60000, 784)\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))      # (10000, 784)\n\n# training\nvae.fit(x_train, x_train, shuffle=True, epochs=epochs, batch_size=batch_size)\n{% endcodeblock %}\n\n### 散點圖\n- 測試資料經編碼後於潛在空間中的分佈情形\n\n- 我另外畫出後續會用來採樣生成圖片的紅框區域\n    ![](https://i.imgur.com/21rENRi.png)\n\n{% codeblock lang:py %}\n# display a 2D plot of the digit classes in the latent space\nx_test_encoded = encoder.predict(x_test, batch_size=batch_size)[0]\nfig = plt.figure(figsize=(6, 6))\nplt.scatter(x_test_encoded[:,0], x_test_encoded[:,1], c=y_test, cmap='viridis')\nplt.colorbar()\nplt.show()\n{% endcodeblock %}\n\n### 生成圖片\n- 使用[numpy.linspace()](https://numpy.org/doc/stable/reference/generated/numpy.linspace.html)生成區間(0.05, 0.95)的具有n個元素的等差數列，再由[scipy.stats.norm.ppf()](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html)轉換為常態累積分佈的[百分位數](https://zh.wikipedia.org/wiki/%E7%99%BE%E5%88%86%E4%BD%8D%E6%95%B0)，做為潛在空間取樣座標(grid_x, grid_y)。\n\n- 取樣範圍區間：[Z(0.05) = -1.645, z(0.95) = 1.645](https://en.wikipedia.org/wiki/Standard_normal_table#Cumulative)\n\n- 反轉grid_x順序的圖片生成結果，對應散點圖的紅框範圍(原始範例會上下顛倒)\n    ![](https://i.imgur.com/elfnFuN.png)\n\n{% codeblock lang:py %}\n# display a 2D manifold of the digits\nn = 15  # figure with 15x15 digits\ndigit_size = 28\nfigure = np.zeros((digit_size * n, digit_size * n))\n# linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian\n# to produce values of the latent variables z, since the prior of the latent space is Gaussian\ngrid_x = norm.ppf(np.linspace(0.05, 0.95, n))\ngrid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n\nfor i, yi in (enumerate(grid_x)):\n    for j, xi in enumerate(grid_y):\n        z_sample = np.array([[xi, yi]])\n        x_decoded = decoder.predict(z_sample)\n        digit = x_decoded[0].reshape(digit_size, digit_size)\n        figure[i * digit_size: (i + 1) * digit_size,\n               j * digit_size: (j + 1) * digit_size] = digit\n\nplt.figure(figsize=(10, 10))\nplt.imshow(figure, cmap='Greys_r')\nplt.show()\n{% endcodeblock %}\n\nRef. [https://github.com/GANs-in-Action/gans-in-action](https://github.com/GANs-in-Action/gans-in-action)","tags":["GAN","keras","deep learning"],"categories":["Data Science"]},{"title":"iOS 捷徑製作：縮網址","url":"/ios-shortcut-tinyurl/","content":"\b\b因為APP的系統版本支援問題，從iOS 11更新上iOS 14，研究了一下捷徑功能。<!--more-->\n\n[捷徑](https://support.apple.com/zh-tw/guide/shortcuts/welcome/ios)能做的事情很多，光是能在網頁執行自己編寫的JavaScript就很不得了...是危險的味道呢\b(pero，儘管網路上很容易就能找到一堆方便的腳本，甚至也有提供人們公開發佈捷徑腳本的網站。這就是為何iOS 13開始對捷徑內容審查變得嚴格(其實也只是要你按下允許不受信任的捷徑為個人行為背書)，而IBM Security的研究人員於2019年也曾提出警告[iOS捷徑可能被用於勒索攻擊](https://www.zdnet.com/article/siri-shortcuts-can-be-abused-for-extortion-demands-malware-propagation/)。\b\n\n---\n\n要製作TinyURL縮址的話，得知道縮址的時候如何發出請求，在TinyURL首頁有個「Add TinyURL to your browser's toolbar」的說明，這裡就提供了連結：\n>tinyurl.com/create.php?url=\n\n1. 建立一個新捷徑 > 點選右上角打開捷徑設定 > 啟用「在分享表單中顯示」> 「分享表單類型」設定為「文字＆URL」\n    ![](https://i.imgur.com/46xfJ1k.png)\n\n2. \n    - 新增動作 > 「網頁」> 「URL」> 輸入下方網址，後面接變數「捷徑輸入」\n    {% codeblock lang:bash %}\n    https://tinyurl.com/create.php?url=\n    {% endcodeblock %}\n    - 新增動作 > 「網頁」> 「取得URL內容」\n    - 新增動作 > 「文件」> 「<span style=\"color:red\">從RTF製作HTML</span>」(動作會自行填入變數「URL內容」取代「RTF」)\n    ![](https://i.imgur.com/z4ptJEb.png)\n\n3. \n    - 新增動作 > 「文件」> 「符合文字」> 選擇變數「從HTML製作RTF」> 輸入下方的Regex(Regular Expression)\n    {% codeblock lang:bash %}\n    (?<=data-clipboard-text=\").*(?=\"><small>)\n    {% endcodeblock %}\n    - 新增動作 > 「分享」> 「拷貝到剪貼板」\n    - 新增動作 > 「工序指令」> 「\b退出捷徑」\n    ![](https://i.imgur.com/1yFJdId.png)\n\n4. 點選「下一步」幫捷徑取個名字就完成了。接著使用瀏覽器開啟任意網頁，打開分享選單往下找就能看到方才製作的捷徑，也可以點選「編輯動作」> 「加入喜好項目」來置頂捷徑。\n    ![](https://i.imgur.com/jHcprZX.png)\n\n5. 點選執行縮網址捷徑，首次使用會詢問是否允許捷徑存取tinyurl.com這個網站(注意到「<span style=\"color:red\">此捷徑將可傳送資料到這些網站</span>」了嗎？看不懂腳本在做什麼而使用它是有風險的)。按下允許後捷徑便會將正在瀏覽的網頁進行縮址，接著自動複製並關閉捷徑，然後就可以在任何地方貼上縮好的網址啦。\n    ![](https://i.imgur.com/yHnHz2z.png)\n\n---\n\n備註：\n1. 事實上我有嘗試要直接透過Regex比對HTML元素來找到縮好的網址，但「從URL內容製作HTML」的動作所輸出的變數卻是「從HTML製作RTF」...而直接比對「取得URL內容」的輸出也沒有結果，該動作的說明寫著「對於下載檔案和網頁內容或提出API要求十分有效」啊啊啊🤪\n2. 關於捷徑中所使用的Regex語法似乎有些特別，我在Reddit找到一篇不錯的參考：[Match Text Examples for the Beginner – A Regex Cookbook and Primer for Siri Shortcuts](https://www.reddit.com/r/shortcuts/comments/b5labq/match_text_examples_for_the_beginner_a_regex/)","tags":["ios","shortcuts"],"categories":["iOS"]},{"title":"Zsh安裝和VS Code顯示設定","url":"/mac-zsh-and-vscode/","content":"順便筆記一下安裝指令。<!--more-->\n\n### Install Oh My Zsh\n參考[瘋先生MRMAD的快速教學](https://mrmad.com.tw/macos-terminal-oh-my-zsh)。\n\n{% codeblock lang:bash %}\n$ sh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\"\n$ vim ~/.zshrc  # change ZSH_THEME as \"agnoster\"\n$ echo 'syntax on' >> ~/.vimrc  # enable syntax highlight\n$ echo 'set nu!' >> ~/.vimrc    # enable line numbers\n$ source ~/.zshrc  # make changes reload\n{% endcodeblock %}\n\n安裝、設定完成會發現Terminal顯示亂碼的情形，因為agnoster主題包含特殊符號，需安裝Powerline系列字體才能正常顯示：\n\b{% codeblock lang:bash %}\n$ cd ~/Downloads && git clone https://github.com/powerline/fonts.git\n$ cd fonts && ./install.sh\n$ cd && rm -rf ~/Downloads/fonts\n{% endcodeblock %}\n\n接著打開Terminal偏好設定 > 描述檔 > 字體，變更為Powerline系列的字體。我是用Source Code Pro for Powerline，另外路徑的背景顏色預設會有過深的問題，可以調整ANSI顏色選項的藍色部分為淺一點的顏色。\n\n＊<span style=\"color:red;\">on my sh默認設定檔為~/.zshrc</span>，若原本bash設定檔是寫在~/.bash_profile，則須在zshrc中寫入：\n{% codeblock lang:bash %}\nif [ -f ~/.bash_profile ]; then\n  . ~/.bash_profile\nfi\n{% endcodeblock %}\n\n### VS Code Integrated Terminal\nTerminal顯示亂碼在VS Code裡頭也會見到，同樣要修改字體為Powerline系列字體：設定 > 功能 > 終端機 > Integrated: Font Family。\n\n顏色設定可以在設定中搜尋workbench，找到Workbench: Color Customizations的選項，點選「在settings.json內編輯」，相關參數設定可參考VS Code官網的說明：[Integrated Terminal Colors](https://code.visualstudio.com/api/references/theme-color#integrated-terminal-colors)\n\n![](https://i.imgur.com/yn3BTug.png)\n\n不過我另外有找到一個設定檔的[懶人包](https://github.com/Tyriar/vscode-snazzy)，或許可以直接套用，再來做調整比較省事 😄\n\n![](https://i.imgur.com/Fuw8S8v.png)","tags":["mac","vs code"],"categories":["Mac"]},{"title":"Manjaro安裝VirtualBox","url":"/linux-manjaro-virtualbox/","content":"因為某堂課程的作業需要M$環境...<!--more-->就為了操作檔案加密，我本來挖出了退役的舊筆電，結果它是Windows 7家用版，無法使用那該死的檔案加密功能！只好裝起虛擬機 🤬\n\n#### Enabling Virtualisation\n在安裝VirtualBox之前，必須先進BIOS檢查，確認已啟用CPU虛擬化，否則會跳出VERR_SVM_DIABLED錯誤。\n\n#### Install VirtualBox\n我們會需要安裝virtualbox和host modules，後者得根據系統核心來安裝對應的版本：\n{% codeblock lang:bash %}\n# check the version of Linux kernel\n$ mhwd-kernel -li\nCurrently running: 4.19.126-1-MANJARO (linux419)\nThe following kernels are installed in your system:\n   * linux419\n{% endcodeblock %}\n\n執行系統更新並根據系統核心版本安裝virtualbox：\n{% codeblock lang:bash %}\n# {KERNEL_VERSION}-virtualbox-host-modules\n$ sudo pacman -Syu virtualbox linux419-virtualbox-host-modules\n{% endcodeblock %}\n\n如果有跑系統更新，建議安裝完成後重新啟動。或手動將virtualbox載入系統核心：\n{% codeblock lang:bash %}\n$ sudo vboxreload\n{% endcodeblock %}\n\n確認VirtualBox\b版本：\n{% codeblock lang:bash %}\n$ vboxmanage --version\n6.1.16r140961\n{% endcodeblock %}\n\n#### Host Config\n在啟動virtualbox之前，還要將自己的系統帳號加入vboxusers使用者群組才行：\n{% codeblock lang:bash %}\n$ sudo gpasswd -a {USERNAME} vboxusers\n{% endcodeblock %}\n\n記得登出或重啟系統以使帳號設定變更生效，然後就可以啟動virtualbox啦：\n{% codeblock lang:bash %}\n$ virtualbox\n{% endcodeblock %}\n\n![](https://i.imgur.com/qf6bNsr.png)\n![](https://i.imgur.com/gO2vZqD.png)\n\n#### Access USB Device\n\b\b＊2021/04/18 update\n最近需要Win10環境和USB裝置來讀取個東西，所以就先用隨身碟測試，但裝置管理員卻顯示錯誤代碼10。問Google得到很多結果都說是沒有設定vboxusers group...查了半天原來是需要安裝[VirtualBox Extension Pack](https://www.virtualbox.org/wiki/Downloads)。\n\n下載、安裝後在擴充功能列表就可以看到Extension Pack⬇︎\n![](https://i.imgur.com/Yx5CRJC.png)\n\n接著在VM的個別設定中將USB控制器設定為2.0\b/3.0⬇︎\n![](https://i.imgur.com/nIqXdHh.png)\n\n重啟VM後插入USB裝置，就可以在VM功能選單>裝置>USB\b\b選取要掛載的USB裝置了。\n\n\n\b\b\bRef.\n- [https://wiki.manjaro.org/index.php/VirtualBox](https://wiki.manjaro.org/index.php/VirtualBox)\n- [VirtualBox 安裝 Extension Pack，讓 Windows 10 虛擬機支援 USB 3.0](https://iqmore.tw/oracle-vm-virtualbox-extension-pack-windows-10-usb-3-0)","tags":["linux","manjaro"],"categories":["Linux"]},{"title":"Travis CI使用設置","url":"/sofdev-travis-ci/","content":"以Python Project為例。<!--more-->\n\n\b\b說到和Github搭配的自動建置測試工具，第一個想到的應該就是Travis CI了，測試的部分我使用[pytest](https://docs.pytest.org/en/stable/index.html)來寫。那麼就先到[Travis CI]((https://travis-ci.org/)註冊帳號吧，直接使用Github帳號登入，方便從Github倉庫直接加入專案。\n\n![](https://i.imgur.com/mIbm9Ul.png)\n\n測試時若需要環境變數可以在設定頁面加入⬇︎\n![](https://i.imgur.com/n8PM94F.png)\n\n接著要在專案根目錄新增一個名稱為 .travis.yml的檔案，這是Travis CI進行建置測試時的腳本。以下是我參考[官方文件](https://docs.travis-ci.com/user/languages/python/)所寫的 .travis.yml內容：\n{% codeblock lang:yml %}\nlanguage: python\npython:\n  - \"3.5\"\n  - \"3.6\"      # current default Python on Travis CI\n  - \"3.7\"\n  - \"3.8\"\n  - \"nightly\"  # nightly build\n# command to install dependencies\ninstall:\n  - pip install -r requirements.txt\n  - pip install pytest\n# command to run tests\nscript:\n  - pytest\n{% endcodeblock %}\n\n由上面的測試腳本內容可以看到，\bTravis CI會依照python區塊所設定，建置Python 3.5~3.8加上[nightly](https://docs.travis-ci.com/user/languages/python/#nightly-build-support)等5個版本的測試環境，進行測試之前會依照install區塊的指令安裝依賴套件，script區塊則是運行測試相關的指令設定，若是有設定環境變數，則必須在此區塊設定「export {var_name}=${env_var_name}」，如此便能在測試程式碼中透過var_name取得環境變數。\n\n上述設定完成後，只要推送更新到Github，便會觸發Travis CI進行自動建置測試，建置結果也會發信通知我們。~~然後我的Telegrambot就會因為測試而發送一堆訊息給我。~~\n![](https://i.imgur.com/Tkail1B.png)","tags":["python","travis ci"],"categories":["Software Dev"]},{"title":"Python:&nbsp;Sphinx ＆ ReadTheDocs","url":"/python-sphinx-and-readthedocs/","content":"當我認真想為個人專案寫文件的時候，於是想到了Sphinx，<!--more-->雖然還是對路徑設定感到有點苦惱，但自動生成文件真的很香，尤其是託管到Read The Docs還能和Github連動，只要推送更新到Github就會觸發自動建置。\n\n### Sphinx\n<p>\n\n總之Sphinx就是能自動生成文件的工具，只要在原始碼中使用[reStructuredText](https://www.sphinx-doc.org/en/master/usage/restructuredtext/index.html)或[Markdown](https://www.sphinx-doc.org/en/master/usage/markdown.html)語法來撰寫文件內容。\n\n官方入門指南：[Sphinx Quick Start](https://www.sphinx-doc.org/en/master/usage/quickstart.html)\n\n1. 安裝：\n    {% codeblock lang:sh %}\n    $ pip install Sphinx\n    {% endcodeblock %}\n\n2. 快速啟用：\n    首先在文件的根目錄建立doc、src兩個資料夾，分別用來放建置文件和原始碼。\bSphinx內建sphinx-quickstart腳本，可引導使用者快速完成基本設定：\n    {% codeblock lang:sh %}\n    $ cd doc\n    $ sphinx-quickstart\n    {% endcodeblock %}\n\n    這裡選擇獨立的原始碼和建置目錄⬇︎\n    ![](https://i.imgur.com/XowPf8k.png)\n\n    接著腳本會引導使用者設定文件名稱、版本號、作者等資訊，設定完成後的目錄結構：\n    {% codeblock lang:sh %}\n    .\n    ├── doc\n    │   ├── Makefile\n    │   ├── build\n    │   ├── make.bat\n    │   └── source\n    │       ├── _static\n    │       ├── _templates\n    │       ├── conf.py\n    │       └── index.rst\n    └── src\n    {% endcodeblock %}\n\n    從上面的目錄結構可以看到，doc目錄下有自動建置的指令檔，source目錄中則是文件相關的資源檔，包含靜態檔案、設定檔conf.py以及首頁index.rst。\n\n3. conf.py基本設定：\n\n    - 原始碼路徑：\n    {% codeblock lang:py %}\n    # -- Path setup --------------------------------------------------------------\n\n    # If extensions (or modules to document with autodoc) are in another directory,\n    # add these directories to sys.path here. If the directory is relative to the\n    # documentation root, use os.path.abspath to make it absolute, like shown here.\n    #\n    import os\n    import sys\n    sys.path.insert(0, os.path.abspath('../../src'))\n    {% endcodeblock %}\n\n    路徑不能亂設定，例如[將package目錄直接設定為原始碼路徑](https://stackoverflow.com/questions/20251007/sphinx-and-relative-imports-in-python-3)，然後就導致各種import error然後文件建置失敗😅\n\n    - 一般設定\n    {% codeblock lang:py %}\n    # -- General configuration ---------------------------------------------------\n    master_doc = 'index'  # main page: index.rst\n    autodoc_member_order = 'bysource'  # optional\n    {% endcodeblock %}\n    如果不希望autodoc自動對member排序就設定為'bysource'。\n\n    - 擴充功能\n    {% codeblock lang:py %}\n    # Add any Sphinx extension module names here, as strings. They can be\n    # extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n    # ones.\n    extensions = ['sphinx.ext.autodoc']\n    {% endcodeblock %}\n\n    - 佈景主題\n    {% codeblock lang:py %}\n    # The theme to use for HTML and HTML Help pages.  See the documentation for\n    # a list of builtin themes.\n    #\n    html_theme = 'alabaster'  # default\n    {% endcodeblock %}\n    更多主題：[Sphinx Doc / Theming](https://www.sphinx-doc.org/en/master/usage/theming.html)\n\n4. index.rst主頁設定：\n    打開index.rst會看到標題和toctree目錄設定，.rst也就是reStructuredText格式的文件，因此文件的每一個頁面都會有一個.rst檔，按需求自行新增。假設我有index.rst和mod_a.rst兩個頁面，那麼toctree目錄設定應該長這樣：\n    {% codeblock lang:sh %}\n    .. toctree::\n        :maxdepth: 2\n        :caption: Contents:\n\n        mod_a\n    {% endcodeblock %}\n\n    *注意空格、縮排以及不需要寫出.rst檔名後綴\n\n    如此在生成文件的時候，首頁目錄就會有mod_a這個頁面，而mod_a頁面內容就在mod_a.rst檔案中撰寫、定義。\n\n5. autodoc：\n    \b語法參考：[sphinx.ext.autodoc](https://www.sphinx-doc.org/en/master/usage/extensions/autodoc.html#module-sphinx.ext.autodoc)\n\n    簡單舉例，假設上述的mod_a.rst對應到原始碼src/proj/mod_a.py這個模組，那麼mod_a.py可能定義了一些類別或方法，則mod_a.rst的內容除了標題和一些說明文字，autodoc的設定應該長這樣：\n    {% codeblock lang:sh %}\n    .. automodule:: proj.mod_a\n        :members:\n    {% endcodeblock %}\n    如此audodoc便會自動將模組中的成員引入mod_a.rst頁面，包含以reStructuredText語法所撰寫的註解！例如：\n    {% codeblock lang:py %}\n    class a():\n\n        \"\"\"\n        write reStructuredText here\n        \"\"\"\n\n        def __init__(self):\n            \"\"\"\n            write reStructuredText here\n            \"\"\"\n            pass\n    {% endcodeblock %}\n\n6. make：\n    \b\b\b\b\b當上述的文件內容都撰寫好了，就可以使用自動建置指令來生成文件：\n    {% codeblock lang:sh %}\n    $ make clean  # Delete the build cache before building documents\n    $ make html\n    {% endcodeblock %}\n    建置完成的html檔會在/doc/build目錄下。\n\n    \b\bSphinx文件實例，供參考：[laplacetw/botlegram-doc](https://github.com/laplacetw/botlegram-doc)\n\n### Read The Docs\n<p>\n\n\b\b生成了文件後若打算公開發佈，可以使用[Read The Docs](https://readthedocs.org/)這個基於Sphinx的免費文件託管服務，註冊帳號後，建議與版本控制服務例如Github連動，如此便可以直接從Github匯入\b我們的Sphinx專案來建立一個Read The Docs專案，之後只要推送更新到Github，那麼Read The Docs便會自動建置更新我們的線上文件了。\n\n![](https://i.imgur.com/DhpdU4O.png)\n\nRead The Docs線上文件實例，供參考：[https://botlegram.readthedocs.io/](https://botlegram.readthedocs.io/)","tags":["python","sphinx","readthedocs"],"categories":["Python"]},{"title":"拋棄繼承聲請記事","url":"/asserting-waived-succession/","content":"總算處理完所有必要文件順利送到郵局了，但遇到中秋連假，所以下週才會寄出。<!--more-->儘管我仍無法理解人生怎麼會突然就稀巴爛，然後一轉眼便是十年，我仍在收拾殘局，然而有人卻已匆匆謝幕。看著戶籍謄本思索了幾秒，人生就只是這樣呢，我們終究都要化為記事欄裡頭的幾行字，但就是有人過得辛苦，有人過得舒服。\n\n一樣米養百樣人，若是遇到豬隊友，為免夜長夢多、債留子孫，繼承這事可就得審慎處理。雖然在2009年民法繼承編修訂後已採「當然限定繼承」，不用再向法院聲請，繼承人僅需繼承所得的遺產為限，負清償責任。但在我和具法律專業背景友人詢問後，了解到限定繼承需開具遺產清冊陳報法院這件事，光想就覺得麻煩，更何況\b\b\b以我自身而言，只求別再受前人債務拖累、斷送餘生，所以說還是乾脆點聲明拋棄繼承。\n\n### 相關法條\n<p>\n\n[民法第五編：繼承]((https://law.moj.gov.tw/LawClass/LawParaDeatil.aspx?pcode=B0000001&bp=126)\n\n\b[民法第1138條](https://law.moj.gov.tw/LawClass/LawSingle.aspx?pcode=B0000001&flno=1138)：\n>「遺產繼承人，除配偶外，依左列順序定之：\n- 一、直系血親卑親屬。\n- 二、父母。\n- 三、兄弟姊妹。\n- 四、祖父母。\n\n[民法第1147條](https://law.moj.gov.tw/LawClass/LawSingle.aspx?PCODE=B0000001&FLNO=1147)：\n>「繼承，因被繼承人死亡而開始。」\n\n[民法第1148條](https://law.moj.gov.tw/LawClass/LawSingle.aspx?pcode=B0000001&flno=1148)：\n>「繼承人自繼承開始時，除本法另有規定外，承受被繼承人財產上之一切權利、義務。但權利、義務專屬於被繼承人本身者，不在此限。<font color='red'>繼承人對於被繼承人之債務，以因繼承所得遺產為限，負清償責任。</font>」\n\n[民法第1153條](https://law.moj.gov.tw/LawClass/LawSingle.aspx?pcode=B0000001&flno=1153)：\n>「<font color='red'>繼承人對於被繼承人之債務，以因繼承所得遺產為限，負連帶責任。</font>繼承人相互間對於被繼承人之債務，除法律另有規定或另有約定外，按其應繼分比例負擔之。」\n\n[民法第1174條](https://law.moj.gov.tw/LawClass/LawSingle.aspx?PCODE=B0000001&FLNO=1174)：\n>「繼承人得拋棄其繼承權。前項拋棄，應於<font color='red'>知悉其得繼承之時起三個月內</font>，以書面向法院為之。<font color='red'>拋棄繼承後，應以書面通知因其拋棄而應為繼承之人</font>。但不能通知者，不在此限。」\n\n[民法第1175條](https://law.moj.gov.tw/LawClass/LawSingle.aspx?PCODE=B0000001&FLNO=1175)：\n>「繼承之拋棄，溯及於繼承開始時發生效力。」\n\n[民法第1176條 部分條文](https://law.moj.gov.tw/LawClass/LawSingle.aspx?pcode=B0000001&flno=1176)：\n>「因他人拋棄繼承而應為繼承之人，為拋棄繼承時，<font color='red'>應於知悉其得繼承之日起三個月內為之。</font>」\n\n### 辦理拋棄繼承\n<p>\n根據我在網路上搜集到的資料，各地方法院的聲請書格式或規定似乎有些微差異(白眼，所以要辦理拋棄繼承的第一件事，便是先確認「被繼承人戶籍所在地之管轄法院」，這樣你才知道該去哪下載聲請書的格式。但網路下載的格式可能會因為疏於更新而過舊，像我~~這樣超TUEEE的勇者~~總是比較謹慎的，當然是直接跑去法院購買紙本格式\b最保險。拋棄繼承聲請要在得知繼承事實發生的那一刻算起三個月內提出，聲請費用為1000塊，一個人聲請或全家一起聲請都是相同費用，若採用郵寄的方式則檢附1000塊郵政匯票，受款人為管轄法院。\n\n＊若管轄法院在臺北、臺中、臺南、臺東之類的名字有「臺」的縣市，要寫繁體的「臺」，\b而且必須寫全稱，例如「臺灣臺南地方法院」。\n\n供參考：[臺南地方法院拋棄繼承聲請書格式](https://tnd.judicial.gov.tw/doc/%AEa%A8%C6/%A9%DF%B1%F3%C4~%A9%D3%C1n%BD%D0%AA%AC.pdf)\n\n接著依照聲請書裡頭的格式依序填寫拋棄繼承書狀、繼承系統表、繼承權拋棄書，至於通知書跟收據我就沒用到了，因為我是寄存證信函通知下一順位的繼承人。\n\n再來就是取得辦理拋棄繼承應檢附的資料：\n1. [印鑑證明](https://www.ris.gov.tw/app/portal/741)：滿7歲之聲請人，如聲請人未滿20歲另應有法定代理人(父母皆須有)或監護人之印鑑證明；受拋棄繼承通知之人如以本狀第六頁收據蓋印鑑證明章表明已收受，亦須提供。\n2. 印鑑證明章：印鑑證明章如在本狀第三頁已蓋印完畢，可供法院核對之狀況下，則可不必攜章至本院(請聲請人自行判斷蓋印是否清楚)。\n3. 戶籍謄本：被繼承人除戶戶籍謄本、死者配偶(死者死亡時仍與其有婚姻關係之人；已往生者亦需要)、聲請人、聲請人之法定代理人(或有監護權之人)、同繼承順位未拋棄之人、第一繼承順位已先死者及其子女，或同繼承順位均拋棄而下一繼承順位之人(已往生者亦需要，如下一順位繼承人均已往生，則下下順位之繼承人亦需要，比如第一順位均拋棄，第二順位均往生，則要提供第三順位繼承人之戶謄)均需提供一份，該些人員有同戶籍者可提供全戶一份。\n\n我是用郵寄方式進行聲請，只要確認書狀聲請人印鑑用印清晰可辨識即可，不需要印鑑證明章。\n\n＊聲請人如為胎兒，應附上媽媽手冊封面、第一次產檢、最新產檢等文件之影本。\n＊<font color='red'>戶籍謄本記事欄不可省略</font>。\n\n![](https://i.imgur.com/DYTMqFI.jpg)\n\n處理到這就差存證信函影本了(通知其他順位繼承人之證明書)。\n\n### 撰寫存證信函\n<p>\n存證信函需要「N+2」份，N是收件人的人數，+2則是自己和郵局都會留存一份副本，<font color='red'>正本ㄧ定要寄出去千萬不要自己留著做紀念</font>，而我們留存的副本就影印一份檢附在聲請書中一併送交法院辦理。一開始我還傻傻的跑去郵局說要買存證信函用紙，然後郵局人員就拿出長得像中學生考試用紙的東東，而且那紙張還超薄...後來郵局人員就說可以上網[下載格式](https://www.post.gov.tw/post/internet/Download/index.jsp?ID=220301)以電腦繕打後複印，然後我就說不買了😅 \n\n多位寄件人或多位收件人相同住址則可以寫在一起，例如：\n\n寄件人：XXX、YYY\n詳細住址：xxxxxxxxxxxxxxxxx\n\n如果人丁興旺寫不下(?)，網路上的參考資料是建議可以直接註記「如附件」，然後把寄件者跟收件者都條列在附件。但也有人遇到[部份郵局不接受附件](https://home.gamer.com.tw/creationDetail.php?sn=4560024)的情形，可能要先詢問自家附近的郵局進行確認。\n\n![](https://i.imgur.com/HJdkBMW.png)\n\n至於內文的部分，我是直接參考聲請書的範例去寫：\n\n>寄件人XXX、YYY，因被繼承人ZZZ於民國YY年MM月DD日亡故，對其遺產，依法有繼承權。茲出於寄件人自由意思，爰依民法第一一七四條規定拋棄繼承權，全部遺產由收件人繼承，絕無異議，特此通知。\n\n我建議存證信函撰寫完<font color='red'>先轉為PDF格式再列印</font>，避免發生部分文字跑版，因為我使用超商雲端列印，然後下方的合計區塊文字就變成一坨இдஇ\n\n＊存證信函是採雙掛號方式郵寄，如果有先到郵局買信封可以先索取雙掛號回執拿回去先填寫，到時候要去寄才不會搞太久。\n＊存證信函撰寫完列印出來後，<font color='red'>寄件人要在每一份存證信函上簽名或蓋章</font>。\n\n### 送件\n<p>\n當聲請書、檢附資料以及存證信函這三件事都處理好，將自己留存的存證信函副本影印，就可以將聲請書、存證信函影本以及其他檢附資料一起寄出了。法院收件受理後，若有需要補費、補件、聲請准許或駁回，都會以掛號通知各聲請人，倘若收到「拋棄繼承准予核備函」就代表聲請核准囉。\n\n2020/09/30：送件中\n\n2020/10/05：送達法院\n\n2020/10/22：聲請通過，法院發文通知「本件拋棄繼承權准予備查」","tags":["civil law","waived succession"],"categories":["Daily"]},{"title":"Python:字典排序","url":"/pyhton-sort-dict-by-value/","content":"\b\b有時候會需要依據dict value來排序，嗯，就是會有這種時候(´･_･`)<!--more--> 話說我看了官方文件才發現，從Python 3.6開始依據[PEP 468](https://www.python.org/dev/peps/pep-0468/)將保留**kwargs的順序，所以現在dict也是有序的呢(插入元素的順序)，而我開始學習Python的時候是3.5版。\n\n\b\n假設有個dict長這樣：\n{% codeblock lang:py %}\nmy_friend = {\n    'Mike':{'gender':'male', 'age':25}, \n    'Emily':{'gender':'female', 'age':23}, \n    'John':{'gender':'male', 'age':30}, \n    'Ted':{'gender':'male', 'age':26}, \n    'Alice':{'gender':'female', 'age':29}\n}\n{% endcodeblock %}\n\n如果想依據'age'來排序？ 利用lambda將sort key指定為dict value中的某個值來排序dict.items()：\n{% codeblock lang:py %}\n>>> sort_my_friend = sorted(my_friend.items(), key=lambda x:x[1]['age'])\n>>> sort_my_friend\n[('Emily', {'gender': 'female', 'age': 23}), ('Mike', {'gender': 'male', 'age': 25}), ('Ted', {'gender': 'male', 'age': 26}), ('Alice', {'gender': 'female', 'age': 29}), ('John', {'gender': 'male', 'age': 30})]\n{% endcodeblock %}","tags":["python"],"categories":["Python"]},{"title":"Python:&nbsp;install psycopg2 error","url":"/python-install-error-psycopg2/","content":"啊啊，ERROR。<!--more-->\n\n上一次安裝PostgreSQL是汰換Win 7筆電之前，這次在Mac OS安裝[Postgres.app](http://postgresapp.com/)，然後要安裝psycopg2的時候報錯了。\n\n傻眼，我有些急用啊，你大哥請支援收銀好嗎？\n\n{% codeblock lang:sh %}\nError: pg_config executable not found.\n\nPlease add the directory containing pg_config to the PATH\n\n(omitted...)\n\nERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\n{% endcodeblock %}\n\npip報錯說找不到pg_config路徑，要把Postgress.app的bin資料夾路徑加入環境變數，[參考stackoverflow上的討論](https://stackoverflow.com/questions/11618898/pg-config-executable-not-found#24684701)，於安裝時指定其路徑(Mac OS)：\n\n{% codeblock lang:sh %}\nPATH=\"/Applications/Postgres.app/Contents/Versions/latest/bin:$PATH\" pip install psycopg2\n{% endcodeblock %}\n\n![](https://i.imgur.com/9Y96knz.png)\n\n##### Note\n<p>\n[Psql Commonly used commands](http://postgresguide.com/utilities/psql.html)\n\n\\list: list databases\n\\dt : list tables in current DB\n\\d TABLE_NAME : list table columns\n\\x : enable expanded display (e.g. SELECT * FROM mytable LIMIT 10;)","tags":["python","error","psycopg2","postgresql"],"categories":["Python"]},{"title":"Python:快速建立Telegram聊天機器人","url":"/python-botlegram/","content":"寫了一個套件，雖然現在還沒啥功能，只能發送文字和照片。<!--more-->也不是只有搞了個套件，還嘗試了用[Sphinx](https://www.sphinx-doc.org/en/master/)自動產生文件然後托管到[Read The Docs](https://readthedocs.org/)，被autodoc路徑折騰了不少時間...這是另一段故事了。雖然現在才開始研究怎麼寫Telegram Bot，也有多種程式語言的現成框架可以用，但我不想要使用高度封裝的複雜框架，所以決定一邊學習Telegram Bot API，一邊完成這個套件，希望我有足夠的時間和心力 😌\n\n\n### Botlegram\n<p>\n\n鏘！鏘！經過一番折騰終於發佈到Github上了，我希望能保持它的彈性，不要做多餘的事，它就只是一個Telegram Bot API的Python版本，所以功能函式命名也會盡可能地保持與[Telegram Bot API methods](https://core.telegram.org/bots/api#available-methods)一致。\n\n- source code: [Botlegram](https://github.com/laplacetw/botlegram)\n- online document: [Botlegram Doc](https://botlegram.readthedocs.io/)\n\n### Tutorial\n<p>\n\n##### 準備工作：\n\n- 以下說明是以部署在Heroku為例，所以必須先準備一個[Heroku帳號](https://www.heroku.com/)，然後[建立一支APP](https://trailhead.salesforce.com/content/learn/projects/develop-heroku-applications/create-a-heroku-app)\n- 初次使用Heroku則必須先[安裝Heroku CLI](https://devcenter.heroku.com/articles/heroku-command-line)\n- 下載我預先準備的Telegram Bot懶人包: [echo Bot](https://github.com/laplacetw/botlegram/files/5236011/echoBot.zip)\n- 和Telegram官方帳號[BotFather](https://telegram.me/BotFather)進行對話 (取名叫Bot Father我覺得很有趣 😆&nbsp;)，按指示建立Bot取得專屬token，此token必須由你自己妥善保管，因為<font color=\"red\">任何人都能使用這個token來控制你的Bot</font>。\n\n![](https://i.imgur.com/wauvK7S.png)\n\n##### 解壓縮懶人包echoBot.zip\n\n開啟app.py:\n- your_bot_token替換成你的專屬token\n- your_host替換成你的Heroku App網址，請注意不可忽略的斜線\ne.g. \"https://APP_NAME.herokuapp.com/\"\n\n\n##### 部署到Heroku\n\n打開終端機依照下方指令操作，APP_NAME替換成你的Heroku App name\n{% codeblock lang:sh %}\n$ cd echoBot\n$ heroku login\n$ heroku git:remote -a APP_NAME\n$ git add .\n$ git commit -am \"echo Bot\"\n$ git push heroku master\n{% endcodeblock %}\n\n##### 確認與測試\n\n部署成功的話，可以在Heroku的APP Logs頁面看到\b「Webhook is already set」\n{% codeblock lang:sh %}\nStarting process with command `gunicorn app:app`\n[INFO] Starting gunicorn 20.0.4\n[INFO] Listening at: http://0.0.0.0:10426 (4)\n[INFO] Using worker: sync\n[INFO] Booting worker with pid: 10\n[INFO] Booting worker with pid: 11\nState changed from starting to up\n* [Bot] Webhook is already set\n* [Bot] Webhook is already set\n{% endcodeblock %}\n\n打開Telegram和你的機器人對話，它應該會開始鸚鵡學舌囉 🐧","tags":["python","chatbot","telegram"],"categories":["Python"]},{"title":"在Heroku遠端主機控制瀏覽器","url":"/data-sci-heroku-selenium-chrome-driver/","content":"\b\b\b\b\b\b如題。<!--more-->最近在研究Telegram Bot API，雖然讀過文件知道許多語言都已經有不少第三方框架支援，基於某些應用目的不想被框架綁住，所以打算自己寫。然後我就耗了整整兩天，嘗試如何讓部署在Heroku上的Bot能順利\b使用headless browser擷取到我要的數據...\b。說也奇怪，本機執行是沒問題的，但在遠端主機就是一直丟出Timeout Error，原來遠端主機控制Chrome訪問目標網頁的時候總是遭遇某DDoS Protection服務所阻擋，但經過一番嘗試目前仍是應對不了這個情況，耗了好幾天...於是學到了windows.navigator.webdriver\b這個參數。\n\n\n*假設Heroku APP已建立。\n\n### Add Config Vars & Buildpacks\n<p>在APP的Setting頁面，設定以下兩個環境變數：\n{% codeblock lang:sh %}\nCHROMEDRIVER_PATH = /app/.chromedriver/bin/chromedriver\nGOOGLE_CHROME_BIN = /app/.apt/usr/bin/google-chrome\n{% endcodeblock %}\n\n在APP的Setting頁面，設定以下兩個buildpack：\n{% codeblock lang:sh %}\nhttps://github.com/heroku/heroku-buildpack-google-chrome\nhttps://github.com/heroku/heroku-buildpack-chromedriver\n{% endcodeblock %}\n<p>\n![](https://i.imgur.com/qOPtW4a.png)\n\n### Code\n<p>程式的部分，Chrome driver的參數會使用到上述所設定的環境變數。\n{% codeblock lang:py %}\nimport os\nfrom selenium import webdriver\n\ndef get_chrome():\n    op = webdriver.ChromeOptions()\n    op.binary_location = os.environ.get(\"GOOGLE_CHROME_BIN\")\n    op.add_argument(\"--headless\")\n    op.add_argument(\"--disable-dev-shm-usage\")\n    op.add_argument(\"--no-sandbox\")\n\n    '''\n    # avoid detection 好孩子先不要 ^.<\n    op.add_argument('--disable-infobars')\n    op.add_experimental_option('useAutomationExtension', False)\n    op.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n    '''\n\n    return webdriver.Chrome(executable_path=os.environ.get(\"CHROMEDRIVER_PATH\"), options=op)\n{% endcodeblock %}\n\n### Deploy\n<p>然後就可以進行部署使用了，Heroku APP會需要安裝許多依賴套件而增加100+MB的使用空間。\n\n透過APP bash測試從證交所擷取上市股票代號一覽表⬇︎\n![](https://i.imgur.com/SrXtcYd.png)\n\n### Ref.\n<p>\n＊[Running ChromeDriver with Python Selenium on Heroku](https://www.andressevilla.com/running-chromedriver-with-python-selenium-on-heroku/)\n＊[Selenium 官方文件](https://selenium-python.readthedocs.io/)\n\n### Note\n<p>\n關於動態網頁資料擷取的小技巧：雖然Selenium WebDriverWait提供explicit waits可等待指定頁面元素載入，但實際上並沒有這麼順利，不過這也是讓我覺得學習web crawler有趣的地方(儘管有時候很頭疼😖)。有時候會發生指定元素確實在頁面上載入完成了，但內容卻是空空如也，又或許是我慧根不夠用不好[text_to_be_present_in_element](https://selenium-python.readthedocs.io/waits.html?highlight=WebDriverWait#explicit-waits)，試了半天還是抓不到我要的數據。哭啊，我就是要擷取內容文字咩！\b只好換個方式等待：\n\n{% codeblock lang:py %}\nfrom selenium.webdriver.support.ui import WebDriverWait\n\ndriver = get_chrome()\ndriver.get(\"{{url}}\")\nis_text = lambda driver: driver.find_element_by_css_selector('{{css_selector}}').text.strip() != ''\nWebDriverWait(driver, 30, 0.5).until(is_text)\n{% endcodeblock %}","tags":["python","web crawler","heroku","selenium","chrome driver"],"categories":["Data Science"]},{"title":"2020 Medical AI Summer Camp","url":"/medical-AI-summer-camp-2020/","content":"學校信箱每天都會收到一堆讓人想直接刪除的信，但我還是會讀完主旨再刪除(?)，畢竟偶爾還是會有不錯的資訊，例如免費的研習...和便當。<!--more-->此研習為科技部補助學校成立的AI生醫創新研究中心所舉辦，報名人數竟然多到要加開教室用視訊連線。\n\n議程：\n\n|           08/31          |                    09/01                  |\n|:------------------------:|:-----------------------------------------:|\n|    淺談機器學習與深度學習    |           雲端人工智慧在醫學影像的應用         |\n|人工智慧於生理計算之應用—訊號篇|人工智慧與自然語言處理概述—以台語在醫療服務之應用為例|\n|人工智慧於生理計算之應用—影像篇|                AWS雲端資源分享               |\n|     快速掌握「雲端運算」    |              AWS AI/ML工具與應用            |\n\n\n\b說實話我並沒有特別期待議題的深度，畢竟講者還是要考量聽眾的程度做調整，如果講演算法或公式推導應該會睡成一片吧😂&nbsp;&nbsp;&nbsp;但我覺得第一天的「人工智慧於生理計算之應用」的內容非常豐富且淺顯易懂，講者分享了將人工智慧應用於肺部CT影像病灶辨識以及睡眠狀態偵測的實務經驗，真的很感謝講師分享如此珍貴的經驗，我想這都是需要投入不少時間跟資源去研究的。\n\n而第二天竟然有AWS的市場拓展代表來介紹他們家的雲端運算服務，\b\b然後我才知道學校有加入AWS Educate，這還不光速註冊一波啊是不是😎&nbsp;&nbsp;&nbsp;聽完他們的簡報，對AWS的平台生態與產品線有較為廣泛的了解...真不愧是市佔龍頭，最後還有提到AWS的量子運算服務也已經上線了，不過就只是提一下XD 科技巨頭們的量子霸權之羅馬競技生死鬥還有得打呢。\n\n![](https://i.imgur.com/YVVX2M0.png)\n\n便當ㄏ呷，完。","tags":["big data","deep learning","cloud computing"],"categories":["Workshop"]},{"title":"Apache Kafka安裝測試","url":"/data-sci-kafka-hello-world/","content":"\b紀錄前陣子嘗試建立Kafka\b平台模擬事件串流的過程。<!--more-->模擬的情境是，假設有人感染了COVID-19，然後我們要利用Kafka Producer發佈該事件通知，使Kafka Consumer接收到訊息並顯示出來。\n\n### What is Apache Kafka?\n\b[Apache Kafka官網](https://kafka.apache.org/)：\n>Apache Kafka is an open-source <font color='red'>distributed</font> event streaming platform used by thousands of companies for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications.\n\n\b[維基中文頁面](https://zh.wikipedia.org/wiki/Kafka)：\n>Kafka最初是由領英開發，由Scala和Java編寫，於2011年初開源。該專案的目標是為處理即時資料提供一個統一、高吞吐、低延遲的平台。\n\n在Kafka中有幾個主要的概念：\n\n|          |                                               |\n|:--------:|:---------------------------------------------:|\n|Broker    |實現資料儲存的主機伺服器                           |\n|Producer  |訊息的生產者                                     |\n|Consumer  |訊息的消費者                                     |\n|Topic     |訊息的分類                                       |\n|Partition |Topic中的訊息會被分為若干Partition，以提高訊息處理效率|\n\n### Installation\n- 安裝JDK：[官網下載連結](https://www.oracle.com/tw/java/technologies/javase-downloads.html)\n- 下載Apache Kafka並解壓縮：[官網下載連結](https://kafka.apache.org/downloads)\n- 安裝kafka-python套件\n{% codeblock lang:sh %}\n$ pip install kafka-python\n{% endcodeblock %}\n\n### Get Started\n移動到解壓縮後的Kafka資料夾根目錄\n\n- 啟動Zookeeper server\n{% codeblock lang:sh %}\n$ bin/zookeeper-server-start.sh config/zookeeper.properties\n{% endcodeblock %}\n\n- 啟動Kafka server\n{% codeblock lang:sh %}\n$ bin/kafka-server-start.sh config/server.properties\n{% endcodeblock %}\n\n\n＊[Apache Zookeeper](https://zookeeper.apache.org/)是用來管理Kafka分散式叢集(Brokers)組態設定與其資源配置的服務。\n＊啟動server若顯示以下錯誤訊息：\n{% codeblock lang:sh %}\nUnrecognized VM option 'PrintGCDateStamps'\nError: Could not create the Java Virtual Machine.\nError: A fatal exception has occurred. Program will exit.\n{% endcodeblock %}\n\n參考[stackoverflow相關討論](https://stackoverflow.com/questions/36970622/kafka-unrecognized-vm-option-printgcdatestamps)，修改/bin/kafka-run-class.sh這個檔案：\n{% codeblock lang:sh %}\nif [[ \"$JAVA_MAJOR_VERSION\" -ge \"9\" ]]\n{% endcodeblock %}\n\n\b<font color='red'>將上述的if條件式內容修改為</font>\n\n{% codeblock lang:sh %}\nJAVA_MAJOR_VERSION=$($JAVA -version 2>&1 | sed -E -n 's/.* version \"([^.-]*).*/\\1/p')\n{% endcodeblock %}\n\n\n- 建立Topic\n以下指令會建立一個具有一個副本、一個分區的名稱為covid-19的Topic：\n{% codeblock lang:sh %}\n$ bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic covid-19\n{% endcodeblock %}\n\n- 確認已建立的Topic\n{% codeblock lang:sh %}\n$ bin/kafka-topics.sh --list --zookeeper localhost:2181\n{% endcodeblock %}\n\n- Producer\n{% codeblock lang:py %}\n#!usr/bin/env python3\n# coding:utf-8\n\n\nimport time\nfrom kafka import KafkaProducer\nproducer = KafkaProducer(bootstrap_servers='localhost:9092')\ncounter = 1\nwhile True:\n    msg = '[Total: ' + str(counter) + ']Someone is contracted COVID-19! Be careful!'\n    msg = msg.encode('ascii')\n    producer.send('covid-19', msg)\n    time.sleep(5)\n    counter += 1\n{% endcodeblock %}\n\n- Consumer\n{% codeblock lang:py %}\n#!usr/bin/env python3\n# coding:utf-8\n\n\nfrom kafka import KafkaConsumer\nconsumer = KafkaConsumer('covid-19')\nfor msg in consumer:\n    print(msg.value.decode('ascii'))\n{% endcodeblock %}\n\n\b\b\b可以看到Consumer都接收到了COVID-19事件通知⬇︎\n![](https://i.imgur.com/DK82jfm.gif)\n\nRef. [Hello World In Kafka Using Python](https://timber.io/blog/hello-world-in-kafka-using-python)","tags":["python","kafka","big data"],"categories":["Data Science"]},{"title":"Python分割影片為指定長度","url":"/python-video-split/","content":"人們經常在通訊軟體分享各種多媒體訊息，而影片長度或檔案大小可能會有上傳限制，只好將其分割成多個片段上傳。<!--more-->就Line而言，我查到的資訊是限制影片長度5分鐘內、檔案大小300MB以下，就能順利傳送並於聊天室中播放。短片的話自己手動分割一下就行了，但你知道的(?)，有些人分享的片段完整加總起來都數十分鐘甚至一個多小時，仔細觀察那些片段的長度竟然都不一樣，而且還有上字(XXX分享之類的)，這...還真是吃力不討好啊，我只能說祝大大一生平安🙆‍♂️。\n\n---\n\b\b還是交給程式來處理吧，指定影片分割秒數，並自動在片頭上字持續3秒做為順序標記。此範例需用到[moviepy](https://pypi.org/project/moviepy/)套件，且需事先安裝[FFmpeg](https://ffmpeg.org/)和[ImageMagick](https://imagemagick.org/script/download.php)這兩個開源軟體。\n\n{% codeblock lang:py %}\n#!/usr/bin/env python3\nimport moviepy.editor as mp\n\n\n# e.g. video_split(\"./LaplaceTW.mp4\", 300)\ndef video_split(filepath, duration):\n    video = mp.VideoFileClip(filepath).resize(width=720)\n    video_length = int(video.duration) # seconds\n    parts = int(video_length / duration)\n    remaining = video_length - (duration * parts)\n    parts = (parts + 1) if remaining > 0 else parts\n    print(\"Video Length:\", video_length, \" | Split Parts:\", parts)\n\n    start, end = 0, duration\n    for part in range(1, parts + 1):\n        title = \"Part.\" + str(part)\n        text = (mp.TextClip(title, fontsize=50, color='yellow')\n            .set_pos((\"right\", \"top\"))\n            .set_duration(3))\n\n        clip = video.subclip(start, end)\n        clip = mp.CompositeVideoClip([clip, text])\n        clip.write_videofile(title + '.mp4')\n        \n        if part == parts - 1 and remaining > 0:\n            start += duration\n            end += remaining\n        else:\n            start += duration\n            end += duration\n{% endcodeblock %}\n\n分割長時間影片 ⬇︎\n![](https://i.imgur.com/IgC7WQW.png)\n\n處理結果 ⬇︎\n![](https://i.imgur.com/XqVlcYG.gif)\n\n---\n＊若沒有安裝ImageMagick則會發生執行錯誤：[Errno 2] No such file or directory: 'unset': 'unset'\n{% codeblock lang:sh %}\nOSError: MoviePy Error: creation of None failed because of the following error:\n\n[Errno 2] No such file or directory: 'unset': 'unset'.\n\n.This error can be due to the fact that ImageMagick is not installed on your computer, \nor (for Windows users) that you didn't specify the path to the ImageMagick binary in \nfile conf.py, or that the path you specified is incorrect\n{% endcodeblock %}\n\nRef. [TextClip Doesn't work at all #1003](https://github.com/Zulko/moviepy/issues/1003)","tags":["python","moviepy","mytoolbox"],"categories":["Python"]},{"title":"COSCUP 2020！","url":"/coscup-2020/","content":"決定得很臨時，但今年不用搶票，只要填寫健康聲明書就能參加了\b\b。<!--more-->雖說COSCUP是免費參加的，但小資如我還是有個人贊助點小錢，希望往後自己每年都能參加。剛好我的三倍券也還沒想到要用在哪，於是趕緊綁定信用卡、光速訂了高鐵票和商旅，週五晚間就飛奔到台北準備參加人生第一場COSCUP😎。\n\nCOSCUP 2020官網：[https://coscup.org/2020/zh-TW](https://coscup.org/2020/zh-TW)\n>開發者 (Coders)、使用者 (Users) 和推廣者 (Promoters) 是讓自由及開放原始碼軟體發光發熱的三大支柱，這個研討會就是專為這三種人舉辦的：你可以是 A 軟體的開發者、B 軟體的推廣者、C 軟體的使用者，不論你是已經踏入自由及開放原始碼軟體領域，還是一直站在門口不知如何入門，歡迎你來參加 COSCUP — Conference for Open Source Coders, Users and Promoters!\n\n這兩天的落腳處⬇︎\n![](https://i.imgur.com/eIUe5PV.jpg)\n\nCOSCUP今年依然在台科大舉辦，我照官網所說的搭捷運到公館站，從2號出口旁沿著舟山路行走至鹿鳴堂，再右轉欒樹道走到底，這才抵達台科大...步行約10分鐘，熱到爆炸。\n\nBadge⬇︎\n![](https://i.imgur.com/7Sy02Dw.jpg)\n\n主議程會場⬇︎\n![](https://i.imgur.com/b80Zd26.jpg)\n\n我在行前有根據議程表稍微規劃了想聽的議程，這次也和多年不見的友人約好在COSCUP碰面，時光飛逝相當有感...不過中午外出用餐回來沒趕上唐鳳政委主講的議題，畢竟現在疫情仍未趨緩，各個議程都是有人數管制的，只好在外頭透過直播觀看天才挨踢大臣的演講。\n\n第一天印象最深刻的就是交大陳志成教授所主講，關於他們的團隊所開發的[free5GC](https://github.com/free5gc/free5gc)，為世界第一套符合國際標準的開放原始碼5G核心網路。\n![](https://i.imgur.com/vxqXSla.jpg)\n![](https://i.imgur.com/RRdmuOt.jpg)\n\n第二天我只能參加上午的議題，然後就要趕搭高鐵回去了，但仍是參加了很棒的兩場議程，其一是Vue的作者、大神[Evan You](https://twitter.com/youyuxi)主講關於Vue第三版的開發過程所涉及的技術難點與設計取捨，雖然受疫情影響是採遠端連線會議，但這依然是令人興奮的議程！有趣的是，在議程最後的QA時間，有人問了Evan You這樣的一個問題：\n\n>請問Vue和React有什麼不同呢？\n\n眾人不禁哄堂大笑😂，Evan You也無奈地笑了笑，但他還是相當耐心地解釋、提出他的看法。\n\n議程結束後，我又立刻趕到另一個會場參加關於Pi Thermal Camera的議題，因為之前用Adafruit AMG8833 Module做過低解析度的熱成像儀，所以個人是相當期待這場議題的，我打算之後購買更高解析度的模組來進行進階實作。\n\n從Mozilla Taiwan Community的攤位獲得了帥氣的Firefox胸章！⬇︎\n![](https://i.imgur.com/3XN2maN.jpg)\n\n\b\b\b收集到了好多貼紙\b呀🙆‍♂️ ⬇︎\n![](https://i.imgur.com/7Jq8Gn9.jpg)\n\n完。","tags":["coscup"],"categories":["Workshop"]},{"title":"Arduino UNO：Coffin Dance","url":"/arduino-uno-r3-buzzer-astronomia/","content":"其實原曲名叫Astronomia啊，只是被幾位知名舞者(?)給抬出名了。<!--more-->看到Arduino範例程式的toneMelody發出了一段像是gameover的音效，我就想讓蜂鳴器播放這段相當知名的迷因歌曲🤣\n\n蜂鳴器分為有(震盪)源蜂鳴器，和無(震盪)源蜂鳴器，有源蜂鳴器就是高電位逼逼叫，低電位不叫，就這樣。而無源的蜂鳴器就好玩了，可以控制其聲音頻率而產生音調高低。\n\n### Music Scales\n參考範例程式中所引入的pitches.h檔案內容：\n{% codeblock lang:c %}\n#define NOTE_B0  31\n#define NOTE_C1  33\n#define NOTE_CS1 35\n.\n.\n.\n#define NOTE_C4  262\n#define NOTE_CS4 277\n#define NOTE_D4  294\n.\n.\n.\n{% endcodeblock %}\n這個.h檔即是定義[唱名](https://zh.wikipedia.org/wiki/%E5%94%B1%E5%90%8D)所對應的聲音頻率(Hz)，其中C4就是鋼琴琴鍵的中央C，亦即C大調的低音Do。如此一來只要有簡譜，像我這樣對樂理沒輒的人也能教Arduino怎麼演奏音樂了呢。\n\n### LCD Screen\n然後我想用個LCD在旁邊顯示播放的曲名，參考[GTW的教學](https://blog.gtwang.org/iot/ywrobot-arduino-lcm-1602-iic-v1-lcd-display)解決了我在編譯時發生的找不到函式庫的問題。要使用HD44780U 1602 LCD須安裝[LiquidCrystal library](https://bitbucket.org/fmalpartida/new-liquidcrystal/downloads/)，下載後解壓縮到Arduino的libraries資料夾底下即可。但這邊又有個小問題：\n{% codeblock lang:shell %}\nArduino:1.8.13 (Mac OS X), 開發板:\"Arduino Uno\"\n/Users/nick/Documents/Arduino/libraries/LiquidCrystal/I2CIO.cpp:35:10: fatal error: ../Wire/Wire.h: No such file or directory\n #include <../Wire/Wire.h>\n{% endcodeblock %}\n\n\b這就要找到剛剛解壓縮的資料夾中的I2CIO.cpp，將#include <../Wire/Wire.h>改為#include <Wire.h>。\n\n*1602 LCD的pin腳說明與像素點控制等教學：[Interfacing 16×2 Character LCD Module with Arduino](https://lastminuteengineers.com/arduino-1602-character-lcd-tutorial/)\n\n### Play Music!\n經過強迫症似的反覆聆聽和調整節拍，我覺得很接近原曲了😆\n{% codeblock lang:c %}\n#include <LiquidCrystal_I2C.h>\n#include \"pitches.h\"\n\n#define PIN_BUZ 8\n\n// Ref. https://youtu.be/miwoTFkiIfQ\nint melody[] = {\n    NOTE_AS4, NOTE_AS4, NOTE_AS4, NOTE_AS4,\n    NOTE_D5, NOTE_D5, NOTE_D5, NOTE_D5,\n    NOTE_C5, NOTE_C5, NOTE_C5, NOTE_C5,\n    NOTE_F5, NOTE_F5, NOTE_F5, NOTE_F5,\n    NOTE_G5, NOTE_G5, NOTE_G5, NOTE_G5, NOTE_G5, NOTE_G5,\n    NOTE_G5, NOTE_G5, NOTE_G5, NOTE_G5, NOTE_G5, NOTE_G5,\n    NOTE_C5, NOTE_AS4, NOTE_A4, NOTE_G4,\n    NOTE_G4, 0, NOTE_G4, NOTE_D5, NOTE_C5, NOTE_AS4, NOTE_A4, NOTE_A4, NOTE_A4,\n    NOTE_C5, NOTE_AS4, NOTE_A4, NOTE_G4, NOTE_G4, NOTE_G4,\n    NOTE_AS5, NOTE_A5, NOTE_AS5, NOTE_A5, NOTE_AS5, NOTE_G4,\n    NOTE_AS5, NOTE_A5, NOTE_AS5, NOTE_A5, NOTE_AS5, NOTE_G4\n};\n\n// note durations: 4 = quarter note, 8 = eighth note, etc.:\nbyte noteDurations[] = {\n    5, 5, 5, 5,\n    5, 5, 5, 5,\n    5, 5, 5, 5,\n    5, 5, 5, 5,\n    5, 5, 5, 5, 5, 5,\n    5, 5, 5, 5, 5, 5,\n    5, 5, 5, 5,\n    5, 5, 5, 5, 3, 3, 3, 5, 5,\n    3, 5, 5, 5, 5, 5,\n    5, 5, 5, 5, 5, 3,\n    5, 5, 5, 5, 5, 3\n};\n\n// Set the pins on the I2C chip used for LCD connections:\n//                    addr, en,rw,rs,d4,d5,d6,d7,bl,blpol\nLiquidCrystal_I2C lcd(0x27, 2, 1, 0, 4, 5, 6, 7, 3, POSITIVE);\n\nvoid setup() {\n    lcd.begin(16, 2); // lcd initial\n    lcd.backlight(); // turn on the backlight\n    lcd.setCursor(0, 0);\n    lcd.print(\"Play:Astronomia\");\n    lcd.setCursor(0, 1);\n    lcd.print(\"(Coffin Dance)\");\n}\n\nvoid loop() {\n    // iterate over the notes of the melody:\n    for (int thisNote = 0; thisNote < 59; thisNote++) {\n\n        // to calculate the note duration, take one second divided by the note type.\n        //e.g. quarter note = 1000 / 4, eighth note = 1000/8, etc.\n        int noteDuration = 1000 / noteDurations[thisNote];\n        tone(PIN_BUZ, melody[thisNote], noteDuration);\n\n        // to distinguish the notes, set a minimum time between them.\n        // the note's duration + 30% seems to work well:\n        int pauseBetweenNotes = noteDuration * 1.30;\n        delay(pauseBetweenNotes);\n        // stop the tone playing:\n        noTone(PIN_BUZ);\n    }\n    delay(3000);\n}\n{% endcodeblock %}\n\n\b\b感謝[這位大叔的彈奏教學](https://youtu.be/miwoTFkiIfQ)。\n{% youtube wqYNDwmzXDE%}","tags":["IoT","arduino"],"categories":["Arduino"]},{"title":"Arduino UNO：RGB模組、PWM、負數","url":"/arduino-uno-r3-rgb-module/","content":"What happens if we give a negative value to analogWrite() ?<!--more-->\b當我看了learning kit提供的、關於RGB模組的範例，在輸出給RGB的數值變化過程中是有出現負值的，於是我困惑了很久，想弄明白analogWrite()如何處理負數。\n\n### PWM\nPWM = Pulse Width Modulation，脈衝寬度調變，是一種利用數位脈衝訊號模擬類比訊號的技術，如何模擬呢？我們知道數位訊號只有0與1兩種狀態，也就是低電位與高電位，\b\b而在頻率不變的狀態下，改變工作週期大小，使整體平均電壓值上升或下降來做到控制或節能的行為，這就是PWM。\b白話點說呢，就是快速的開、關、開、關、開、關...以LED燈來說，就是快到肉眼無法察覺的程度，當我們調整工作週期中\b開和關的持續時間比例，若開的時間較長，那麼LED燈看起來就比較亮，反之則較暗。\n\n在Arduino中可用PWM模擬0~5v之間的電壓。圖片連結自[arduino.cc](https://www.arduino.cc/en/tutorial/PWM)⬇︎\n![](https://www.arduino.cc/en/uploads/Tutorial/pwm.gif)\n\n### RGB Module\n我手邊的是共陽極RGB模組，也就是其4根接腳為VCC、R、G、B。\n![](https://i.imgur.com/R6BxKqA.jpg)\n\nRGB模組範例程式：\n此範例使用有PWM功能的digital I/O pin 9 ~ 11，原始範例是有對這3個腳位設定pin mode，但[Arduino官方說analogWrite()不需要設定pin mode喔](https://www.arduino.cc/reference/en/language/functions/analog-io/analogwrite/)：\n>You do not need to call pinMode() to set the pin as an output before calling analogWrite().\nThe analogWrite function has nothing to do with the analog pins or the analogRead function.\n\n\b\b\b{% codeblock lang:c %}\n#define PIN_G 9\n#define PIN_B 10\n#define PIN_R 11\n\nvoid setup() {\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    for (int i = 255; i > 0; i--) {\n        int blue = 128 -i;\n        //twos_complement(blue);\n\n        analogWrite(PIN_R, i);\n        analogWrite(PIN_B, blue); // 127 -> 0 -> 127 \n        analogWrite(PIN_G, 255 - i);\n\n        delay(50);\n    }\n\n    for (int i = 0; i < 255; i++) {\n        int blue = 128 -i;\n        //twos_complement(blue);\n\n        analogWrite(PIN_R, i); \n        analogWrite(PIN_B, blue); // 128 -> 0 -> 126 \n        analogWrite(PIN_G, 255 - i);\n\n        delay(50);\n    }\n}\n\nvoid twos_complement(int binary) {\n    if (binary < 0) Serial.println((~binary) + 1);\n    else Serial.println(binary);\n}\n{% endcodeblock %}\n![](https://i.imgur.com/WQXvn2G.gif)\n\n### analogWrite()\n從上面的範例程式可以看到，analogWrite()寫入RGB module的B pin值，也就是for loop中的變數blue，它是會出現負值的。但analogWrite()只接受0 ~ 255之間的值呢？？？後來我找到[一篇文章](https://techexplorations.com/blog/arduino/blog-what-happens-if-you-give-a-negative-pwm-value-to-analogwrite/)說Arduino使用二補數來處理負數，於是我寫了twos_complement()來計算二補數\b並print出實際上寫入B pin的值。\n\n### Ref.\n[https://www.arduino.cc/en/tutorial/PWM](https://www.arduino.cc/en/tutorial/PWM)\n[http://wiki.csie.ncku.edu.tw/embedded/PWM](http://wiki.csie.ncku.edu.tw/embedded/PWM)\n[https://www.arduino.cc/reference/en/language/functions/analog-io/analogwrite/](https://www.arduino.cc/reference/en/language/functions/analog-io/analogwrite/)\n[https://techexplorations.com/blog/arduino/blog-what-happens-if-you-give-a-negative-pwm-value-to-analogwrite/](https://techexplorations.com/blog/arduino/blog-what-happens-if-you-give-a-negative-pwm-value-to-analogwrite/)","tags":["IoT","arduino"],"categories":["Arduino"]},{"title":"正確理解YOLO的辨識準確率","url":"/data-sci-yolo-accuracy/","content":"這幾天媒體報導了[YOLOv4](https://arxiv.org/abs/2004.10934)的相關新聞，提到其為中研院研究團隊與俄羅斯開發者所共同研發，而這全世界最快最準的物體偵測演算法，其平均準確率為43.5%，於是這43.5%的準確率迅速引來許多不明就裡的人留言批評。<!--more-->不懂沒有關係，我們可以先查證，再提出質疑，而非只是「我覺得這準確率有夠低」就輕率地批評指責(中研院難道是能隨便誇大其詞的研究機構嗎？)，但你可能連state-of-the-art意味什麼都不明白。這對無私貢獻的[Open Source](https://zh.wikipedia.org/wiki/%E9%96%8B%E6%BA%90%E8%BB%9F%E9%AB%94)開發者一點都不公平，真是站著說話不腰疼、躺著留言不費勁。\n\n## 什麼是YOLO?\n<p>[YOLO官網](https://pjreddie.com/darknet/yolo/)是這麼介紹它自己的：\n>You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Pascal Titan X it processes images at 30 FPS and has a mAP of 57.9% on COCO test-dev. (YOLO是最先進的即時物體偵測系統，在Pascal Titan X GPU上以30 FPS的速度處理影像，於COCO測試開發資料集中的mAP為57.9%)\n\n然後我們可能又會疑惑：FPS? COCO? mAP? 別著急，多理解一下物體偵測。\n\n電腦是如何進行物體偵測？一般做法是透過各種選擇性搜索演算法(selective search)，偵測、分割出影像中可能有物體存在的區域(region proposal)，那麼沒有物體存在的區域就不需要進行無效的運算，也能加快處理速度，接著再對這些可能有物體存在的區域進行辨識分類。如此先搜索region proposal再進行辨識的處理方式稱為Two Stage(e.g. R-CNN)。\n![](https://i.imgur.com/O62Ncev.png)\n\n但這有個潛在問題，假設系統偵測出影像中有數百個甚至上千個region proposal，那麼就得進行上千次的辨識運算...個人電腦即便有高階GPU亦可能做不到即時運算，更遑論行動裝置。\n<p>圖片連結自[https://github.com/ouyanghuiyu/darknet_face_with_landmark](https://github.com/ouyanghuiyu/darknet_face_with_landmark)⬇︎\n![](https://raw.githubusercontent.com/ouyanghuiyu/darknet_face_with_landmark/master/test_imgs/selfie.jpg)\n\n於是我們有了One Stage(e.g. YOLO)，物體偵測和辨識一氣呵成，這樣的做法能大幅提升處理速度。不過有一好沒兩好，要速度快你就得在準確率做點取捨，因此整體辨識準確率相較Two Stage來得差一些，但One Stage在許多應用上仍是可接受範圍內，兩種作法各有其優勢，端看需求。\n![](https://i.imgur.com/OdWNkUk.png)\n\n回到YOLO，自從2015年發佈v1發展至今，最新版本為今年4月底所發佈的v4，處理速度簡直快到沒朋友，但YOLO的創造者[Joseph Redmon](https://pjreddie.com/)今年二月[於推特宣佈退出電腦視覺研究領域](https://twitter.com/pjreddie/status/1230524770350817280)，當時引起相當大的討論，多少人引頸期盼YOLO的下個版本，Joseph Redmon表示自己的工作對人類社會的衝擊性實在太大了，即使熱愛電腦視覺的研究工作，但其終究無法忽視自己的研究成果在軍事科技應用以及個人隱私方面可能導致的問題。因此YOLOv4為俄羅斯開發者、YOLOv3的實現 — Darknet作者[Alexey Bochkovskiy](https://twitter.com/alexeyab84)與中研院資科所所長Hong-Yuan Liao及博士後研究員Chien-Yao Wang等三人基於後兩位研發的CSPNet，對YOLO的最新研究成果。而Joseph Redmon也[更新](https://github.com/pjreddie/darknet#darknet)了YOLOv4的論文與原始碼連結，顯示YOLOv4為官方所認可的後繼版本。\n\n## 什麼是FPS?\n<p>FPS就是影格率或是經常聽到的幀數，[維基百科](https://zh.wikipedia.org/wiki/%E5%BD%B1%E6%A0%BC%E7%8E%87)就有寫了沒啥好說：\n>影格率是用於測量顯示影格數的量度。測量單位為「每秒顯示影格數」(Frame per Second，FPS)或「赫茲」，一般來說FPS用於描述影片、電子繪圖或遊戲每秒播放多少影格。\n\n## 什麼是COCO資料集？\n<p>[COCO資料集(Common Objects in Context)](https://cocodataset.org/)是微軟所發佈、擁有33萬張影像的大型開源資料集：\n>COCO is a large-scale object detection, segmentation, and captioning dataset. COCO has several features:\n- Object segmentation\n- Recognition in context\n- Superpixel stuff segmentation\n- 330K images (>200K labeled)\n- 1.5 million object instances\n- 80 object categories\n- 91 stuff categories\n- 5 captions per image\n- 250,000 people with keypoints\n\n## 什麼是mAP？\n<p>mAP的\"m\"代表\"mean\"，簡而言之，AP(average precision)是用來評估物體識別模型效能表現的指標之一。我參考維基百科[Precison and Recall](https://en.wikipedia.org/wiki/Precision_and_recall)頁面的說明圖片，重新繪製了下方這張圖(原圖為直向)來說明。\n*關於Precision and Recall可參考：[心理學和機器學習中的 Accuracy、Precision、Recall Rate 和 Confusion Matrix](https://medium.com/@ChingTien/529d18abc3a)\n![](https://i.imgur.com/KgFbe8Y.png)\n\n假設我現在要從一些含有各種物體的影像中找出狗的圖片，那麼上圖左側深灰色矩形代表狗的圖片集合，右側淺灰色影像代表其他物體的圖片集合，中間的大圓圈則是被判定為狗的圖片的集合，其中包含真的為狗的圖片(分類正確)以及不是狗的圖片(分類錯誤)。所以precision就代表在「所有被判定為狗的圖片」之中有多少**比例**是「狗的圖片」。\n\n至於average precision的計算則是將precision加總後取平均值：\n\n|判定為狗且真的為狗的圖片數 |  判定為狗的圖片數 |Precision|\n|:---------------------:|:--------------:|:-------:|\n|1                     |1                |1        | \n|1                     |2                |1/2      |\n|1                     |3                |1/3      |\n|2                     |4                |2/4      |\n|2                     |5                |2/5      |\n|...                   |...              |...      |\n\n又物體識別會有許多類別，以COCO資料集而言就有80種object categories，mean average precision便是所有類別AP加總的平均值。\n\n＊COCO資料集究竟有多少個類別？網路上有人說80種，也有人說91種，合理推測是將object categories跟stuff categories搞混了，這兩種分類的差異我也是看了某篇論文的摘要才明白，根據[COCO-Stuff: Thing and Stuff Classes in Context](https://arxiv.org/abs/1612.03716)所述：\n>Semantic classes can be either things (objects with a well-defined shape, e.g. car, person) or stuff (amorphous background regions, e.g. grass, sky).\n\nobject類就是能明確界定形狀的**物體**，例如汽車、人。stuff類則是沒有特定形狀或邊界的**背景區域**，例如草地、天空。懂！\n\n## 效能評估指標\n<p>根據COCO資料集的效能評估頁面所述：\n>Average Precision (AP):\n- AP：AP at IoU=.50:.05:.95 (primary challenge metric)\n- AP IoU=.50：AP at IoU=.50 (PASCAL VOC metric)\n- AP IoU=.75：AP at IoU=.75 (strict metric)\n\b\n\n從這段敘述可以確定COCO資料集效能評估指標的AP指的就是mAP：\n>AP is averaged over all categories. Traditionally, this is called \"mean average precision\" (mAP). We make no distinction between AP and mAP (and likewise AR and mAR) and assume the difference is clear from context.\n\n說到這兒又得理解一個跟AP有關係的詞：IoU(Intersection over Union，並交比)，簡而言之，物體識別的IoU為物體標記範圍與系統偵測範圍這兩個集合的交集和並集之間的比例，有請台北市立動物園的水豚君幫忙示範一下：\n![](https://i.imgur.com/w7sc0Vc.jpg)\n假設紅框為影像的原始標記邊界範圍\b\ba1，黃框為YOLO所偵測的物體邊界範圍a2，那麼IoU則為a1與a2的**交集**除以a1與a2的**聯集**。\n\n因此以COCO資料集的AP指標而言，可以看到其IoU並非一個固定值，而是「.50:.05:.95」，意思是IoU共有{0.5, 0.55,...0.95}10個閾值，以這10個標準做判定、計算AP再取平均，而AP50\b(IoU=.50)或AP75(IoU=.75)則是傳統的評估方式。\n\n## 平均準確率\n<p>說了一堆，可以來看底下這張效能表現比較圖了。\n\n我直接連結[Darknet](https://github.com/AlexeyAB/darknet)其GitHub頁面的圖片⬇︎\n![](https://user-images.githubusercontent.com/4096485/82835867-f1c62380-9ecd-11ea-9134-1598ed2abc4b.png)\n\nYOLOv4的效能表現是相當突出的，在FPS為90的時候，v4的AP比v3多了10%，要不光看它和YOLOv3那條線之間有好大一段垂直距離也不難理解。對於一件事情的難易度若是沒有概念，只看43.5%這個數字能看出什麼呢？\n\nYOLOv4論文摘要：\n>We use new features: WRC, CSP, CmBN, SAT, Mish activation, Mosaic data augmentation, CmBN, DropBlock regularization, and CIoU loss, and combine some of them to achieve state-of-the-art results: 43.5% AP (65.7% AP50) for the MS COCO dataset at a realtime speed of ~65 FPS on Tesla V100.\n\n辨識無數的物體要**即時**又要**快狠準**你說容易嗎？\n![](https://i.imgur.com/NG4nEoT.png)\n{% youtube 1_SiUOYUoOI %}\n\n## Research Papers of YOLO\n<p>\n- [You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640)\n- [YOLO9000: Better, Faster, Stronger](https://arxiv.org/abs/1612.08242)\n- [YOLOv3: An Incremental Improvement](https://arxiv.org/abs/1804.02767)\n- [YOLOv4: Optimal Speed and Accuracy of Object Detection](https://arxiv.org/abs/2004.10934)","tags":["deep learning","computer vision","yolo","darknet"],"categories":["Data Science"]},{"title":"Arduino UNO R3","url":"/arduino-uno-r3-learning-kit/","content":"\b\b終於有時間玩玩買來很久的learning kit。開發版種類繁多，但除了修課玩過Ti OMAP系列的PandaBoard、Devkit8000，也就自己買的樹莓派3B+了，<!--more-->\b\b『這都2020了還沒玩過Arduino，豈不是要給人看笑話了😝』就這麼想著的某天便光速下單買來了套件組合準備試玩。\n\n![](https://i.imgur.com/jWi2s0M.jpg)\n\n先下載[Arduino IDE](https://www.arduino.cc/en/Main/Software)，將Arduino透過USB接上PC，設置好USB連接埠就可以開始玩了，寫段程式碼來測試看看。<br>\n序列埠輸出要先用[Serial.begin()](https://www.arduino.cc/reference/en/language/functions/communication/serial/begin/)方法初始化、設定baud rate⬇︎\n![](https://i.imgur.com/PPlSksQ.png)\n![](https://i.imgur.com/OEk9ppo.png)\n\nArduino的程式架構基本上就是setup()跟loop()兩個函式，用來執行初始化和持續執行的動作，經過編譯後會整合為main()函式。[Arduino維基頁面](https://zh.wikipedia.org/wiki/Arduino)寫著其IDE是源自Processing程式語言，哈！想起大三時曾經修過清大MOOCs\b的玩電玩學程式課程，當時就是使用這有趣的語言，難怪有種熟悉感🤣\n\n環境設置完成，使用幾個LED來測試、學習Arduino程式編寫：\n\n### LED Control\n<br>\n![](https://i.imgur.com/iKiu4BM.png)\n我將PIN 13設為輸出，因此板子上的LED也會跟著閃爍。\n![](https://i.imgur.com/AB5h1WK.gif)\n\n### Traffic Light\n使用黃綠紅3顆LED模擬紅綠燈。\n{% codeblock lang:c %}\n#define PIN_LED_G 2\n#define PIN_LED_Y 3\n#define PIN_LED_R 4\n\nvoid setup() {\n  pinMode(PIN_LED_R, OUTPUT);\n  pinMode(PIN_LED_G, OUTPUT);\n  pinMode(PIN_LED_Y, OUTPUT);\n}\n\nvoid loop() {\n  digitalWrite(PIN_LED_G, HIGH);\n  delay(3000);\n  digitalWrite(PIN_LED_G, LOW);\n\n  digitalWrite(PIN_LED_Y, HIGH);\n  delay(1000);\n  digitalWrite(PIN_LED_Y, LOW);\n\n  digitalWrite(PIN_LED_R, HIGH);\n  delay(3000);\n  digitalWrite(PIN_LED_R, LOW);\n}\n{% endcodeblock %}\n\n![](https://i.imgur.com/rcmlVTs.gif)\n\n### Switch Control\n以按鍵開關控制LED：若偵測到按鍵開關的狀態為HIGH(按下)則使PIN_LED狀態亦為HIGH。\n{% codeblock lang:c %}\n#define PIN_LED 7\n#define PIN_SWITCH 8\n\nvoid setup() {\n  pinMode(PIN_SWITCH, INPUT);\n  pinMode(PIN_LED, OUTPUT);\n}\n\nvoid loop() {\n  int switch_status = digitalRead(PIN_SWITCH);\n  if(switch_status == HIGH){\n    digitalWrite(PIN_LED, HIGH);\n  }\n  else{\n    digitalWrite(PIN_LED, LOW);\n  }\n}\n{% endcodeblock %}\n\n![](https://i.imgur.com/iZzRafD.gif)\n\n### Light Ticker\nEmbedded System的資源都是有限的，UNO R3 Digital I/O僅有13個port，又RX/TX佔了0和1兩個port，所以實際上能用的也就11個port，彌足珍貴呀😌&nbsp;&nbsp;當遇到需要控制多個LED的情況，例如模擬跑馬燈，讓每顆LED都佔用一個port實在太浪費，而此時便是74HC595位移暫存器派上用場的時候，只要佔用Arduino 3個port就能控制74HC595的8個port，超棒der。\n![](https://i.imgur.com/hpNCaiM.jpg)\n關於74HC595詳細的說明與接線可參考[佑來了老師的教學影片](https://www.youtube.com/watch?v=KKdNk5lne50)，他的神解釋相當通俗易懂😆\n\n- 直白的寫法：\n雖然程式碼長了點，但我覺得這是容易理解其運作的寫法。\n{% codeblock lang:c %}\n#define PIN_DATA 2\n#define PIN_STORE 3\n#define PIN_SHIFT 4\n\nvoid setup() {\n  pinMode(PIN_DATA, OUTPUT);\n  pinMode(PIN_SHIFT, OUTPUT);\n  pinMode(PIN_STORE, OUTPUT);\n}\n\nvoid loop() {\n  // left --> right\n  for(int i=7; i>=0; i--){\n    digitalWrite(PIN_STORE, LOW);\n    for(int j=0; j<8; j++){\n      if(j == i){ light_up(); }\n      else{ light_down(); }\n    }\n    digitalWrite(PIN_STORE, HIGH);\n    delay(200);\n  }\n  // right --> left\n  for(int i=0; i<8; i++){\n    digitalWrite(PIN_STORE, LOW);\n    for(int j=0; j<8; j++){\n      if(j == i){ light_up(); }\n      else{ light_down(); }\n    }\n    digitalWrite(PIN_STORE, HIGH);\n    delay(200);\n  }\n}\n\nvoid light_up() {\n  digitalWrite(PIN_SHIFT, LOW);\n  digitalWrite(PIN_DATA, 1);\n  digitalWrite(PIN_SHIFT, HIGH);\n}\n\nvoid light_down() {\n  digitalWrite(PIN_SHIFT, LOW);\n  digitalWrite(PIN_DATA, 0);\n  digitalWrite(PIN_SHIFT, HIGH);\n}\n{% endcodeblock %}\n\n- 簡潔的寫法：\n使用[shiftOut()](https://www.arduino.cc/reference/en/language/functions/advanced-io/shiftout/)方法來推送8-bit的數據，由參數bit_order來控制讀取順序，MSBFIRST為由左至右，LSBFIRST則相反。我自定義了light_ticker()函式，接收bit_order參數來控制跑馬燈方向，所以loop()裡頭僅有兩行code。\n{% codeblock lang:c %}\n#define PIN_DATA 2\n#define PIN_STORE 3\n#define PIN_SHIFT 4\n\nvoid setup() {\n  pinMode(PIN_DATA, OUTPUT);\n  pinMode(PIN_SHIFT, OUTPUT);\n  pinMode(PIN_STORE, OUTPUT);\n}\n\nvoid loop() {\n  light_ticker(MSBFIRST);  // left  --> right\n  light_ticker(LSBFIRST);  // right --> left\n}\n\nvoid light_ticker(bool bit_order) {\n  byte num;\n  for(int i=0; i<8; i++){\n    num =0;\n    digitalWrite(PIN_STORE, LOW);\n    bitSet(num, i);\n    shiftOut(PIN_DATA, PIN_SHIFT, bit_order, num);\n    digitalWrite(PIN_STORE, HIGH);\n    delay(200);\n  }\n}\n{% endcodeblock %}\n\n![](https://i.imgur.com/dhVYF1i.gif)\n\n### Notes\n[Arduino - Data Types - int](https://www.arduino.cc/reference/en/language/variables/data-types/int/)\n[Arduino - Data Types - byte](https://www.arduino.cc/reference/en/language/variables/data-types/byte/)","tags":["IoT","arduino"],"categories":["Arduino"]},{"title":"CIFAR-10分類任務的辨識準確率","url":"/data-sci-vgg-cifar10/","content":"對DL初學者而言，最常用來測試的大概就是MNIST跟CIFAR-10\b這兩個數據集了。或許對大神們來說不過都是些玩具，但我認為CIFAR-10不只是個toy dataset，相較於MNIST那樣使用MLP就能輕易達到近乎99%辨識準確率的灰階影像，CIFAR-10不像\"Hello World!\"這麼容易吧？🤨<!--more-->\n\n關於[CIFAR-10數據集](https://www.cs.toronto.edu/~kriz/cifar.html)，像我這樣略懂略懂的人就不贅言了，網路上介紹CIFAR-10的文章很多。不過，當我爬了許多文章之後，大致上都是介紹數據集和使用簡單的CNN來測試而已(準確率約70%)，如何對現有模型結構優化並提升CIFAR-10準確率還是沒頭緒，雖然可以直接載入Keras內建的預訓練模型，例如VGG-16、ResNet-50，但我認為那樣做沒啥意思，根本上還是沒搞懂，也像是大砲打小鳥。\n\n## Keras Sample Code\n<p>\n看一下[Keras的範例程式](https://keras.io/examples/cifar10_cnn/)，根據頁面說明，該範例於訓練50 epochs後達到79%的驗證準確率。實際訓練了100 epochs也差不多。\n\n- Model Summary\n![](https://i.imgur.com/mgSpvB8.png)\n\n- Train History\n![](https://i.imgur.com/14YO3XH.png)\n\n## More Optimization\n就Keras範例來說，我嘗試以相同結構增加其網路深度，驗證準確率有得到些微提升(約82%)，但持續盲目地加深網路卻會造成反效果。後來我找到了[Jason Brownlee博士的教學](https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/)，那是一個很棒的tutorial，嘗試對模型結構進行優化後，訓練結果在測試數據集取得89%的準確率(Train / Test : 94.60% / 89.35%)。\n\n- Model Summary\n![](https://i.imgur.com/VxnAUMG.png)\n\n- Train History\n![](https://i.imgur.com/WzberYE.png)\n\n## Fractional Max-Pooling\n\b\b在優化了模型結構後，測試準確率依然無法突破90%，因此我搜尋了state-of-the-art on CIFAR-10，看看大神們超脫凡俗的思路究竟是如何突破問題。於是我[仔細閱讀了Fractional Max-Pooling這篇論文](https://laplacetw.github.io/study-fractional-max-pooling)，並實際應用到我的模型訓練，儘管我沒有使用和原始論文實驗中同樣深的網路結構，依然在測試數據集的準確率達到了93%(Train / Test : 97.94% / 93.55%)。順帶一提，該模型在我的GTX 1660 Super訓練600 epochs需耗費30個小時左右。\n\n關於Fractional Max-Pooling的實現，TensorFlow已有內建，而Keras可以利用Lambda來引入模型中使用：\n{% codeblock lang:py %}\ndef frac_max_pool(x):\n    return tf.nn.fractional_max_pool(x, [1.0, 1.41, 1.41, 1.0], pseudo_random=True, overlapping=True)[0]\n\nmodel.add(Lambda(frac_max_pool))\n{% endcodeblock %}\n\n- Model Summary\n![](https://i.imgur.com/IW0Z2VC.png)\n\n- Train History\n![](https://i.imgur.com/mLV3eVI.png)\n\n## Comparison\n對參數量和模型大小做個比較：\n\n|            | VGG-16/VGG-19 |VGG-like + FMP|\n|:----------:|:-------------:|:------------:|\n|total params|10M+           |1.5M          |\n| model size |200+ MB        |12.4 MB       |\n\n## Source Code\n<p>\n[https://github.com/laplacetw/vgg-like-cifar10](https://github.com/laplacetw/vgg-like-cifar10)\n\n＊2020/12/07 發現被[PapersWithCode](https://paperswithcode.com/paper/fractional-max-pooling)社群收錄了。","tags":["keras","deep learning","computer vision","cifar-10"],"categories":["Data Science"]},{"title":"翻譯：Fractional Max-Pooling","url":"/study-fractional-max-pooling/","content":"作者：Benjamin Graham\n原文：[https://arxiv.org/abs/1412.6071](https://arxiv.org/abs/1412.6071)\n<!--more-->\n### 摘要\n卷積網路幾乎總是包含若干特徵空間取樣(pooling)的形式，通常使用α x α max-pooling(α = 2)。最大取樣作用於卷積網路的隱藏層，以整數倍乘因子α來縮減隱藏層的大小。而當你拋棄了75%的數據所獲得的驚人副產物是—在網路中建立了一定程度對於平移與彈性形變的不變性。然而，如果你只是交替使用卷積層與最大取樣，則效能表現將會受限於特徵空間的快速縮減與取樣區域不相交的特性。因此，我們制訂了分數形式的最大取樣，允許α採用非整數值。分數階最大取樣是隨機的，因為構建合適的取樣區域有許多不同的方法。我們發現分數階最大取樣的形式減少了許多數據集的過擬合現象。例如，我們改善了CIFAR-100目前最先進的技術，甚至沒使用隨機去活化(dropout)。\n\n### 卷積神經網路\n\b卷積網路被使用來解決影像辨識問題，主要由兩種類型的分層結構組成：\n- 卷積濾波層\n- 若干形式的空間取樣，例如最大取樣(max-pooling)\n\n聚焦於改善卷積層的研究造就了豐富的技術，例如dropout [[10]](#參考文獻)、DropConnect [[12]](#參考文獻)、deep networks with many small filters [[2]](#參考文獻)、large input layer filters for detecting texture [[5]](#參考文獻)以及deeply supervised networks [[6]](#參考文獻)。\n\n相較之下，不起眼的取樣操作已經被逐漸忽略，長期以來2 × 2 max-pooling(MP2-pooling)已成為構建卷積神經網路的默認選項。MP2-pooling之所以受歡迎有許多原因：執行快速、能迅速縮減隱藏層的大小、對於平移與彈性形變有一定程度的不變性。然而，取樣區域的不相交特性可能限制其泛化能力。此外，由於MP2 pooling如此迅速地縮減了隱藏層的大小，因此需要透過堆疊連續的卷積層，以構建真正的深度網路 [[7, 9, 11]](#參考文獻)。有兩種方法已經被提出來解決此問題：\n- 使用3 x 3取樣區域搭配步長2(strides = 2)的重疊取樣 [[5]](#參考文獻)\n- 隨機取樣，即以大小偏差的取樣形式代替在每個取樣區域選擇最大值的動作 [[13]](#參考文獻)\n\n但是，這兩種技術仍將隱藏層大小縮減了兩倍。這令人不禁想問，是否能有更和緩的方法來有效地應用特徵空間取樣。如果取樣只讓隱藏層大小縮減$ \\sqrt 2 $倍，那麼我們在構建卷積神經網路時能使用的取樣層數便能翻兩倍。每個取樣層都有機會以不同尺度來查看輸入影像，以正確的尺度查看影像，應該能更容易地辨識出線索特徵，並將物件標記為特定類別。\n\n因此，本文的重點是最大取樣的一種特殊形式，我們稱之為分數階最大取樣(Fractional Max-Pooling, FMP)， FMP的想法是，將影像的特徵空間尺寸縮小α倍(1 < α < 2)。如同隨機取樣，FMP在取樣過程中引入了一定程度的隨機性。然而，FMP與隨機取樣不同的是，其隨機性和取樣區域的選擇有關，而非每個取樣區域內的取樣方式。\n\n於第二節中，我們將說明分數階最大取樣的形式。簡而言之，有三種選擇會影響FMP的實現方式：\n- 取樣的非整數值α決定了取樣層輸入和輸出的特徵空間尺寸比例。例如2 × 2最大取樣對應於α = 2的特定情況。\n- 取樣區域可以用隨機或偽隨機的方式來選擇。在FMP的隨機性和使用隨機去活化是否搭配數據增強(data augmentation)之間似乎得做適當的取捨，隨機的FMP或許可以表現得更好，但如果「過度」使用隨機去活化或訓練數據強化，則可能導致欠擬合(underfitting)。\n- 取樣區域可以不相交(disjoint)或重疊(overlapping)。不相交的區域較容易描述，但我們發現重疊區域的效果更好。\n\n我們會在第三節中描述如何設計和訓練我們的卷積網路，並於第四節中展示MNIST手寫數字、CIFAR-10、CIFAR-100、阿薩姆語手寫文字以及CASIA-OLHWDB1.1手寫漢字等數據集的訓練結果。\n\n### 分數階最大取樣\nCNN的每個卷積濾波器都會產生一個隱含變數的矩陣，通常使用某種形式的取樣來縮減矩陣大小。最大取樣是一個採用$ N_{in} \\times N_{in} $矩陣並返回較小的$ N_{out} \\times N_{out} $輸出矩陣的過程，這是透過將$ N_{in} \\times N_{in} $輸入正方形分割為$ N^2_{out} $個取樣區域$ (P_{i,j}) $而實現：\n$$ (P_{i,j}) \\subset \\lbrace 1,2,...,N_{in} \\rbrace ^2 \\ \\text{for each}\\ (i,j) \\in \\lbrace 1,...,N_{out} \\rbrace ^2 $$\n接著令：\n$$ Output_{i,j} = \\displaystyle{\\max_{(k,l)\\in P_{i,j}}} Input_{k,l} $$\n\n以我們的使用慣例2 x 2最大取樣而言，$ N_{in} = 2N_{out}\\ and\\ P_{i,j} = \\rbrace 2i-1,2i \\rbrace \\times \\rbrace 2j-1,2j \\rbrace $。[參考文獻 [5]](#參考文獻)中提到，最大取樣應用於3 x 3重疊取樣區域，因此$ N_{in} = 2N_{out}+1 $，$ P_{i,j} $為3 x 3正方形，以步長2進行擴展。上述兩種情況中，$ N_{in}\\ /\\ N_{out} \\approx 2 $，因此輸入影像中任何有效特徵的空間大小會在每個取樣層中減半。相較之下，如果我們採用$ N_{in}\\ /\\ N_{out} \\approx \\sqrt[n]{2} $，則有效特徵的空間大小之縮小速率減緩N倍。為清楚起見，我們現在將重點放在$ N_{in}\\ /\\ N_{out} \\in (1,2) $，因為我們主要感興趣的是準確率；如果對執行速度相當介意，則FMP可以採用$ N_{in}\\ /\\ N_{out} \\in (2,3) $。\n\n![](https://i.imgur.com/n77VYDM.png)\nFigure 1：由左至右依序為\b36 x 36的網格；4個偽隨機的FMP不相交取樣區域，$ \\alpha \\in \\lbrace \\sqrt[3]{2},\\sqrt 2,2,\\sqrt 5 \\rbrace $；以及$ \\alpha = \\sqrt 2 $的隨機的FMP不相交取樣區域。對$ \\alpha \\in (1,2) $，FMP生成的矩形取樣區域其邊長為1或2。對$ \\alpha \\in (2,3) $，其取樣區域邊長則為2或3。\n\n給定一對特定數值$ (N_{in},N_{out}) $，我們需要一種選擇取樣區域$ (P_{i,j}) $的方法。我們將考慮兩種類型的排列方式：重疊的正方形以及不相交的矩形集合。在Figure 1中我們展示了數種不同的方法來將36 x 36正方形網格分割為不相交的矩形。Figure 1中的第2、第3及第6張影像可以用來定義重疊的2 x 2正方形的排列：將影像中每個矩形的左上角視為其中一個正方形的左上角。為標準化地描述如何生成取樣區域，令：\n$$ (a_i)^{N_{out}}_{i=0}\\ ,\\ (b_i)^{N_{out}}_{i=0} $$\n<a id=\"link-formula-1\"></a>\n\n為兩個以1為起始、$ N_{in} $結束的整數遞增數列，且遞增量皆為1或2(i.e. $ a_{i+1}-a_i \\in \\lbrace 1,2 \\rbrace $)。然後我們可以用以下任一方式定義取樣區域 :\n$$ P = [a_{i-1},a_i-1] \\times [b_{j-1},b_j-1]\\ \\text{or}\\ P_{i,j} = [a_{i-1},a_i] \\times [b_{j-1},b_j]\\ \\ (1) $$\n\n![](https://i.imgur.com/a1uq3oy.png)\nFigure 2：左上角為柯達公司釋出的真實色彩圖片數據集，解析度為384 x 256(原始解析度為768 x 512)。其他五張影像則是以隨機的不相交FMP$ \\sqrt 2 $取樣區域進行6層平均取樣的結果，解析度為左上角的八分之一。\n\n我們稱這兩種情況分別為不相交和重疊，接著嘗試兩種不同的方法來生成整數序列：隨機數列以及偽隨機數列。如果數列的增加是透過對適當數量的1和2進行隨機排列而獲得的，那麼我們稱其為隨機數列。若是透過以下方式則稱之偽隨機數列：\n$$ a_i = ceiling(\\alpha(i+u)),\\ \\alpha \\in (1,2)\\ \\text{with some}\\ u  \\in (0,1) $$\n\n以下是對應$ N_{in} = 25、N_{out} = 18 $之情況的增量模式，左側增量為隨機生成，右側增量則來自偽隨機數列：\n\n211112112211112122 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 112112121121211212\n111222121121112121 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 212112121121121211\n121122112111211212 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 211211212112121121\n\n儘管兩種類型的數列都是不規則的，但偽隨機數列所生成的取樣區域較隨機數列來得穩定。為顯示取樣區域隨機化的效果，請參考Figure 2。我們拍攝了一張影像，接著疊代使用不相交的隨機取樣區域來縮減影像大小(在每個取樣區域中取平均值)。結果按比例縮減的影像顯示出彈性形變。相反地，若我們使用偽隨機取樣區域，則生成的影像僅為原始影像的真實比例縮小版本。\n\n### 實作方法\n<br>\n![](https://i.imgur.com/WRZu8v6.png)\nFigure 3：微型FMP$ \\sqrt 2 $網路各層的空間大小如圖所示。分數$ \\frac32,\\frac64,\\frac{10}{7} $近似於$ \\sqrt 2 $。\n\n我們將使用稀疏卷積網路的實例來進行訓練，這實際上意味著我們能逐層依序指定卷積網路的結構。例如：\n$$ 10C2-FMP \\sqrt 2 -20C-30C2-FMP \\sqrt 2 -40C2-50C1-output $$\n\n輸入層的空間大小是透過由右至左的運算所獲得的：每個C2卷積層將空間大小增加為2倍，FMP$ \\sqrt 2 $層則是將空間大小增加為2倍(四捨五入至最接近的整數)；參見Figure 3。輸入層通常會大於輸入影像—必要時會自動以0來補齊。分數階最大取樣也能輕易地在常用的卷積神經網路套件中實現。為簡單起見，我們使用的所有網路中每個卷積層的濾波器數量都呈線性增長。因此，我們能簡要地說明上述的網路結構為\n\n$$ (10_nC2-FMP \\sqrt 2)_3-C2-C1-output $$\n\n$ 10_n $代表第n個卷積層中的濾波器數量為$ 10_n $，下標的3表示3對交替使用的C2/FMP層。使用隨機去活化時，進入的網路越深，所使用的隨機去活化數量就越多。我們在第一個隱藏層中使用0％隨機去活化，並在最後一個隱藏層中線性增加至50％。所使用的活化函數為leaky ReLU(帶滲漏整流線性函數)。\n\n#### 模型平均\n每次我們基於訓練或測試目的而應用FMP網路時，都會使用不同的隨機或偽隨機序列來生成取樣區域。因此FMP網絡可以被視為相似網路的集合，而每個不同的取樣區域設定都定義了該集合的不同成員。 這類似於隨機去活化[[10]](#參考文獻)；隨機去活化其遮罩的不同數值可以用來定義相關網路的集合。如同隨機去活化，FMP網路的模型平均可以幫助提升效能。如果你對同一張測試影像進行多次分類，可能會得到許多不同的預測結果。對每個測試影像進行多次分類後，使用多數決可以大幅提升準確度；參見Figure 4。\n\n![](https://i.imgur.com/NXYLssj.png)\nFigure 4：重複測試對於一個由MNIST所訓練的FMP網路之影響\n\n### 實驗結果\n<br>\n\n#### 不使用數據增強或隨機去活化\n為比較不同種類的分數階最大取樣，我們在$ \\text{MNIST}^1 $以及CIFAR-100數據集上訓練FMP網路[[4]](#參考文獻)。對於MNIST，我們使用了小型的FMP網路：\n$$ \\text{input layer size 36 x 36：}\\ (36_nC2-FMP \\sqrt 2)_6-C2-C1-output $$ \n\n對於CIFAR-100則使用了較大的網路：\n$$ \\text{input layer size 94 x 94：}\\ (64_nC2-FMP \\sqrt[3]{2})_{12}-C2-C1-output $$ \n\n在不使用訓練數據增強的情況下，這兩個數據集最新的測試誤差分別為0.39%以及34.57%[[6]](#參考文獻)。FMP網路的結果如Table 1所示。使用重複測試12次的模型平均，我們發現使用隨機重疊取樣的FMP對這兩個數據集的表現最佳。對於CIFAR-100而言，此方法相較於常規的最大取樣有著相當程度的改進。就網路的複雜程度概括來說，CIFAR-100的網路擁有1200萬個權重參數，且經過250次訓練數據的重複訓練(在GeForce GTX 780上需耗費18小時)。我們嘗試改變CIFAR-100每層的隱藏單元數量，搭配隨機重疊取樣：\n\n- 使用$ {16}_nC2 $(0.8M weights)的測試結果誤差為42.07% / 34.87\n- 使用$ {32}_nC2 $(3.2M weights)的測試結果誤差為35.09% / 29.66\n- 使用$ {96}_nC2 $(27M weights)結合隨機去活化以及較為和緩的學習率衰減，測試結果誤差為27.62% / 23.82\n\n![](https://i.imgur.com/NblVtwE.png)\nTable 1：MNIST以及CIFAR-100的測試誤差\n\n註1：[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)\n\n#### 阿薩姆語手寫文字\n為比較FMP和MP2兩種取樣方式搭配訓練數據增強的影響，我們使用線上線上阿薩姆語手寫文字數據集來測試。此數據集包含了183個印度-雅利安文字中每個文字的45個樣本。「線上」的意思是指每一筆畫皆代表(x, y)座標序列。我們使用每個文字的前36個樣本做為訓練集，剩餘的9個樣本做為測試集，並將樣本縮放為64 x 64的大小來訓練一個有6層MP2的網路：\n$$ 32_nC3-MP2-(C2-MP2)_{12}-C2-output $$\n\n以及使用10層隨機的重疊FMP$ \\sqrt 2 $取樣的FMP網路：\n$$ (32_nC2-FMP\\sqrt 2)_{10}-C2-C1-output $$\n\n我們訓練了沒有使用隨機去活化的網路，以及：\n- 不使用數據增強\n- 使用隨機平移來位移文字\n- 使用仿射轉換(平移、旋轉、拉伸以及剪切的隨機組合)\n\n![](https://i.imgur.com/fNDKsYO.png)\nTable 2：以阿薩姆語手寫文字數據集搭配不同類型的數據增強來訓練網路的測試誤差\n\n參照Table 2。某種意義上來說，我們對於「在某種程度的輕微失真下，筆跡的意義通常是不變的」的認知，來自最大取樣與訓練數據增強這兩種不同的方式。有趣的是，不使用數據增強的FMP網路比起使用數據增強的MP2網路表現更好，顯示FMP網路更適合處理該數據集。\n\n#### 線上中文手寫文字\nCASIA-OLHWDB1.1數據集包含了3755個獨立的GBK 1級漢字手寫樣本[[8]](#參考文獻)，每個類別大約有240個訓練樣本與60個測試樣本。使用4層的MP2取樣層可以達到5.61%的測試誤差[[2]](#參考文獻)。\n\n我們使用[[3]](#參考文獻)所描述的線上字符表示法；以64 x 64的大小繪製文字，加上量測筆跡方向的特徵，生成64 x 64 x 9的陣列。使用2 x 2最大取樣、隨機去活化以及仿射訓練數據增強，測試結果誤差為3.82% [[3]](#參考文獻)。以偽隨機的重疊FMP取代最大取樣：\n$$ (64_nC2-FMP\\sqrt 2)_7-(C2-MP2-C1)_2-C2-C1-output $$\n\n測試結果誤差為3.26%(1 test)以及2.97%(12 tests)。\n\n#### CIFAR-10搭配隨機去活化與訓練數據增強\n對於CIFAR-10數據集，我們使用了隨機去活化和透過仿射轉換來擴充訓練數據：隨機對數據集執行平移、旋轉、反射、拉伸及剪切的預處理。相較之下，人類在CIFAR-10數據集的表現估計為6%$ {}^2 $ 。而近期(2015)於Kaggle平台上的CIFAR-10競賽，獲勝者的測試誤差為4.47%$ {}^3 $, 使用上述的數據增強策略和以下的網路結構：\n$$ (300_nC2-300_nC2-MP2)_5-C2-C1-output $$\n\n使用偽隨機的重疊FMP網路：\n$$ (160_nC2-FMP\\sqrt[3]{2})_12-C2-C1-output $$\n\n我們得到了4.50%(1 test)，3.67%(12 tests)及3.47%(100 tests)的測試誤差。\n\n註2：[http://karpathy.github.io/2011/04/27/manually-classifying-cifar10/](http://karpathy.github.io/2011/04/27/manually-classifying-cifar10/)\n註3：[https://www.kaggle.com/c/cifar-10/](https://www.kaggle.com/c/cifar-10/)\n＊原文中註2的[原始網址](http://karpathy.ca/myblog/?p=160)已失效，推測是網站搬遷。\n\n### 結論\n我們在許多受歡迎的數據集上訓練搭配分數階最大取樣的卷積網路，並於效能方面發現有顯著的改善。取樣區域重疊的FMP比起不相交的似乎表現得更好。使用訓練數據增強時，偽隨機取樣區域比隨機取樣區域的表現更佳。若微調隨機去活化的使用數量，隨機取樣可能會重新取得優勢。\n\n再次查看Figure 2由隨機取樣所創造的失真，請注意此「失真」可以分解為「X軸的失真」和「Y軸的失真」，探究無法以[方程式(1)](#link-formula-1)表達的取樣區域可能會很有趣，因為它們可能將更為通用的失真編碼至結果的卷積網路。\n\n### 參考文獻\n[1] K. Bache and M. Lichman. UCI machine learning repository, 2013.\n\n[2] D. Ciresan, U. Meier, and J. Schmidhuber. Multi-column deep neural networks for image classification. In Computer Vision and Pattern Recognition(CVPR), 2012 IEEE Conference on, pages 3642–3649, 2012.\n\n[3] Ben Graham. Spatially-sparse convolutional neural networks. 2014.\n\n[4] Alex Krizhevsky. Learning Multiple Layers of Features from Tiny Images.Technical report, 2009.\n\n[5] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolutional neural networks. In F.Pereira, C.J.C. Burges, L. Bottou, and K.Q. Weinberger, editors, Advances in Neural Information Processing Systems 25, pages 1097–1105. Curran Associates, Inc., 2012.\n\n[6] Chen-Yu Lee, Saining Xie, Patrick Gallagher, Zhengyou Zhang, and Zhuowen Tu. Deeply-Supervised Nets, 2014.\n\n[7] Min Lin, Qiang Chen, and Shuicheng Yan. Network in network. ICLR, 2014.\n\n[8] C.-L. Liu, F. Yin, D.-H. Wang, and Q.-F. Wang. CASIA online and offline Chinese handwriting databases. In Proc. 11th International Conference on Document Analysis and Recognition (ICDAR), Beijing, China, pages 37–41, 2011.\n\n[9] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. 2014.\n\n[10] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: A Simple Way to Prevent Neural Networks from Overfitting. Journal of Machine Learning Research, 15:1929–1958, 2014.\n\n[11] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed,Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. 2014.\n\n[12] Li Wan, Matthew Zeiler, Sixin Zhang, Yann Lecun, and Rob Fergus. Regularization of Neural Networks using DropConnect, 2013. JMLR W&CP 28 (3) : 1058–1066, 2013.\n\n[13] Matthew D. Zeiler and Rob Fergus. Stochastic Pooling for Regularization of Deep Convolutional Neural Networks. ICLR 2013.","tags":["deep learning","computer vision"],"categories":["Study"]},{"title":"樹莓派：紅外線熱像儀","url":"/rspi-thermal-cam-amg8833/","content":"看到火車站架設熱像儀監控旅客們的體溫，然而並非每個車站都能設置如此昂貴的儀器，出於好奇也想做個低成本的來看看，雖然解析度與精確度都比不上昂貴的精密儀器，但在近距離下能做到快速、自動偵測體溫的話，比起讓站務人員逐一量測後進站，這應該堪用且有效率多了。\n<!--more-->\n### AMG8833 Intro\n![](https://i.imgur.com/JATdb1S.jpg)\n於是我買來了Adafruit AMG8833模組，這模組上頭裝著Panasonic所生產的紅外線陣列感測器。\nDatasheet：[Panasonic IR Array Sensor Grid-EYE](https://b2b-api.panasonic.eu/file_stream/pids/fileversion/1819)\n\n![](https://i.imgur.com/gQseBWz.jpg)\n![](https://i.imgur.com/DBrxsGu.jpg)\n\n參考[Adafruit官網](https://www.adafruit.com/product/3538)的技術參數說明：\n1. 感測器為8x8紅外線陣列\n2. 溫度感測區間為攝氏0度～攝氏80度(精度為正負2.5度)\n3. 人體最大感測距離為7米\n4. 透過[I2C協定](https://zh.wikipedia.org/wiki/I%C2%B2C)進行數據傳輸\n\n\n### Setting & Installing\n接下來將於運行Raspbian作業系統的樹莓派上進行環境設置，我習慣[使用VNC Server與樹莓派進行遠端連線操作](https://laplacetw.github.io/rspi-meet-raspberry-pi-b3-plus/#Remote)。\n\n#### 系統更新\n{% codeblock lang:shell %}\n$ sudo apt-get update\n$ sudo apt-get upgrade\n{% endcodeblock %}\n\n#### 啟用I2C & SPI介面\n{% codeblock lang:shell %}\n$ sudo raspi-config\n{% endcodeblock %}\n\n在選項5的介面設定中啟用它們，然後測試是否成功啟用\n{% codeblock lang:shell %}\n$ ls /dev/i2c* /dev/spi*\n{% endcodeblock %}\n\n#### Package Installing\n直接安裝Adafruit的AMG88XX Package，pip會處理其他依賴的函式庫(e.g. Adafruit-Blinka)。\n{% codeblock lang:shell %}\n$ sudo pip3 install adafruit-circuitpython-amg88xx\n{% endcodeblock %}\n![](https://i.imgur.com/sANUgo1.png)\n\n#### Blinka Test\n使用Adafruit的測試範例來確認環境設定是否完成。\n{% codeblock lang:py %}\nimport board\nimport digitalio\nimport busio\n\nprint(\"Hello blinka!\")\n\n# Try to great a Digital input\npin = digitalio.DigitalInOut(board.D4)\nprint(\"Digital IO ok!\")\n\n# Try to create an I2C device\ni2c = busio.I2C(board.SCL, board.SDA)\nprint(\"I2C ok!\")\n\n# Try to create an SPI device\nspi = busio.SPI(board.SCLK, board.MOSI, board.MISO)\nprint(\"SPI ok!\")\n\nprint(\"done!\")\n{% endcodeblock %}\n![](https://i.imgur.com/msoQDyb.png)\n\n#### I2C Test\n依照[樹莓派GPIO](https://pinout.xyz/)與AMG8833進行連接：\n1. 3V Power連接到Vin\n2. \b\bGND連接到GND\n3. 連接SDA & SCL\n![](https://i.imgur.com/ilmXszn.jpg)\n\n試著透過I2C讀取感測器數據並印出來\n{% codeblock lang:py %}\nimport time\nimport busio\nimport board\nimport adafruit_amg88xx\n\ni2c = busio.I2C(board.SCL, board.SDA)\namg = adafruit_amg88xx.AMG88XX(i2c)\n\nwhile True:\n    for row in amg.pixels:\n        # Pad to 1 decimal place\n        print([\"{0:.1f}\".format(temp) for temp in row])\n        print(\"\")\n    print(\"\\n\")\n    time.sleep(1)\n{% endcodeblock %}\n![](https://i.imgur.com/DK85IXe.png)\n\n### Build Thermal Camera\n安裝溫度數據視覺化所需的函式庫\n{% codeblock lang:shell %}\n$ sudo apt-get install -y python3-scipy python3-pygame\n$ sudo pip3 install colour\n{% endcodeblock %}\n\nAdafruit官方範例程式：\n{% codeblock lang:py %}\n\"\"\"This example is for Raspberry Pi (Linux) only!\n   It will not work on microcontrollers running CircuitPython!\"\"\"\nimport os\nimport math\nimport time\n\nimport busio\nimport board\n\nimport numpy as np\nimport pygame\nfrom scipy.interpolate import griddata\n\nfrom colour import Color\n\nimport adafruit_amg88xx\n\ni2c_bus = busio.I2C(board.SCL, board.SDA)\n\n#low range of the sensor (this will be blue on the screen)\nMINTEMP = 26.\n\n#high range of the sensor (this will be red on the screen)\nMAXTEMP = 32.\n\n#how many color values we can have\nCOLORDEPTH = 1024\n\nos.putenv('SDL_FBDEV', '/dev/fb1')\npygame.init()\n\n#initialize the sensor\nsensor = adafruit_amg88xx.AMG88XX(i2c_bus)\n\n# pylint: disable=invalid-slice-index\npoints = [(math.floor(ix / 8), (ix % 8)) for ix in range(0, 64)]\ngrid_x, grid_y = np.mgrid[0:7:32j, 0:7:32j]\n# pylint: enable=invalid-slice-index\n\n#sensor is an 8x8 grid so lets do a square\nheight = 240\nwidth = 240\n\n#the list of colors we can choose from\nblue = Color(\"indigo\")\ncolors = list(blue.range_to(Color(\"red\"), COLORDEPTH))\n\n#create the array of colors\ncolors = [(int(c.red * 255), int(c.green * 255), int(c.blue * 255)) for c in colors]\n\ndisplayPixelWidth = width / 30\ndisplayPixelHeight = height / 30\n\nlcd = pygame.display.set_mode((width, height))\n\nlcd.fill((255, 0, 0))\n\npygame.display.update()\npygame.mouse.set_visible(False)\n\nlcd.fill((0, 0, 0))\npygame.display.update()\n\n#some utility functions\ndef constrain(val, min_val, max_val):\n    return min(max_val, max(min_val, val))\n\ndef map_value(x, in_min, in_max, out_min, out_max):\n    return (x - in_min) * (out_max - out_min) / (in_max - in_min) + out_min\n\n#let the sensor initialize\ntime.sleep(.1)\n\nwhile True:\n\n    #read the pixels\n    pixels = []\n    for row in sensor.pixels:\n        pixels = pixels + row\n    pixels = [map_value(p, MINTEMP, MAXTEMP, 0, COLORDEPTH - 1) for p in pixels]\n\n    #perform interpolation\n    bicubic = griddata(points, pixels, (grid_x, grid_y), method='cubic')\n\n    #draw everything\n    for ix, row in enumerate(bicubic):\n        for jx, pixel in enumerate(row):\n            pygame.draw.rect(lcd, colors[constrain(int(pixel), 0, COLORDEPTH- 1)],\n                             (displayPixelHeight * ix, displayPixelWidth * jx,\n                              displayPixelHeight, displayPixelWidth))\n\n    pygame.display.update()\n{% endcodeblock %}\n<br>\n迷你紅外線熱像儀就這麼運作起來囉～🙆‍♂️ 可依照自己的測試環境，嘗試調整感測溫度上下限讓影像清晰一些。\n![](https://i.imgur.com/KtWuOfU.gif)\n\n＊參考\n1. [I2C-協定用法原理簡介-晶片溝通的橋樑](https://www.strongpilab.com/i2c-introduction/)\n2. [Installing CircuitPython Libraries on Raspberry Pi](https://learn.adafruit.com/circuitpython-on-raspberrypi-linux/installing-circuitpython-on-raspberry-pi)\n3. [Adafruit AMG8833 8x8 Thermal Camera Sensor](https://learn.adafruit.com/adafruit-amg8833-8x8-thermal-camera-sensor/python-circuitpython)\n4. [Raspberry Pi Thermal Camera](https://learn.adafruit.com/adafruit-amg8833-8x8-thermal-camera-sensor/raspberry-pi-thermal-camera)","tags":["IoT","raspberry pi","adafruit","thermal camera"],"categories":["Raspberry Pi"]},{"title":"Python批次影片轉GIF","url":"/python-batch-video-to-gif/","content":"\b\b\b\b\b\b\b\b\b偶爾會為了DEMO用途，需要將影片\b轉換為GIF的形式，便於穿插在文章裡頭，但我不想為了這小小的需求安裝什麼軟體。<!--more-->而線上服務就是圖個方便打到很多使用者的痛點，但你必須將圖片上傳，這對某些使用者而言可能有疑慮...雖然我見到的線上轉檔服務使用者都是莫名安心地上傳的(?)\n\nPython是非常美好的程式語言，自己寫段程式碼來處理就行了😎&nbsp;&nbsp;我們只需要先在電腦安裝[FFmpeg](https://ffmpeg.org/)，然後引入[moviepy](https://pypi.org/project/moviepy/)這個套件就行了，作者zulko在他的個人網站有[詳細的教學](http://zulko.github.io/blog/2014/01/23/making-animated-gifs-from-video-files-with-python/)。\n\n---\n範例程式：\n\n設置參數可更換影片輸入格式、是否加入浮水印以及生成的GIF和浮水印的縮放倍率。\n{% codeblock lang:py %}\n#!/usr/bin/env python3\nfrom glob import glob\nimport moviepy.editor as mp\n\n\n# setting\nfiletype = '.mov'\nwatermark = './devilcat.png'\nscale_gif = 0.3\nscale_mark = 0.3\n\nvideos = glob('./*' + filetype)\nvideos.sort()\nfor video in videos:\n    output = video.replace(filetype, '.gif')\n    with mp.VideoFileClip(video).resize(scale_gif) as clip:\n        if watermark == '':  # no watermark\n            clip.write_gif(output, fps=5)\n        else:\n            mark_image = (mp.ImageClip(watermark)\n            .resize(scale_mark)\n            .set_duration(clip.duration)\n            .set_pos((\"left\", \"top\")))\n            \n            # add watermark to video\n            mark_video = mp.CompositeVideoClip([clip, mark_image])\n            mark_video.write_gif(output, fps=5)\n{% endcodeblock %}\n＊關於resize的錯誤參考：[stackoverflow — Moviepy does not recognize resize function](https://stackoverflow.com/questions/57696343/moviepy-does-not-recognize-resize-function)\n\n---\n我使用[YT頻道哈哈台訪問浪漫Duke經典片段](https://youtu.be/H4Cn4taeuA4)當範例，實際執行將影片轉換為GIF動圖並加上浮水印。\n\n- 首先來畫一個浮水印...惡魔貓男！你今晚的惡夢！(\b激動 ⬇︎\n![](https://i.imgur.com/FwCJqVN.png)\n\n- 接著準備幾個要轉成GIF的片段，開始轉換⬇︎\n![](https://i.imgur.com/6FNRGii.png)\n\n- 轉檔結果，可以看到GIF左上角出現剛剛畫的浮水印🤣&nbsp;&nbsp;⬇︎\n\n世界要有愛!|雞肉飯❤️\n:----------------------------------:|:-----------------------------------:\n![](https://i.imgur.com/tLDHNqj.gif)|![](https://i.imgur.com/IaS7v3K.gif)\n好看!|浪漫Duke❤️\n![](https://i.imgur.com/XLTZUVm.gif)|![](https://i.imgur.com/aKcPhnH.gif)","tags":["python","moviepy","mytoolbox"],"categories":["Python"]},{"title":"eMask口罩預購&取貨","url":"/taiwan-emask-pre-order/","content":"Taiwan No.1❤️<!--more-->\n\n### 口罩預購\n<br>\n\b[eMask口罩預購系統](https://emask.taiwan.gov.tw/msk/index.jsp)於3/12~3/18開放首波預購，今天終於開始取貨啦！取貨時間為3/26~4/1，若沒有在期限內完成領取就視同放棄唷。(這可不是什麼愚人節梗！\n\n第二波預購期間為3/25~3/27晚上8點截止，詳情見[衛福部公告](https://mrmad.com.tw/emask-taiwan-gov-20-app)，我個人是使用健保快易通APP來預購的，相關設定可以參考這篇教學：[點我](https://mrmad.com.tw/emask-taiwan-gov-20-app)，無須讀取我們的~~地表最強~~健保卡，非常方便。\n\n預購完成後就等待抽籤，首波預購人數不多，因此有參加預購的人都能買到(儘管有18萬人沒有繳費...)，第二波就未知數了＠＠\n3/28 更新：因為第二波預購人數依然未超過上限，因此登記預購者都能買到。\n![](https://i.imgur.com/vRZqnCX.jpg)\n\n### 預購繳費\n<br>\n第二波預購開放APP也能刷卡繳費囉～話說填寫信用卡資訊的這個「卡片後三碼」反而讓我有點錯愕，就檢核碼呀😅\n![](https://i.imgur.com/Hi10jKK.png)\n繳費成功！\n![](https://i.imgur.com/t3NxohE.png)\n\n### 口罩領取\n<br>\n統一超商ibon首頁就能看到口罩取貨專區😷\n![](https://i.imgur.com/c0mPcLA.jpg)\n\n輸入身分證後4碼以及取貨通知簡訊中的取貨序號\n![](https://i.imgur.com/jEZxkSq.jpg)\n\n拿著小白單到超商櫃檯就能領取到珍貴的口罩！\n![](https://i.imgur.com/CW90CFq.jpg)\n\n\n\n希望這糟糕的一切能盡快結束😬，祝福我們都健健康康💪。","tags":["covid-2019"],"categories":["Daily"]},{"title":"Manjaro安裝NVIDIA Driver＆CUDA","url":"/linux-manjaro-nvidia-driver-and-cuda/","content":"搞定Manjaro的基本環境後，接下來要設定GTX 1660 Super以利後續的運算任務...噢，又折騰了不少時間，得好好紀錄過程與問題才行吶。<!--more-->\n\n### Manjaro freezing at boot screen after NVIDIA driver installed\n透過Manjaro硬體偵測安裝non-free driver：\n{% codeblock lang:bash %}\n$ sudo mhwd -a pci nonfree 0300\n{% endcodeblock %}\n![](https://i.imgur.com/mfQGFmj.png)\n\n重新開機後，很好，畫面就停在黑螢幕了，進不去登入畫面(傻眼。原來在安裝了NVIDIA驅動後還必須手動修改硬體設定，否則視窗服務的運作會異常，導致系統看起來掛了，所以安裝N卡驅動的正確姿勢應該是要先修改設定文件後再重新啟動。首先，在黑螢幕的畫面按下ctrl + alt + F3來進入Terminal：\n\n查詢GPU BusID\n{% codeblock lang:bash %}\n$ lspci | grep -E \"VGA|3D\"\n{% endcodeblock %}\n輸出訊息前三組數字即為BusID(忽略前綴0)，例如「01:00.0」則BusID為「1:0:0」。\n\n備份設定\n{% codeblock lang:bash %}\n$ sudo mv /etc/X11/xorg.conf.d/90-mhwd.conf /etc/X11/xorg.conf.d/90-mhwd.conf.bak\n{% endcodeblock %}\n\n寫入 /etc/X11/xorg.conf.d/90-mhwd.conf，BusID改為你要設定的GPU，我是設定為內顯的AMD GPU。\n{% codeblock lang:bash %}\nSection \"Module\"\n    Load \"modesetting\"\nEndSection\n\nSection \"Device\"\n    Identifier \"nvidia\"\n    Driver \"nvidia\"\n    BusID \"PCI:1:0:0\"\n    Option \"AllowEmptyInitialConfiguration\"\nEndSection\n{% endcodeblock %}\n\n修改完成後重新啟動即可。\n\n參考：https://blog.csdn.net/baidu_33340703/article/details/103977592\n\n### CUDA＆cuDNN\n在安裝CUDA之前，先確認N卡驅動是否正確安裝：\n{% codeblock lang:bash %}\n$ nvidia-smi\n{% endcodeblock %}\n![](https://i.imgur.com/UKIf8U1.png)\n\n安裝CUDA、cuDNN以及後續會用到的Python函式庫：\n{% codeblock lang:bash %}\n$ sudo pacman -Syu tensorflow-cuda cuda cudnn python-pycuda python-tensorflow-cuda python-matplotlib\n{% endcodeblock %}\n＊為避免和pacman軟體庫提供的版本衝突，Arch/Manjaro移除了pip軟體庫中的tensorflow-gpu，以tensorflow-cuda取代之。\n\n將CUDA安裝目錄中的samples複製到home目錄下，編譯然後測試CUDA是否安裝成功：\n{% codeblock lang:bash %}\n$ cp -r /opt/cuda/samples ~\n$ ~/samples\n$ sudo make -k\n{% endcodeblock %}\n編譯過程需要點時間，大概30分鐘，編譯完成後執行deviceQuery：\n{% codeblock lang:bash %}\n$ cd ~/samples/1_Utilities/deviceQuery\n$ ./deviceQuery\n./deviceQuery Starting...\n\nCUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"GeForce GTX 1660 SUPER\"\n CUDA Driver Version / Runtime Version          10.2 / 10.2\n CUDA Capability Major/Minor version number:    7.5\n Total amount of global memory:                 5945 MBytes (6233391104 bytes)\n (22) Multiprocessors, ( 64) CUDA Cores/MP:     1408 CUDA Cores\n \n(略...)\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.2, CUDA Runtime Version = 10.2, NumDevs = 1\nResult = PASS  # PASS表示CUDA安裝成功\n{% endcodeblock %}\n\n### Test\n用[MNIST手寫數字辨識](https://laplacetw.github.io/data-sci-ml-hello-world-mnist/)\b來做測試，每批次都1秒就運算完了，雖然實際應該不到1秒XD\n\n\n### Keras could not create cudnn handle: cudnn_status_alloc_failed\n噢，正想說一切都配置好了，趕緊來繼續實驗放置了半個月的cifar-10模型訓練(因為Google CoLab的免費資源太熱門導致經常斷線而白忙，只好自己建置運算環境了😂)，結果出現了一個看起來很厲害的錯誤訊息(傻眼x2。查詢後發現是GPU記憶體配置問題，[Tensorflow為了避免記憶體碎片化](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth)，預設會盡可能把可見的GPU記憶體都映射給當前的進程：\n\n>By default, TensorFlow maps nearly all of the GPU memory of all GPUs (subject to CUDA_VISIBLE_DEVICES) visible to the process. This is done to more efficiently use the relatively precious GPU memory resources on the devices by reducing memory fragmentation.\n\n結果就是cifar-10這樣的運算量就導致記憶體不足而拋出錯誤訊息，所以我們必須讓Tensorflow按需求配置GPU記憶體：\n{% codeblock lang:py %}\nconfig = tf.compat.v1.ConfigProto()  # tensorflow-gpu 2.1.0\nconfig.gpu_options.allow_growth=True\ntf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))\n{% endcodeblock %}\n\n解決～每批次的運算速度比我在CoLab上面快10秒呢，$$沒有白花了QQ\n\n參考：\n- https://blog.csdn.net/weixin_42769131/article/details/88848478\n- https://blog.csdn.net/zuoyouzouzou/article/details/104329286","tags":["keras","linux","manjaro","nvidia"],"categories":["Linux"]},{"title":"Manjaro:You need to load kernel first","url":"/linux-need-to-load-kernel-first/","content":"Manjaro在安裝完成並執行同步軟體庫&更新後，重新開機黑屏顯示「error: file '/boot/vmlinuz-4.19-x86_64' not found」<!--more-->、「\berror: You need to load kernel first」，這問題在我重新安裝並更新後依然發生了，到Manjaro Forum爬文才\b得知此問題來自pacman原始碼的變更，若使用低於18.1.5的舊版本ISO檔進行安裝就可能會受到影響，而我是使用18.0.1來安裝的😅\n\n### Solution\n\n使用live USB來開機啟動Manjaro，在terminal執行以下指令 :\n{% codeblock lang:bash %}\n$ sudo manjaro-chroot -a\n$ pacman -S linux419 linux419-headers\n$ mkinitcpio -P\n$ update-grub\n$ sync\n$ exit\n{% endcodeblock %}\n\nheader版本依照錯誤訊息顯示哪個版本not found，重新安裝該版本就行了，指令執行完畢重新開機即可。\n\n參考 :\n- [Rescue your system: error: hook … Invalid value Path](https://forum.manjaro.org/t/howto-rescue-your-system-error-hook-invalid-value-path/123226)\n- [error: file ‘/boot/vmlinux-4.19-x86_64’ not found](https://forum.manjaro.org/t/error-file-boot-vmlinux-4-19-x86-64-not-found/123303)","tags":["error","linux","manjaro"],"categories":["Linux"]},{"title":"Manjaro KDE 安裝＆個人化","url":"/linux-manjaro-install-and-optimization/","content":"前陣子組了一台新主機，安裝了Manjaro Linux。\n<!--more-->\n\b其實是為了NVIDIA GPU的運算力，礙於窮學生經費有限僅能擠出20K左右的預算，取捨後實際花費為18K。\n\n- AMD AM4 Ryzen 5 2400G\n- ASUS PRIME A320M-K\n- Crucial 16GB DDR4-3200 Ballistix SportLT\n- WD Blue 250GB(M.2 SATA 3D TLC)\n- Power Master N9 RGB/ATX\n- Antec NX650\n- Zotec GTX1660 SUPER Twin Fan 6G(T16620F-10L)\n\n![](https://i.imgur.com/E7LsmEN.jpg)\n![](https://i.imgur.com/9waIGr8.jpg)\n\n### About Manjaro\n目前實際接觸過的Linux版本也就Ubuntu跟Raspberry Pi的Raspbian，本來也是預計要裝Ubuntu，但無意間看到Manjaro的相關文章，決定安裝KDE桌面環境版本，內建的下拉式terminal真香😋\n\nManjaro是基於Arch的Linux發行版(這意味著許多問題都能在[Arch Wiki](https://wiki.archlinux.org)找到答案)，初始版本發行日期為2011年7月10日，目標為使強大的Arch Linux能被人們更容易地使用，硬體檢測與核心切換是Manjaro相當突出的特色。[官方](https://manjaro.org/download/)支援桌面環境有XFCE、KDE Plasma、GNOME，另外社群也支援了其他桌面環境，例如MATE、LXDE等。Manjaro雖然和Arch同樣採用滾動更新，但[根據Manjaro官方所述](https://manjaro.org/features/fresh-and-stable/)，為避免滾動更新可能引發的相容性問題或錯誤，Manjaro有3個軟體庫:Stable、Testing、Unstable，Arch的滾動更新在經過Manjaro官方測試後才會正式發佈給Manjaro的使用者，所以Manjaro的滾動更新相對於Arch會有一定的延遲。至於安全性相關的更新則採用「快速追蹤」的做法，其有較高的優先測試等級，甚至是略過測試，以便盡快修復安全性問題。(↓官網圖片)\n![](https://manjaro.org/img/features/repositories.png)\n\n社群資源 :\b\b\b\b\n- [Manjaro Forum](https://forum.manjaro.org)\n- [Manjaro Wiki](https://wiki.manjaro.org/) / [Manjaro Wiki(繁中)](https://wiki.archlinux.org/index.php/Main_page_(正體中文) )\n- [Manjaro＠中文](https://manjaro-zh.blogspot.com/p/blog-page_7.html)\n\n＊Wiki頁面亦有列出官方推特、臉書與Reddit討論版的連結。另外，官方論壇雖然也有(簡體)中文討論區，但目前活躍程度跟Manjaro＠中文(繁體)討論區差不多...主要還是英文討論區較為活躍。\n\n### Install\nISO載點 : [官網](https://manjaro.org/download/)、[OSDN(含社群版本)](https://osdn.net/projects/manjaro/storage/)\n接下來就是找支閒置的4GB+ USB來製作開機隨身碟，燒錄工具推薦[BalenaEtcher](https://www.balena.io/etcher/)。完成後就使用這支隨身碟來開機，Manjaro啟動選項的驅動設定建議選擇non-free，進入桌面環境後啟動安裝程式~~然後就是下一步下一步下一步~~。\n![](https://i.imgur.com/BdZpaEz.png)\n\nManjaro的安裝就跟M$的作業系統一樣簡單沒啥好說😁\n\n### Setting\n\n核心切換\n![](https://i.imgur.com/VP0nbJW.png)\nMHWD - Manjaro Hardware Detection\n![](https://i.imgur.com/890z6MZ.png)\n\n#### Network\n\n↓DSL就是設定一般家用有線網路，例如CHT ADSL。\n![](https://i.imgur.com/i3sv4Dh.png)\n\n#### WiFi\n這部分有點折騰🤪，原本買了某知名A牌廠商的USB網卡，外盒寫了支援WIN、MAC、LINUX，而Manjaro早就內建該網卡的WiFi晶片驅動了...但無論是內建或是AUR下載來的，怎麼搞就是抓不到，我耗了好幾個晚上的時間在爬文跟測試，最後還在Manjaro Forum發問仍是沒有解決，於是我決定棄用(狀態顯示為很混怒)。\n\n查了一下直接買來TP-Link TL-WN722N，我他X什麼設定都沒搞！什麼驅動都沒裝！一插就爽！！！\n![](https://i.imgur.com/hp7z3aA.jpg)\n\n#### Chinese IME(Input Method Editor)\n中文輸入法安裝參考 : [Manjaro@中文](https://manjaro-zh.blogspot.com/2015/05/manjaro-linux-gcin.html)\n安裝gcin\n{% codeblock lang:bash %}\n$ sudo pacman -S gcin\n{% endcodeblock %}\n\n編輯.xprofile\n{% codeblock lang:bash %}\n$ kate ~/.xprofile\n{% endcodeblock %}\n寫入以下設定 :\n{% codeblock lang:bash %}\nexport GTK_IM_MODULE=gcin\nexport QT_IM_MODULE=gcin\nexport LC_CTYPE=zh_TW.UTF-8\nexport XMODIFIERS=\"@im=gcin\"\ngcin &\n{% endcodeblock %}\n\n打開terminal執行下列指令 :\n{% codeblock lang:bash %}\n$ sudo gtk-query-immodules-2.0 --update-cache\n$ sudo gtk-query-immodules-3.0 --update-cache\n{% endcodeblock %}\n\n然後重新登入即可使用。\n\n#### Google Chrome / Chromium\n{% codeblock lang:bash %}\n$ sudo pacman -S chromium\n$ sudo pacman -S google-chrome\n{% endcodeblock %}\n\n#### VS Code\n{% codeblock lang:bash %}\n$ sudo pacman -S code\n{% endcodeblock %}\n\n### MacOS-like KDE\n\n全域主題 : Glassy\n圖示 : McMojave-circle-dark\n游標 : McMojave-circle-dark \n安裝 Latte Dock桌面元件 :\n{% codeblock lang:bash %}\n$ sudo pacman -S latte-dock\n{% endcodeblock %}\n\n↓看起來跟Mac OS桌面環境有87%像🤣🤣🤣\n![](https://i.imgur.com/5xQmNUU.png)\n![](https://i.imgur.com/8jMN6Zb.png)\n![](https://i.imgur.com/W5KyxXn.png)\n![](https://i.imgur.com/EvXxv3m.png)\n\n虛擬桌面切換 :\n![](https://i.imgur.com/F2H0OyB.gif)\n\n### Update\n查詢Pacman Mirror來源\n{% codeblock lang:bash %}\n$ pacman-mirrors -l\n{% endcodeblock %}\n\n變更Mirror來源為Taiwan\n{% codeblock lang:bash %}\n$ sudo pacman-mirrors -t 5 -c Taiwan\n{% endcodeblock %}\n\n同步軟體庫＆更新\n{% codeblock lang:bash %}\n$ sudo pacman -Syyu\n{% endcodeblock %}\n\n![](https://i.imgur.com/yHCOIyM.png)\n\n### Troubleshooting\n原則上會在此條目持續紀錄自己使用Manjaro Linux所遇到的問題，特別是系統更新後\bOrz\n<br>\n\n#### Mojibake(Garbled Text)\n系統更新後若發生中文亂碼的情況，則需安裝字體並重新登入：\n{% codeblock lang:bash %}\n$ sudo pacman -S noto-fonts-cjk\n{% endcodeblock %}\n\n我所安裝的Noto Fonts為Google的開源字型，[Arch Wiki](https://tinyurl.com/uhwvs4w)亦有其他推薦的中文字體可選擇。\n\n#### Dolphin Launch Error\n系統更新後於啟動Dolphin時無法正常顯示檔案，並顯示錯誤訊息：\nUnable to create io-slave. klauncher said: Error loading '/usr/lib/qt/plugins/kf5/kio/file.so'\n\n在[Manjaro Forum](https://forum.manjaro.org/t/unable-to-create-io-slave-klauncher-said-error-loading-usr-lib-qt-plugins-kf5-kio-file-so/25866)找到問題的發生原因是Qt版本衝突導致的，因為系統當下仍載入舊版本Qt，然後我們執行了系統更新。\n\n重新啟動系統，或在terminal執行以下命令重新啟動Dolphin即可：\n{% codeblock lang:bash %}\n$ dbus-launch dolphin\n{% endcodeblock %}\n\n#### File Exists in Filesystem\n更新Packages時，下載完所有可更新項目時報錯，系統因偵測到檔案衝突而取消更新。\n例如我遇到的衝突提示是python-pasta這個套件，必須手動更新覆寫：\n{% codeblock lang:bash %}\n# sudo pacman -S {PACKAGE_NAME} --overwrite {PACKAGE_PATH}/* \n$ sudo pacman -S python-pasta --overwrite usr/lib/python3.8/site-packages/pasta/*\n# update packages again\nsudo pacman -Syyu\n{% endcodeblock %}\n\n#### The requested URL returned error: 404\n當我想在Manjaro系統安裝Node.js時卻得到這樣的回應，一度懷疑是鏡像來源有問題，但切換到其他來源還是同樣報錯。Arch討論區也有人發佈同樣的問題，原來是因為有段時間沒更新導致本機軟體包資料庫太舊 😅\n\n#### python-gast03 and python-gast are in conflict\n執行系統更新時遇到了這個軟體衝突導致無法進行更新，當我嘗試先移除python-gast時，系統又告知python-tensorflow-cuda依賴於此套件所以無法移除。只好手動更新python-tensorflow-cuda，然後系統就會詢問你是否要刪除衝突的python-gast套件...刪了它就解決此衝突問題了。\n\n#### failed to start Load/Save screen backlight brightness of backlight:acpi\n雖不影響日常使用，但每次開關機都會顯示警告訊息也是蠻令人在意的(>.<)\n編輯/etc/default/grub\b，在GRUB_CMDLINE_LINUX_DEFAULT設定值加入\b參數：acpi_backlight=native\n\n接著更新GRUB並重新啟動：\n{% codeblock lang:bash %}\n$ sudo update-grub\n$ reboot\n{% endcodeblock %}\n\n#### Error: resume: hibernation device '/dev/sda2' not found\n這和上面同樣是每次開關機都會顯示的警告訊息...(´_ゝ`)\n\n查詢/dev/sda2的UUID：\n{% codeblock lang:bash %}\n$ sudo blkid | grep /dev/sda2\n/dev/sda2: UUID=\"9e6297be-****-****-************\" TYPE=\"swap\" PARTUUID=\"********-**\"\n{% endcodeblock %}\n\n編輯/etc/default/grub\b，修改GRUB_CMDLINE_LINUX_DEFAULT設定值中的resume參數：\n{% codeblock lang:bash %}\nresume=UUID=9e6297be-****-****-************\n{% endcodeblock %}\n\n然後更新GRUB並重新啟動：\n{% codeblock lang:bash %}\n$ sudo update-grub\n$ reboot\n{% endcodeblock %}","tags":["linux","manjaro","kde"],"categories":["Linux"]},{"title":"Python批次加密PDF文件","url":"/python-pdf-batch-encrypt/","content":"又好一段時間沒更新了(忙，然後就2020年了...紀錄一下前陣子寫了段程式碼幫人處理批次加密PDF。\n<!--more-->\n\n### Description\n事實上這需求與薪資系統有關，我只知道那系統似乎很瞎，但人工處理這種大量重複性的問題更瞎🙄\n於是我們會有無數個PDF文件和一個txt文件，PDF內容是個人機密😎，而txt裡頭則是對照表，當程式讀進路徑下所有PDF文件後，會依照PDF檔名去對照每個人的ID Number，以作為PDF文件加密的密碼，然後使用PyPDF2這個模組來進行加密。需注意讀取跟寫入的檔名不能相同，因為加密完會遇到檔案已存在而無法回寫的情況，只好在讀檔之前一律先把檔名改為\"tmp.pdf\"，讀進來加密完再另存回原檔名，然後刪除\"tmp.pdf\"，如此完成一個PDF文件的加密。\n\n\b＊PDF檔名即為code，而txt檔裡頭的對照表有兩個欄位：code | id_number\n\n\n### Code\n{% codeblock lang:python %}\n# *** coding:utf-8 ***\nimport os, glob\nfrom PyPDF2 import PdfFileReader as pdfReader\nfrom PyPDF2 import PdfFileWriter as pdfWriter\n\n\ndef find_id_by_code(code, table):\n    pswd = \"123456\"  # default password\n    for i in table:\n        if code in i:\n            pswd = str(i).split()[1]\n            print(code, \"-->\", pswd)\n    \n    return pswd\n\nid = open(\"ID.txt\")\nID_table = list(id)\nid.close()\n\npdf_files = glob.glob(r\"*.pdf\")\nfor path in pdf_files:\n    code = path.replace(\".pdf\", \"\")\n    os.rename(path, \"tmp.pdf\")\n    in_file = open(\"tmp.pdf\", \"r+b\")\n    in_pdf = pdfReader(in_file)\n\n    out_pdf = pdfWriter()\n    out_pdf.appendPagesFromReader(in_pdf)\n    pswd = find_id_by_code(code, ID_table)\n    out_pdf.encrypt(pswd)\n\n    out_file = open(path, \"wb\")\n    out_pdf.write(out_file)\n\n    in_file.close()\n    out_file.close()\n    os.remove(\"tmp.pdf\")\n\ndel in_pdf, out_pdf\ninput(\"Encrypt Complete! Now you can close the window.\")\n{% endcodeblock %}\n","tags":["python","mytoolbox","pdf"],"categories":["Python"]},{"title":"大眾運輸x穿戴裝置x感應進站","url":"/apple-watch-with-ipass/","content":"自從改用icash 2.0搭台鐵以來，在感應進站的時候，明顯感覺icash 2.0需要大約2秒的感應時間😒 於是我想到並馬上設定了line pay一卡通，但想要做到「感應進站」這件事，似乎沒有這麼順利...<!--more-->當我仔細研究了line pay的「[乘車碼](https://www.i-pass.com.tw/IPS/Event/LINEPay-iPASS/an006.html)」功能，才知道\b\b目前僅有高雄捷運、高雄客運橘12以及東南客運橘20能用啊😬 另外，高雄捷運已經和Mastercard合作啦，所以是可以搭配Apple Pay或其他電子支付來感應進站的。\n\n花了點時間做資訊收集，總之，要用我手上的iPhone逼～進台鐵或搭公車目前還是做不到的(台鐵目前只允許台鐵E訂通產生的對號座QR碼讀取進站)。看來，只能透過「物理」的方式來達成我的需求了，目標是讓隨身物品附加上電子票證的功能，例如手錶。\n\n立馬找了網拍賣家，買來一卡通貼片，將錶帶用酒精清潔乾淨後，仔細地貼上。\n\n![](https://i.imgur.com/ZyhdWvs.png)\n![](https://i.imgur.com/A2ujMAY.png)\n![](https://i.imgur.com/jtjIOaj.png)\n\n\b之所以會選擇一卡通，是打算綁定到line pay一卡通帳戶上來使用其自動加值的功能。首先，到手機上的line pay頁面，點選設定-->連結一卡通-->輸入卡號，設定完成後，因為一卡通尚未完成記名設定，因此line pay會提示使用者要到全家FamiPort完成卡片更新。\n\n![](https://i.imgur.com/GoVhvle.png)\n![](https://i.imgur.com/joqo0wD.png)\n![](https://i.imgur.com/OytTTZS.png)\n\n\b\b不過...[自動加值](https://www.i-pass.com.tw/IPS/Event/LINEPay-iPASS/an009.html)只適用於一卡通的特約商店，不包含7-ELEVEN、台鐵、高鐵、公車、捷運等🙄 算了，反正我還是帶著Apple Watch到超商完成加值並開始使用了。\n\n---\n\n使用電子票證貼片來搭乘台鐵約一週後，我認為它是仍有改善空間的解決方案 :\n- 貼片的邊緣部分會沾黏灰塵而逐漸減弱黏性，黏貼的方式或許比較適合封閉的環境，例如前陣子爆紅的寶貝球悠遊卡或其他吊飾的內部\n- \b台鐵自動驗票閘門的感應區域在右側，但手錶配戴之慣用手則是因人而異，以我配戴於左手為例，感應進站需要稍微蹲低並轉動手腕才能順利感應...\n\n因為受不了貼片黏膠，就把貼片給撕下來了，錶帶整個黏呼呼的，還得用橡皮擦把殘膠嚕個乾淨。有了貼片的使用經驗，目前順利使用中的是網路賣家客製的電子票證手機貼片，但我可沒想再黏貼於任何地方了，就讓它在手機和保護殼之間的夾縫中生存吧，這樣一來無論是換手機還是換保護殼都很方便，搭乘台鐵就直接拿出手機來感應吧","tags":["apple watch","ipass","e-payment"],"categories":["Daily"]},{"title":"動手更換老舊的電源插座","url":"/replace-electrical-socket/","content":"\b\b\b突然想起很久、很久以前，似乎在五金賣場買了兩個插座要來更換，但買回來後就一直擱著...然後就忘了這件事😅<!--more-->雖然插座不知道為什麼某天就突然插不緊了，我一開始還以為是裡頭的簧片變形之類的，\b不過就一直忘了換，儘管插頭插上去不是很穩固，但也還算得上堪用。\n\n＊<span style=\"color:red;\">安全至上，插座是有電的，更換前務必切掉總開關。</span>\n\n但我終於想起來啦，趕緊把兩個放到長灰塵的新插座挖出來，開始拆掉舊的插座，卸下蓋板、轉開兩顆固定螺絲...草泥馬呀！😱我想說怎麼看起來怪怪的，原來是插座本體的塑膠外殼竟然劣化斷掉了，所以才會直接看到裡頭的簧片...我以為只是簧片變形 ＝＝\n![](https://i.imgur.com/VVpK0Au.png)\n\n接著用一字起子往電線旁紅圈處的卡榫插進去，就可以把電線給卸除了，不過我手邊沒有一字起子，所以用之前魚缸用的不鏽鋼長夾代替XD 如果怕忘了怎麼裝(或原本裝設的人裝反了)，卸除電線之前可以先拍照紀錄，通常紅色的為火線(有電)、白色的為水線(無電)，如果是三孔插座的話還會有綠色的接地線。\n\n話說這插座還真是裂得誇張...\n![](https://i.imgur.com/wID59J9.png)\n\n\b電線都卸除後就可以安裝新的插座啦，電線安裝的孔位旁邊會有圖示，較短的橫槓表示為火線安裝處，較長的橫槓則為水線，或有標示一個大寫英文字母W的字樣，中間則是接地線，務必確認電線有插到底不會鬆脫。而我當初買的是兩孔插座並沒有接地的設計，所以兩條接地線稍微整個線收好，就可以把插座面板鎖回去啦。\n\b\b\b![](https://i.imgur.com/hqiXjor.png)\n\n打開電源總開關測試一下插座是否安裝正確，裝上插座蓋板，完成～😎\n![](https://i.imgur.com/uLTa5wO.png)","tags":["DIY","plug socket"],"categories":["Daily"]},{"title":"南科自造基地研習Part 2","url":"/maker-space-workshop-part-2/","content":"人工智慧―自然語言處理與聊天機器人開發。\n<!--more-->\nPart 2於8/26 ~ 8/27在成大系統系館進行，講師為A.P. Wen-Hsiang Lu。\n\n### 研習內容大綱\n<br>\n- 自然語言處理(NLP)技術和應用簡介\n- 自然語言處理工具練習\n- 命名實體識別(NER)語意分析練習\n- 聊天機器人(ChatBot)實作練習\n---\n\n### 筆記\n<br>\n- NLP的最終目標—自動化的語言理解/處理/分析/推理\n- NLP的重要性—使人機互動能做到真正的「溝通」\n- 語言句法結構\n    - 例1：日文為SOV結構(動詞在句尾)\n    - 例2：原民語為VSO結構(動詞在句首)\n- 語言學相關知識類型\n    - 聲學知識(音譯)\n    - 詞彙學知識(字根)\n    - 詞性知識\n    - 文法知識\n    - 語意學知識\n    - 實用知識：情境如何影響句子的解釋\n    - 世界知識：\b\b\b我的理解是common sense，例如「I read an article about ＯＯＯ in the paper.」，我們會「直覺」地認為句子中的paper指的是「論文」。\n- NLP相關技術\n    - 概率與資訊理論\n    - 語言學知識\n    - 字彙/詞庫/語料庫/片語/詞義辨識\n    - Ｎ-gram語言建模／隱性馬可夫模型\n    - 詞性標記\n    - 文法解析\n    - 深度學習\n    - 計算語言學\n        - 語言描述：普遍性與跨語言研究\n        - 計算模型的實現\n            - 演算法與資料結構\n            - 知識表徵模型\n            - 推理過程模型\n    - 心理語言學\n        - 人類為語言理解可計算性的存在證明\n        - 心理學研究可以被用來解釋計算模型\n- NLP技術問題\n    - 龐大的字彙量/無數的現象與規則\n    - 不規則變化(例外、例外中的例外...)\n    - 字彙/情境/文法中的歧義\n    - 網路時代的多語言問題\n        - 語言障礙(人類語言據估算約有5000到7000種)\n        - 資訊過載\n- NLP相關應用\n    - 機器翻譯\n    - 自動語音識別\n    - (跨語言)資訊檢索\n    - (跨語言)問題回答\n    - 文本摘要\n    - 資訊抽取\n    - 對話系統/聊天機器人\n- NLP基本機率模型\n    - N-gram Language Model\n    - Hidden Markov Model(HMM)\n- NLP深度學習模型\n    - 模型發展：訓練結果的詞向量由非上下文相關 --> 上下文相關(詞彙於不同句子中有各自的向量表示)\n    - Word2Vec\n        - CBOW(Continuous Bag of Words)：利用周圍的詞預測中心的詞\n        - Skip-gram：利用中心的詞預測周圍的詞，訓練時間久、結果較CBOW準確\n    - RNN(Recurrent Neural Network)\n    - LSTM(Long Short-Term Memory)\n    - Seq2Seq(Sequence to Seqence)\n    - Seq2Seq with Attention\n- 命名實體識別(NER)\n    - 擷取文字資料中的人名、地名、組織名等目標實體進行分析、標記\n    - 模型構建\n        - Rule-based:\n            - Pos Tagging Pattern + statistic\n            - Dictionary-based\n        - Traditional ML-based:\n            - Hidden Markov Model(HMM)\n            - CRF(Conditional Random Field) + template\n        - DL-based:\n            - LSTM(Long Short-Term Memory)\n            - LSTM with Attention\n    - Viterbi Algorithm(維特比演算法)\n        - 動態規劃演算法\n        - 在語音辨識中，聲音訊號做為觀察到的事件序列，而文字字串被視為隱含產生聲音訊號的原因，因此可對聲音訊號應用維特比演算法尋找出最有可能的文字字串。\n    - CRF++：條件隨機域詞性標記工具\n- 線上工具\n    - [中研院E-HowNet繁體知網系統](http://ehownet.iis.sinica.edu.tw/index.php)\n    - [中研院CKIP中文斷詞系統](http://ckipsvr.iis.sinica.edu.tw)\n    - [中研院CKIP中文剖析器線上測試版](http://parser.iis.sinica.edu.tw)\n    - [Stanford Parser](http://nlp.stanford.edu:8080/parser/)\n\n### 實作練習\n\b\n#### 中文斷詞工具\n此工具使用了教育部國語辭典(16萬詞)來協助斷詞比對，練習用Python實作一個中文斷詞工具，大致上的概念為「先斷句，再斷詞」。\n\n程式範例：先用正則式比對各種標點符號進行斷句後，再逐句來處理斷詞。斷詞的部分，則是由左至右循序比對、抽取出句子中最長的詞，然後再比對剩下的句子...透過重複前述步驟來拆解句子。\n\b\b\b\b{% codeblock lang:py %}\n#!usr/bin/env python3\n# coding:utf-8\nimport re\nbook = {}\nresult = \"\"\n\n\ndef segment(sentences):\n    lines = re.split(r'[，。；：！？／（）「」『』【】]', sentences)\n    end = len(lines) - 1\n    if lines[end] == '':\n        del lines[end]\n    return lines\n\n\ndef compare(txt):\n    end = len(txt)\n    res = \"\"\n    while end != 0:\n        if txt[0:end] in book:\n            res = txt[0:end]\n            break\n        end -= 1\n    res = res if res != \"\" else txt\n    return res\n\n\ndef breakSen(txt):\n    global result\n    str_len = len(txt)\n    start = 0\n    end = str_len + 1\n    while start < str_len:\n        _slice = txt[start:end]\n        word = compare(_slice)\n        result += word\n        start += len(word)\n        if start != str_len:\n            result += \"/\"\n\n\nwith open('words.txt', 'r', encoding='utf-8') as file:\n    lines = file.read().splitlines()\n    for line in lines:\n        book[line] = line\ntxt = \"長頸鹿屬是一屬生長在非洲的反芻偶蹄動物，共有四個物種，是現存世界上最高的陸生動物。一般雄性個體高達4.8到5.5公尺高，重達900公斤。雌性個體一般要小一些。\"\nprint(\"\\ntxt : \\n\\n\", txt, \"\\n\")\nsentences = segment(txt)\nprint(\"segment : \\n\\n\", sentences, \"\\n\")\nfor s in sentences:\n    breakSen(s)\n    if s != sentences[len(sentences) - 1]:\n        result += \"/\"\nprint(\"result : \\n\\n\" + result, \"\\n\")\n{% endcodeblock %}\n\n![](https://i.imgur.com/1DFMiqJ.png)\n\n#### 聊天機器人\n使用Google Dialogflow負責NLP，並與Line Channel串接為可自動回應的Chatbot。網路上[基礎教學](https://www.appcoda.com.tw/chatbot-dialogflow-ios/)很多，因此設定過程省略，基本上就是建立一個Agent來負責處理回應的接收和傳送，在Agent底下可以建立Intents以及Entities來設定對話流程、關鍵字。\n\n![](https://i.imgur.com/NNhEuJO.png)\n![](https://i.imgur.com/WWiDs8E.png)\n![](https://i.imgur.com/Aqqcwxy.png)\n\n---\n\n### 心得\n<br>\n透過盧老師的詳細講解，讓大家了解到自然語言處理(NLP)所涉及包含社會科學等各方面的技術知識，以及在NLP領域還有許多難題尚待解決，如果少了NLP相關技術的話，未來的人機互動將會缺少相當重要的一塊，而人類的語言是如此多元、複雜，絕非單純把數據無腦地丟進深度學習模型就能解決(自從Google DeepMind讓阿發狗秀了一波騷操作後，人們聽到AI深度學習什麼的就像聽到傳說中的~~EX咖哩棒~~Excalibur呀😂)。\b\n\n經過Part 2的研習，對於NLP中所謂的「斷詞」總算是有較完整的概念了，雖然自己在工作上有寫過Line與Web聊天機器人，但我自己明白那有多粗糙，就只是抓取關鍵字做出相對的回應罷了，一點兒都不智慧😕雖然使用者還是會很認真和機器人對話，但看在龜毛的人眼裡是很介意的~~，我絕對不會承認我很介意~~。我想我接下來可以嘗試使用NLP來做點什麼，並從經驗中更進一步理解關於NLP的知識。\n\n感謝A.P. Wen-Hsiang Lu與助教們的用心講解，受益良多。","tags":["NLP","semantic analysis","chatbot"],"categories":["Workshop"]},{"title":"什麼是兒童急性壞死性腦病(ANEC)？","url":"/study-acute-necrotizing-encephalopathy-of-childhood/","content":"前幾天於PTT看到某篇[媽寶版的文章](https://www.ptt.cc/bbs/BabyMother/M.1566400996.A.FC7.html)，才知道如此令人心碎的疾病。<!--more-->作者的孩子(1Y10M)其病況始於突然反覆發燒，於短短幾天內病情便急轉直下、陷入昏迷，神經科醫師診斷可能有腦部損傷，疑似兒童急性壞死性腦病(ANEC)，經緊急安排腦部核磁共振檢查，結果發現視丘及腦幹受損相當嚴重！\b\b\b去年遇到相同狀況的[賴教授與其夫人](https://www.parenting.com.tw/article/5079996)得知此事，便和作者聯繫並給予鼓勵，我也和大家留言鼓勵作者，無論如何都希望奇蹟能出現。\n\n這樣的事令我感到相當震驚與難過，無知的我以為都2019年了，除了那些罕見遺傳性疾病，我們對於大多數的已知疾病應該都有所掌握才對...我這想法真可笑。出於好奇，我在網路上搜尋了關於ANEC的資訊，想知道關於其預防及治療的進展。\n\n---\n### 什麼是兒童急性壞死性腦病(ANEC)？\n\b\b\b吳昌騰醫師今年1月曾於其[臉書貼文](https://zh-tw.facebook.com/TaiwanPerDoctor/posts/268050263890017)說到：\n{% blockquote %}\n兒童急性壞死性腦病(acute necrotizing encephalopathy of children，ANEC)絕對是令兒科急診醫師人人驚心動魄的疾病。ANEC是一種高死亡率的腦病變，主要好發於日本、台灣和韓國。目前為止全世界已經有許多的病例報告。雖然致病機轉尚未完全明瞭，不過目前認為此病與人體的免疫系統和代謝有關。不同病毒皆能引發ANEC，包括A型及B型流感、副流感、帶狀泡疹病毒(水痘)、德國痲疹、HHV-6 及 HHV-8、腸道病毒及柯薩奇病毒 A9；ANEC亦分偶發性或遺傳性，死亡率達70%。ANEC具有病情急、進展快、死亡率高等特點，兒童患者常伴隨嘔吐、快速的意識喪失、不同程度肝功能障礙，預後差，存活者常伴有嚴重的神經系統後遺症。目前ANEC尚缺乏有效的治療方法，治療方法通常為支持療法，如抗生素、抗病毒藥物、IVIG等等治療。\n{% endblockquote %}\n\n＊「預後」: 疾病發生後，對疾病未來發展的病程和結果(痊愈、複發、惡化、致殘、 併發症及死亡等)的預測。\n\n### 疾病管制署致醫界通函第369號\n\b衛福部疾管署曾於今年2/26發佈[醫界通函](https://www.cdc.gov.tw/Bulletin/Detail/RZNFvB_786v_kT6tQ2HTBQ?typeid=48)，呼籲臨床醫師針對流感併發腦炎之病例提高警覺：\n{% blockquote %}\n全國醫界朋友，您好：\n\n國內自2018年10月1日起累計406例流感併發重症病例(以217例感染H1N1、166例感染H3N2為多)，34例死亡(21例H1N1、13例H3N2)，包含4名孩童死亡病例，其中3名孩童未接種本季流感疫苗。此4名死亡孩童皆併發腦炎，其病毒學檢驗結果皆為H1N1，又其發病至出現神經學症狀中位數為1天(範圍0–4天)，且病程快速惡化，雖均使用流感抗病毒藥物治療，仍於發病後2至5天內死亡。\n\n根據國內研究，兒童感染流感後約有1–2%出現腦炎症狀，然而其最嚴重的表現為急性壞死性腦病變(acute necrotizing encephalopathy)，死亡率可高達30-40%。<span style=\"color:red;\">疾管署籲請醫師提高警覺，於流感流行季，對於出現疑似腦炎的神經學症狀，如意識改變、抽搐、局部神經學症狀等個案，應儘速進行流感相關檢驗並使用流感抗病毒藥物</span>；另根據日本少數病例治療經驗，針對未侵犯腦幹之急性壞死性腦病變部分個案，早期使用類固醇可能對個案預後有幫忙，請臨床醫師評估個案狀況審慎使用。\n\n感謝您與我們共同維護全民的健康安全。\n{% endblockquote %}\n\n因為發現疾管署曾發佈此醫界通函，便找了找相關的新聞報導，但我對於ANEC的新聞搜尋結果感到疑惑，只找到幾則於今年2月所發佈關於流感併發腦炎的報導，這才提到兒童急性壞死性腦病這個詞...呵呵。\n\n### 相關文獻\n\n#### Acute necrotising encephalopathy of childhood: a new syndrome presenting with multifocal, symmetric brain lesions\nANEC\b係由[日本國立神經科學研究中心](https://www.ncnp.go.jp/nin/english/department.html)的Mizuguchi等人於1995年發表的[論文](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1073485/)所提出，文件中回顧了13位接受治療的連續患者與28份報告的病例記錄，描述日本兒童中普遍存在著一種未被識別的急性腦病類型之臨床病理學特徵，於呼吸道感染後，原本健康的兒童開始出現<span style=\"color:red;\">昏迷，抽搐，嘔吐，高燒以及肝腫大等症狀</span>。此急性腦病被認為是多發性兒童急性壞死性腦病的新型實體，<span style=\"color:red;\">電腦斷層掃描與核磁共振結果顯示，ANEC\b於視丘、白質、腦幹及小腦造成之腦損傷呈現對稱分佈</span>。\n\n#### Neuropsychological outcomes of childhood acute necrotizing encephalopathy\n此[論文](https://www.sciencedirect.com/science/article/abs/pii/S0387760419301627)描述了3位ANEC患者的神經心理學結果，研究於經歷ANEC後的18個月至10年之間，對患者長期認知與心理的影響。3個病例均表現出<span style=\"color:red;\">注意力不集中、精細動作困難(例如:書寫、下棋)、焦慮，甚至社交障礙</span>。長期損害的嚴重程度與急性症狀表現及恢復期的神經成像有關，這些研究結果強調了詳細的神經心理學評估和長期恢復之必要性。\n\n#### Acute Necrotizing Encephalopathy of Childhood with Novel Influenza A (swH1) Infection : A Case Report\n此病例報告為發表於童綜合醫學雜誌(2018，P.123-P.128)上的[論文](http://zh-tw.sltung.com.tw/uploadfiles/files/20190510_092057_4490.pdf)，病患為4歲8個月的女童，發病前相當健康。其初始症狀為間歇性發燒與嘔吐表現，隨著發生<span style=\"color:red;\">抽搐與快速的意識喪失</span>，以及鼻腔檢體分離出豬流感病毒，腦部神經成像出現典型的兒童急性壞死性腦病特徵。此女童於醫療團隊積極使用Oseltamivir(克流感)，搭配immunoglobulin(免疫球蛋白)和methylprednisolone(類固醇)治療後存活下來。\n\n---\n### 結論\n這幾天看了些相關資訊與近一年內的文獻，除上述所提到的，還有[ANEC患者之臨床特徵](https://jcpsp.pk/archive/2019/Jul2019/13.pdf)、[發展小鼠急性腦病模型以釐清致病機制](https://journals.sagepub.com/doi/abs/10.1177/1535370219846497)以及針對成人ANE患者的相關研究，於前述臨床特徵的研究中甚至發現，抗病毒藥物搭配免疫調節治療並未改變疾病進程。看來，ANEC至今仍是缺乏有效的治療方法，但我相信醫學研究很快就會找到答案的。","tags":["ANEC","influenza"],"categories":["Study"]},{"title":"南科自造基地研習Part 1","url":"/maker-space-workshop-part-1/","content":"\b系統晶片應用―以無線心律檢測為例。\n<!--more-->\nPart 1於8/14 ~ 8/16在成大系統系館進行，講師為Prof. Shuenn-Yuh Lee。\n\n### 研習內容大綱\n<br>\n- 應用於智慧互動照護與監控系統之體外感測網路簡介\n- 應用於身體感測網路之低功率無線心電訊號擷取電路與系統\n    - ZigBee\b\b\b無線心電訊號擷取系統晶片\n    - 身體感測網路之低功率無線心電訊號擷取與分類系統\n- 應用於神經調節之植入式身體感測網路\n- 應用於植入式身體感測網路之低功率雙向遙測裝置結合微型心臟起搏器\n---\n\n### 筆記\n<br>\n- IP-Based vs. Solution-Based\n- 遠距醫療照護服務的潛在市場與預期成長\n- 心肌於心搏週期中之極化、去極化、再極化\n- 心電圖(ECG)之P波、QRS波群和T波之簡易判讀\n- 從實驗室走向產品化所面臨的挑戰\n    - 居家照護系統\n    - 裝置續航力―低功耗設計\n    - 使用便利性―無線傳輸\n    - 訊號解析度對診斷精確度之影響\n    - 診斷結果對醫生與使用者之呈現\n- Wi-Fi/Bluetooth/ZigBee應用於穿戴式裝置無線傳輸之可行性評估\n- 無線生物訊號擷取SoC\b所整合之元件架構介紹\n    - 涉及過多電子學知識，個人認知無法消化...QQ\n- 植入式微型電刺激器之應用\n    - 心臟起搏器\n    - 人工耳蝸\n    - 人工視網膜\n    - 功能性神經肌肉電刺激器\n    - 膀胱控制\n    - 深層腦部電刺激\n\n### 實作練習\n- 使用HSPICE進行電路模擬測試驗證\n\n\b＊HSPICE筆記\n- 以電晶體、二極體、電阻和電容等各種電子元件模型為基礎，經數值模擬分析計算出電路中各結點之電壓、電流\n- 主要提供直流穩態(DC)、暫態(TRAN)以及小信號頻率響應(AC)的模擬，使用者可依照所設計之電路自行編寫模擬分析等控制指令\n- 語法規則\n    - 指令檔(.sp)第一行預設不會執行，使用慣例為撰寫標題用\n    - 英文字母大小寫無區分\n    - \b\b指令執行並無先後順序\n    - 註解符號為 '*'(星號)\n    - 指令檔需以 '.END'宣告結束\n    - 引入元件庫 : .lib 'filepath' TT\n    - 引入子電路 : .include 'filepath'\n    - 將引入元件庫指令放在.protect & .unprotect之間，可於模擬時不顯示元件之製程參數\n    - 宣告變數 : .param param_name = value\n    - 呼叫元件―MOSFET : M11 n1 n2 n3 n4 N_18 W=10u L=1u m=2\n        - M11的M代表MOSFET，11為自定義元件名稱，如同程式語言中的變數名稱\n        - MOSFET為四端元件，因此n1 ~ n4依序代表其D、G、S、B端點所連接的節點\n        - N_18表示呼叫元件庫中名稱為N_18的MOSFET元件\n        - W & L參數為指定MOSFET元件之寬度與通道長度\n        - m = 2代表將兩個Ｍ11元件並聯，此為“抽象上的並聯”，也就是說呼叫這個MOSFET元件時，實際寬度為W x m，當所需的MOSFET寬度超出製程規定區間時，可適當地利用此參數來做調整\n\n元件代號  |對應元件  \n:------:|:------:\nV       |Voltage Source\nI       |Current Source\nR       |Resistor\nL       |Inductor\nC       |Capacitor\nM       |MOSFET\nX       |Sub-Circuit\n\n控制指令 :\n\n指令       |作用  \n:--------:|:--------:\n.AC       |交流分析(頻率響應)\n.DC       |直流分析\n.OP       |靜態點分析\n.NOISE    |雜訊分析\n.TRAN     |暫態分析\n.SUBCKT   |定義子電路\n.ENDS     |子電路定義結束\n.OPTIONS  |設定參數及其他功能\n.PRINT    |指定輸出內容\n.PLOT     |視覺化輸出\n.TEMP     |指定模擬環境溫度\n.END      |指令檔編寫結束\n\n---\n\n### 心得\n<br>\n很幸運能參與自造基地這一系列的研習，關於Part 1的研習內容，雖然資工人沒學過電子學\b(我想我該找本電子學來研讀😅)，De Morgan's laws也不大記得了😂，但知識不嫌多，聽在心裡想在腦子裡，總是有個概念。而李教授除了課程內容，也講了許多受用的觀念，特別是Solution-Based的概念令我相當有感，投入職場至今確實見到台廠普遍沒有系統整合的概念，撇開台積電那樣將晶圓代工做到極致的特例不談，即使我們有先進工業製程能生產各種精密機械與零組件，卻無法發揮其最大價值，因為我們習慣當打工仔，不負責兜出完整的終端產品。\n\n\b\b\b研習課程的最後由李老師所指導的優秀博士生助教帶大家使用HSPICE來模擬電路，雖然我不懂如何完整編寫出模擬電路，但資工人對於電腦語言總是有點Sense😎，理解語法規則後，也是看得懂每一行在做些什麼的，例如元件庫和子電路的概念，就如同程式語言中的函式庫及自訂函式。\n\n感謝Prof. Shuenn-Yuh Lee與助教們的用心講解，受益良多。","tags":["ecg","wireless","hspice"],"categories":["Workshop"]},{"title":"MLP with Keras 手寫數字辨識測試","url":"/data-sci-ml-hello-world-mnist/","content":"## Load MNIST Data Set\n<!--more-->\n載入60000筆訓練數據與10000筆測試數據。\n{% codeblock lang:py %}\n(train_feature, train_label), (test_feature, test_label) = mnist.load_data()\n{% endcodeblock %}\n\n## Data Preprocessing\n<p>\n\n### Reshape\n將28x28特徵值Raw Data(圖片)轉換為32位元浮點數一維數據。\n{% codeblock lang:py %}\ntrain_feature_vector = train_feature.reshape(len(train_feature), 784).astype('float32')\ntest_feature_vector = test_feature.reshape(len(test_feature), 784).astype('float32')\n{% endcodeblock %}\n\n### Feature Normalization\n對特徵值進行正規化處理，也就是將數據按比例縮放至[0, 1]區間，且不改變其原始分佈，以收斂速度與預測精準度。\n{% codeblock lang:py %}\ntrain_feature_normal = train_feature_vector / 255\ntest_feature_normal = test_feature_vector / 255\n{% endcodeblock %}\n\n### One-Hot Encoding\n對離散型資料標籤進行獨熱編碼處理轉換為布林陣列，便於進行矩陣運算。\n{% codeblock lang:py %}\ntrain_label_onehot = np_utils.to_categorical(train_label)\ntest_label_onehot = np_utils.to_categorical(test_label)\n{% endcodeblock %}\n\n## Model Definition\n定義循序模型之結構、訓練方法、準確率評估\n{% codeblock lang:py %}\nmodel = Sequential()\n{% endcodeblock %}\n\n### Layer Definition\n定義輸入層、隱藏層、輸出層 :\n- Units : 784 -> 256 -> 10\n- 常態分佈亂數初始化weight＆bias\n- 隱藏層活化函數使用ReLU\n- 輸出層活化函數使用Softmax\n\n{% codeblock lang:py %}\nmodel.add( Dense(units=256, input_dim=784, init='normal', activation='relu') )\nmodel.add( Dense(units=10, init='normal', activation='softmax') )\n{% endcodeblock %}\n\n### Training Definition\n定義訓練方法 : \n- 損失函數為 CrossEntropy Loss\n- 優化器使用 Adam\n- 驗證數據分割比例為0.2(將6萬筆訓練數據進一步分割為4.8萬筆訓練數據和1.2萬筆驗證數據)\n- 訓練週期(epoch)為10\n- 每批次樣本數為200(因此一個訓練週期為4.8萬/200=240批次)\n\n{% codeblock lang:py %}\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(x=train_feature_normal, y=train_label_onehot, validation_split=0.2, epochs=10, batch_size=200, verbose=2)\n{% endcodeblock %}\n\n### Accuracy Evaluation\n{% codeblock lang:py %}\naccuracy = model.evaluate(test_feature_normal, test_label_onehot)\nprint('\\n[Accuracy] = ', accuracy[1])\n{% endcodeblock %}\n\n### Save & Load Model\n{% codeblock lang:py %}\n# save\nmodel.save(\"mdl_mlp_mnist.h5\")\n# load\nmodel = load_model(\"mdl_mlp_mnist.h5\")\n{% endcodeblock %}\n\n---\n## Full Code\n{% codeblock lang:py %}\n#!/usr/bin/env python3\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.utils import np_utils\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.models import load_model\nnp.random.seed(1234)  # for reproducibility\n\n\ndef showPredict(imgs, lbls, predictions):\n    plt.gcf().set_size_inches(10, 10)\n    for i in range(0, 10):\n        fig = plt.subplot(2, 5, i + 1)\n        fig.imshow(imgs[i], cmap='binary')\n\n        title = 'prediction = ' + str(predictions[i])\n        if predictions[i] != lbls[i]:\n            title += '(X)'\n\n        title += '\\nlabel = ' + str(lbls[i])\n        fig.set_title(title, fontsize=10)\n        fig.set_xticks([])\n        fig.set_yticks([])\n    \n    plt.show()\n\n\ndef mdlTrain(train_feature, train_label, test_feature, test_label):\n    # model definition\n    model = Sequential()\n\n    # input:784, hidden:256, output:10\n    model.add( Dense(units=256, input_dim=784, init='normal', activation='relu') )\n    model.add( Dense(units=10, init='normal', activation='softmax') )\n\n    # training definition\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    model.fit(x=train_feature, y=train_label, validation_split=0.2, epochs=10, batch_size=200, verbose=2)\n\n    # accuracy evaluation\n    accuracy = model.evaluate(test_feature, test_label)\n    print('\\n[Accuracy] = ', accuracy[1])\n\n    return model\n\n\n# load mnist data\n(train_feature, train_label), (test_feature, test_label) = mnist.load_data()\n\n# data preprocessing\n# reshape\ntrain_feature_vector = train_feature.reshape(len(train_feature), 784).astype('float32')\ntest_feature_vector = test_feature.reshape(len(test_feature), 784).astype('float32')\n\n# feature normalization \ntrain_feature_normal = train_feature_vector / 255\ntest_feature_normal = test_feature_vector / 255\n\n# one-hot encoding\ntrain_label_onehot = np_utils.to_categorical(train_label)\ntest_label_onehot = np_utils.to_categorical(test_label)\n\naction = input(\"1: Model Testing\\n2: Model Training\\n\")\nif action == \"1\":\n    print(\"Load mdl_mlp_mnist.h5\")\n    model = load_model(\"mdl_mlp_mnist.h5\")\n    prediction = model.predict_classes(test_feature_normal)\n    showPredict(test_feature, test_label, prediction)\n    del model\nelse:\n    print(\"===== Start training =====\")\n    model = mdlTrain(train_feature_normal, train_label_onehot, test_feature_normal, test_label_onehot)\n    model.save(\"mdl_mlp_mnist.h5\")\n    print(\"===== Model has been saved =====\")\n    prediction = model.predict_classes(test_feature_normal)\n    showPredict(test_feature, test_label, prediction)\n    del model\n{% endcodeblock %}\n\n![IPC8oCO.png](https://i.imgur.com/IPC8oCO.png)\n![qCt4QIA.png](https://i.imgur.com/qCt4QIA.png)\n\n---\n\n## Test Your Own Handwritten Numbers Image\n為了讓訓練好的模型預測看看資料集以外的圖片，我用FireAlpaca\b「手寫」了10張28x28的數字圖片😆，並將圖片命名為「真實數字_圖片順序編碼.jpg」這樣的格式，例如「8_image2.jpg」代表這張圖片為我製作的第2張圖片，內容為數字8，這樣的命名規則是為了方便讀取圖片時能從檔名擷取其label。\n\n### import blob & opencv\n{% codeblock lang:py %}\nfrom glob import glob\nfrom cv2 import cv2 as cv\n{% endcodeblock %}\nP.S. 在VS Code中若只寫「import cv2」的話會報錯...\n\n### data preprocessing\n{% codeblock lang:py %}\ndef get_test_process(files):\n    test_image = []\n    test_label = []\n    for file in files:\n        label = int(file[0:1])  # get label from file name\n        image = cv.imread(file, cv.IMREAD_GRAYSCALE)  # read image as grayscale\n        # retval, dst = cv.threshold(src, thresh, maxval, type[,dst])\n        image = cv.threshold(image, 120, 255, cv.THRESH_BINARY_INV)[1]  # binary invert\n        test_image.append(image)\n        test_label.append(label)\n\n    # list -> numpy.array\n    test_image = np.array(test_image)\n    test_label = np.array(test_label)\n\n    # reshape(flatten) & normalization\n    test_image_normal = test_image.reshape(len(test_image), 784).astype('float32') / 255\n    # one-hot encoding\n    test_label_onehot = np_utils.to_categorical(test_label)\n\n    return (test_image, test_label), (test_image_normal, test_label_onehot)\n{% endcodeblock %}\n\n### Prediction\n{% codeblock lang:py %}\nmodel = load_model(\"mdl_mlp_mnist.h5\")\nprint(\"=== Load mdl_mlp_mnist.h5 ===\")\nfiles = glob('*.jpg')  # find all images (path)\n\n# data preprocessing\n(test_image, test_label), (test_image_normal, test_label_onehot) = get_test_process(files)\n\nprediction = model.predict_classes(test_image_normal)\nshowPredict(test_image, test_label, prediction)\ndel model\n{% endcodeblock %}\n\n### Result\n哎呀，其中一張數字8的圖片預測錯誤😂\n![1eJE60d.png](https://i.imgur.com/1eJE60d.png)\n\n和數據集的圖片比較起來，我的手寫圖片經過影像處理完筆跡變得超細，或許特徵相對不那麼明顯吧，把原圖多點幾個像素上去再預測一次就過了呢。\n![0MsDeaK.png](https://i.imgur.com/0MsDeaK.png)\n\n---\n＊測試程式指定隨機亂數種子是為了[再現性](https://keras.io/zh/getting-started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development)\n\n＊下載MNIST數據集時若發生 [ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed](https://stackoverflow.com/questions/41691327/ssl-sslerror-ssl-certificate-verify-failed-certificate-verify-failed-ssl-c/41692664?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa)，在\b Terminal 執行以下命令 :\n{% codeblock lang:shell %}\n/Applications/Python\\ 3.6/Install\\ Certificates.command\n{% endcodeblock %}\n\n📄[Keras中文說明文件](https://keras.io/zh/)","tags":["keras","deep learning","mnist","computer vision"],"categories":["Data Science"]},{"title":"使用 Selenium 模組控制瀏覽器","url":"/data-sci-use-selenium-with-chrome-driver/","content":"自從開發環境轉移到 Mac OS 後，倒是沒有在這環境下測試用 Selenium 去控制瀏覽器，不過我並不想控制 Safari ，因為它不是一個跨平台的瀏覽器。\n<!--more-->\n第一次使用 Selenium 是學習 Web Crawler 的過程中發現，在瀏覽器中可見的物件並不代表一定爬得到(初心者😗)，於是我了解到那些自己抓不到的數據是由 JavaScript 所動態產生的，因為我向目標伺服器所發出的 request 只能取得靜態的數據，若要進行進階的動態網頁資料擷取，那麼我就必須學習如何用程式碼去控制瀏覽器。\n\n---\n## Install Selenium\n{% codeblock lang:bash %}\n$ pip3 install selenium\n{% endcodeblock %}\n\n## Download Chrome Driver\n要讓 Selenium 能夠控制 Chrome 瀏覽器，需要<span style=\"color:red;\">對應版本</span>的 [ChromeDriver](https://chromedriver.storage.googleapis.com/index.html)，例如我的 Chrome 為目前的最新版本 76.0.3809.100，那麼我就下載 ver.76 最新的 76.0.3809.68 版本 ChromeDriver，然後把 ChromeDriver 放在適當的路徑下，以便在程式中呼叫。\n\n## Test\n{% codeblock lang:py %}\n#!/usr/bin/env python3\n# coding:utf-8\n\nimport time\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\n\n\ndef getChrome(show=False):  # return chrome handler\n    WINDOW_SIZE = \"1366, 768\"  # screen size\n    CHROMEDRIVER_PATH = r\"/Users/nick/Downloads/chromedriver\"\n\n    options = Options()  # config\n    options.add_argument(\"log-level=3\")  # shut the logging\n    options.add_argument(\"--window-size=%s\" % WINDOW_SIZE)\n    if not show: options.add_argument(\"--headless\")  # headless mode\n\n    return webdriver.Chrome(CHROMEDRIVER_PATH, chrome_options=options)\n\n\nchrome = getChrome()\nchrome.get(\"https://laplacetw.github.io/categories/\")\ntime.sleep(1)\nchrome.save_screenshot(\"screenshot.png\")\nchrome.quit()\n{% endcodeblock %}\n\n測試程式若順利執行的話，在檔案目錄下應該會發現多了個執行畫面的截圖 :\n![5qmRipW.png](https://i.imgur.com/5qmRipW.png)\n\ngetChrome()預設會用 headless 模式啟動 Chrome，若想顯示使用者介面的話可以將 \"show\" 這個參數設為 True，如此便能看到自動化執行 Chrome 的過程。但實際應用的情況下非必要就別啟動圖形介面了，執行速度會快很多的😎","tags":["python","web crawler","selenium","chrome driver"],"categories":["Data Science"]},{"title":"關於 SharePoint REST API","url":"/sharepoint-rest-api/","content":"這是一段關於沒有伺服器權限的開發者\b於 SharePoint 進行網站開發的恐怖故事。\n<!--more-->\n這段故事實在是太可怕了，伺服器權限在資訊單位手裡，而完全不懂 SharePoint 也不會 .NET 的我只有使用者權限帳號(黑人問號.jpg)，看著一點幫助都沒有的 training kit 文件，我必須想辦法把它寫成一個入口網站...\n\n經過摸索研究最終想出了解決方法，我自製母版定義了導航列與頁腳，並利用內容編輯器這個 Web Part 在每個頁面「填入」我要的 HTML 內容，但不得不放棄內建的其他 Web Part，因為我根本無法完全控制那些頑固的東西，它們讓整個頁面佈局看起來相當糟糕!!!\n\n但如此我便擁有整個頁面內容的控制權了，前端頁面佈局樣式就交給 Bootstrap 去搞定啦，而後端就只能依賴 SharePoint REST API 去處理 CRUD。\n\n雖然很荒謬但我還是硬著頭皮上了，最後寫了個多功能的 SharePoint 企業內網 :\n\n- 公告\n- 行事曆(支援批次匯入事件)\n- 會議室預約\n- 工時追蹤填報(支援統計圖表)\n- 出勤狀況發佈(系統通知信)\n- 討論區\n- Smart Chat Bot(答覆公司系統與網站相關問題)\n\n這任務至此告一段落了，紀錄一下 SharePoint REST API 如何使用 : \n\n{% codeblock lang:js %}\nvar api_create = \"https://server/site/_api/web/lists('{ your_list_guid }')/items\",\n    api_read = \"https://server/site/_api/web/lists('{ your_list_guid }')/items( { your_list_item_id } )\",\n    api_update = \"https://server/site/_api/web/lists('{ your_list_guid }')/items( { your_list_item_id } )\",\n    api_delete = \"https://server/_api/web/lists('{ your_list_guid }')/items( { your_list_item_id } )\",\n    data ={\n        __metadata: { 'type': 'SP.Data.{ your_list_item_entity_type_fullname }' },\n        { list_column_name } : { value }\n    };\n \nfunction sp_create(api_create){\n    $.ajax({\n        url: api_create,\n        method: \"POST\",\n        data: JSON.stringify(data),\n        contentType: \"application/json; odata=verbose\",\n        headers:{\n            \"Accept\": \"application/json; odata=verbose\",\n            \"X-RequestDigest\": $(\"#__REQUESTDIGEST\").val()\n        },\n        success: function(res){\n            let data = res.d; // the data you create\n            // do something\n        },\n        error: function(error){\n            console.log(JSON.stringify(error));\n        }\n    });\n}\n \nfunction sp_read(api_read){\n    $.ajax({\n        url: api_read,\n        type: \"GET\",\n        headers: {\n            \"accept\":\"application/json; odata=verbose\"\n        },\n        success: function(res){\n            let data = res.d; // the data you read\n            // do something\n        },\n        error: function(error){\n            console.log(JSON.stringify(error));\n        }\n    });\n}\n \nfunction sp_update(api_update){\n    $.ajax({\n        url: api_update,\n        method: \"POST\",\n        data: JSON.stringify(data),\n        contentType: \"application/json; odata=verbose\",\n        headers: {\n            \"Accept\": \"application/json;odata=verbose\",\n            \"X-RequestDigest\": $(\"#__REQUESTDIGEST\").val(),\n            \"IF-MATCH\": \"*\",\n            \"X-Http-Method\": \"MERGE\"\n        },\n        success: function(res){\n            let data = res.d; // the data you update\n            // do something\n        },\n        error: function(error){\n            console.log(JSON.stringify(error));\n        }\n    });\n}\n \nfunction sp_delete(api_delete){\n    $.ajax({\n        url: api,\n        method: 'DELETE',\n        headers: {\n            \"Accept\": \"application/json;odata=verbose\",\n            \"X-RequestDigest\": $(\"#__REQUESTDIGEST\").val(),\n            \"IF-MATCH\": \"*\"\n        },\n        success: function(res){\n            // do something\n        },\n        error: function(error){\n            console.log(JSON.stringify(error));\n        }\n    });\n}\n \n/* filter & select & order(asc / desc)\n\"https://server/_api/web/lists('{ your_list_guid }')/items?$filter={ list_column_name } eq { keyword }&$select=ID,AuthorId,Created,...&$orderby={ list_column_name } desc\"\n*/\n\n{% endcodeblock %}\n\n特別留意 SharePoint REST API 返回的資料筆數預設值是100筆，這在我寫的會議室預約功能所依賴的資料庫筆數超過100之後，因為使用者反應預約完成的會議卻沒有顯示在頁面上而發現。此問題只要在 API 裡頭加上一個 \"TOP\"參數並指定返回的資料筆數即可解決，例如「TOP=5000」，而 API 能返回的最大值為5000筆。如果需要返回更多筆資料，印象中看過網路上相關討論，但我用在查詢會議室預約這樣有時效性的資料，估計5000筆已經綽綽有餘了XDD","tags":["web","sharepoint"],"categories":["SharePoint"]},{"title":"第一次吃樹莓派","url":"/rspi-meet-raspberry-pi-b3-plus/","content":"\b\b\b\b樹莓派3B+初始化安裝。\n<!--more-->\n\n![](https://i.imgur.com/wIdoqQ8.jpg)\n![](https://i.imgur.com/Dec2LcF.jpg)\n\n### \b\bOperation System\n參考了[IT技術家](http://blog.itist.tw/2016/12/34-best-operating-systems-for-raspberry-pi.html)所整理的作業系統清單，我決定直接安裝官方發行的Raspbian OS。\n\n- [Raspbian載點](https://www.raspberrypi.org/downloads/raspbian/)\n- [Raspbian安裝指南](https://www.raspberrypi.org/documentation/installation/installing-images/README.md)\n- [更新Raspbian](https://www.raspberrypi.com.tw/20004/faq-how-to-update-and-upgrade-raspbian/)\n\n由於Raspberry Pi是以SD Card\b\b來當硬碟([官方說明](https://www.raspberrypi.org/documentation/installation/sd-cards.md))，網路上大多建議儲存容量至少8G、寫入速度class 10，加上系統更新考量，於是我準備了一張儲存容量16G、寫入速度class 10的SD Card\b來當系統儲存空間，以及一支隨身碟來當資料儲存空間。不過官方有特別強調，較高的寫入速度並非記憶卡性能的唯一標準，因為寫入速度通常是藉由犧牲讀取速度和尋軌效能而提升的。\n\n>The card class determines the sustained write speed for the card; a class 4 card will be able to write at 4MB/s, whereas a class 10 should be able to attain 10 MB/s. However, it should be noted that this does not mean a class 10 card will outperform a class 4 card for general usage, because often this write speed is achieved at the cost of read speed and increased seek times.\n\nRaspbian鏡像檔目前有3種版本:\n- Raspbian Stretch with desktop and recommended software\n- Raspbian Stretch with desktop\n- Raspbian Stretch Lite\n![](https://i.imgur.com/c8sOf6D.png)\n\nRaspberry Pi安裝作業系統有許多方式，直接刷進去SD Card應該是最簡單的方式，官方推薦[Etcher](https://www.balena.io/etcher/)燒錄工具。\n![](https://i.imgur.com/lr2zQQi.png)\n\n\n### Connect to Wi-Fi Networks\n將作業系統刷進SD Card後，讓電腦重新讀取記憶卡，在根目錄下建立wpa_supplicant.conf，寫入網路連線參數，可寫入多筆。\n\n{% codeblock lang:conf %}\ncountry=TW\nctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev\nupdate_config=1\nnetwork={\n    priority=9\n    ssid=\"{SSID}\"\n    psk=\"{Password}\"\n    key_mgmt=WPA-PSK\n} \n{% endcodeblock %}\nP.S. 優先度Priority數字越大，優先度越高。\n\n### Remote\n<p>\nSSH連線預設為關閉狀態，如同無線網路設定，在根目錄下建立名稱為'ssh'的檔案即可強制啟用SSH連線。\n![](https://i.imgur.com/5X2bahA.png)\n\n我忘了在網路連線設定country參數，所以連線時系統有提醒可以進config設定。\n![](https://i.imgur.com/QI8vFEc.png)\n\n#### 在Raspberry Pi安裝VNC Remote Server\n{% codeblock lang:shell %}\n$ sudo apt-get install tightvncserver -y\n$ vncserver  # run server\n{% endcodeblock %}\n\n首次遠端桌面連線時，系統會要求設置連線密碼。\n{% codeblock lang:shell %}\npi@raspberrypi:~ $ vncserver\nYou will require a password to access your desktops.\n\nPassword: \nWarning: password truncated to the length of 8.\nVerify:   \nWould you like to enter a view-only password (y/n)? n\n\nNew 'X' desktop is raspberrypi:1\n\nCreating default startup script /home/pi/.vnc/xstartup\nStarting applications specified in /home/pi/.vnc/xstartup\nLog file is /home/pi/.vnc/raspberrypi:1.log\n{% endcodeblock %}\n\n#### 在Google Chrome安裝VNC Viewer擴充程式\n*[VNC Viewer for Google Chrome](https://chrome.google.com/webstore/iabmpiboiopbgfabjmgeedhcmjenhbla)\n\b\b\b\b\b\b![](https://i.imgur.com/mKcoeaT.png)\n\n連線Address需指定VNC Server Port，連接阜編碼規則為5900+Display編號。\ne.g. 192.168.0.2:5901\n![](https://i.imgur.com/fnD2RQc.png)\n![](https://i.imgur.com/dYVH37J.png)\n\n\n### Shutdown\n{% codeblock lang:shell %}\n$ sudo shutdown -h now\n{% endcodeblock %}","tags":["IoT","linux","raspberry pi"],"categories":["Raspberry Pi"]},{"title":"QArt Coder:客製化QR Code產生器","url":"/create-qrcode-with-image-by-qart-coder/","content":"~~這是一款真正的~~影像合成QR Code產生器😎<!--more-->\n\n無意間看到[電腦玩物的Esor大](https://www.playpcesor.com/2019/03/qart-coder-qr-code-logo.html)分享一個很特別的[QArt Coder](https://research.swtch.com/qr/draw)，於是我滿心期待地跑去試用，之前用過的QR Code產生器都是很直白地在QR Code正中央呈現一個縮圖，但這個QArt Coder是將影像用點陣圖的方式呈現～跟QR Code漂亮地結合在一起！\n\n這個線上工具介面並不複雜，圖片上傳後微調一下，接著點選Save this QR Code，頁面就會產生3種尺寸的QR Code讓人下載\n![](https://i.imgur.com/Z1UITpy.png)\n\n但下載的時候有點問題，所以我才寫了這篇XD 直接右鍵儲存影像的話，會發現下載了一個.html檔，在新分頁開啟影像或者下載得到的.html檔都是呈現亂碼的狀態(~~黃捷式~~白眼\n![](https://i.imgur.com/MZ0yKBM.png)\n\n只好檢查一下網頁原始碼，什麼在新標籤頁打開還是直接拷貝都是不起作用的，對著這張圖片的網頁元件按下**擷取螢幕快照**，就可以成功下載這些QR Code了，但上述是在Mac OS下的操作，我也挺好奇Win OS是否也有個相同狀況XD\n![](https://i.imgur.com/AN5xk3Q.png)","tags":["qr code"],"categories":["Tools"]},{"title":"Mac Safari網頁檢閱器顯示位置","url":"/mac-safari-show-web-inspector/","content":"這東西竟然困擾我兩天，我只記得在Safari檢視網頁原始碼的時候，意外點了某個按鈕，然後它就變成獨立視窗了、然後它就變成獨立視窗了、然後它就變成獨立視窗了...<!--more-->於是我開始把Safari的選單找了一遍又一遍，然後中文關鍵字搜尋只能告訴你該如何在Safari上面叫出這個網頁檢閱器🙄🙄🙄\n\n最後終於讓我發現，有個國外的老兄在網路上問了[How Do I Make the Web Inspector Appear In the Bottom Half Of My Browser Window?](https://macmost.com/forum/how-do-i-make-the-web-inspector-appear-in-the-bottom-half-of-my-browser-window.html)這樣的問題，我的老天鵝呀，感恩網路！讚嘆網路！\n\n原來我誤觸的按鈕，會讓網頁檢閱器顯示為獨立視窗\n![](https://i.imgur.com/EfnEXsd.png)\n\n按下置於視窗底部的按鈕就回到Safari的底部啦！\n![](https://i.imgur.com/lrdRwJV.png)\n\n因為這按鈕在<span style=\"color:red;\">全螢幕模式下不可見</span>，所以我才一直沒注意到這按鈕(傻眼)","tags":["mac","safari"],"categories":["Mac"]},{"title":"Google Apps Script ＋ Spread Sheet = 微後端","url":"/google-app-script-and-spreadsheet/","content":"若想以Google表單來做一個簡易的daily time tracking，提交一次表單就是一筆數據，但每天的時間總是會適當地分配，如此就得重複填寫並送出表單...這真是一個不聰明的方法，若自己寫的話因為某些原因難以避開CORS...就試著用Apps Script來解決這件事吧，我也沒寫過呢。<!--more-->\n\n### Create\n[Google Apps Script Doc : Web Apps](https://developers.google.com/apps-script/guides/web)\n\n> #### Requirements for web apps <p>\n> A script can be published as a web app if it meets these requirements:\n>\n> -It contains a doGet(e) or doPost(e) function.\n> -The function returns an HTML service HtmlOutput object or a Content service TextOutput object.\n\n首先建立Google雲端試算表和Apps Script，複製試算表網址“docs.google.com/spreadsheets/d/{Sheet ID}/edit#gid=0\"當中的{Sheet ID}，寫Apps Script的時候會需要這部分的資訊。\n<p>\n![](https://i.imgur.com/UiGda9u.png)\n\n若找不到Apps Script，點選連結更多應用程式，過濾Google的應用程式就能看到了，然後就將它連結至個人的雲端硬碟。\n![](https://i.imgur.com/4BsYTfE.png)\n\n建好表格欄位後就可以來寫App Script了\n![](https://i.imgur.com/NUIlhKk.png)\n\n### Apps Script\n{% codeblock lang:js %}\nfunction doGet(e) {\n  // parameter\n  var params = e.parameter,\n      date = params.Date,\n      name = params.Name,\n      proj = params.Proj,\n      hours = params.Hours,\n      des = params.Des;\n\n  // google sheet\n  var spreadSheet = SpreadsheetApp.openById({Sheet ID}),       # 需要Sheet ID\n      sheet = spreadSheet.getSheets()[0],  // focus on sheet 1\n      lastRow = sheet.getLastRow();\n  \n  // set value <= getRange(row, col)\n  sheet.getRange(lastRow + 1, 1).setValue(date);\n  sheet.getRange(lastRow + 1, 2).setValue(name);\n  sheet.getRange(lastRow + 1, 3).setValue(proj);\n  sheet.getRange(lastRow + 1, 4).setValue(hours);\n  sheet.getRange(lastRow + 1, 5).setValue(des);\n\n  // complete => return true\n  return ContentService.createTextOutput(true);\n}\n{% endcodeblock %}\n\napp script寫好之後，可以另外寫個debug.gs來執行看看\n{% codeblock lang:js %}\nfunction debug() {\n  var status = doGet({\n      \"parameter\": {\n        \"Date\" : \"2019-05-06\",\n        \"Name\" : \"LaplaceTW\",\n        \"Proj\" : \"Proj-19-05-06\",\n        \"Hours\" : \"4\",\n        'Des' :\"Daily Time Tracking\",\n      }\n   });\n  Logger.log(\"Status : %s\" , status);\n} \n{% endcodeblock %}\n\n沒問題的話，就部署為網路應用程式，部署成功後可取得API網址\n![](https://i.imgur.com/f6YkDkO.png)\n\n### Test\n<p>\n用瀏覽器的開發人員模式console發送request測試\n![](https://i.imgur.com/DNfVP7p.png)\n![](https://i.imgur.com/4dbIvcw.png)\n\n### Passing an array into Google Apps Script ?\n官方文件對參數的解釋是這樣的:\n>e.parameter\t\n>An object of key/value pairs that correspond to the request parameters. Only the first value is returned for parameters that have multiple values.\n>{\"name\": \"alice\", \"n\": \"1\"}\n\n>e.parameters\t\n>An object similar to e.parameter, but with an array of values for each key\n>{\"name\": [\"alice\"], \"n\": [\"1\", \"2\"]}\n\n但實際測試的時候我也遇到如同[Webduino官方教學文](https://tutorials.webduino.io/zh-tw/docs/socket/useful/google-sheet-1.html)所說的，怎麼試就是無法透過e.parameters這個欄位傳遞參數呀！最後我也採用了相同的做法(汗)，直接傳遞字串到Apps Script裡頭再分割數據。\n{% codeblock lang:js %}\n// doGet(e)\nvar params = e.parameter,\n    data = ['d1', 'd2', 'd3', 'd4', 'd5'],\n    len = data.length,\n    counter = 1.0;\n\nwhile(counter <= len){\n  var index = (counter - 1.0),\n      arr = params[data[index]];\n  if(arr != undefined){\n    arr = arr.split(',');\n    // set value <= getRange(row, col)\n    sheet.getRange(lastRow + counter, 1).setValue(arr[0]);\n    sheet.getRange(lastRow + counter, 2).setValue(arr[1]);\n    sheet.getRange(lastRow + counter, 3).setValue(arr[2]);\n    sheet.getRange(lastRow + counter, 4).setValue(arr[3]);\n    sheet.getRange(lastRow + counter, 5).setValue(arr[4]);\n  }\n  counter ++;\n}\n{% endcodeblock %}\n\n### Lock\n在透過Ajax對Apps Script發送請求寫入Spread Sheet的測試過程中，原本前端會對User填寫的每筆數據個別送出Ajax請求，雖然過於頻繁並非好的處理方式，但這也才讓我意識到同時間多個寫入請求的衝突及數據覆寫問題，所以後來整合成一次性的Ajax請求，改為在Apps Script處理、分割數據的方式。但這樣還沒解決衝突問題，偉大的Google當然也有考量到潛在的寫入衝突問題:\n\n> #### [Class Lock](https://developers.google.com/apps-script/reference/lock/)\n>\n> A representation of a mutual-exclusion lock.\n>\n> This class allows scripts to make sure that only one instance of the script is executing a given section of code at a time. This is particularly useful for callbacks and triggers, where a user action may cause changes to a shared resource and you want to ensure that aren't collisions.\n\n藉由鎖定Script的方式，確保每個時刻只會有唯一的讀寫動作，來避免衝突問題。另外，SpreadsheetApp.flush()的使用也需特別留意。\n{% codeblock lang:js %}\n// get a script lock for modifying a shared resource\nvar lock = LockService.getScriptLock();\nlock.waitLock(30000);\n\n// Do Something\n\n// you should call SpreadsheetApp.flush() prior to releasing the lock,\n// to commit all pending changes to the spreadsheet\nSpreadsheetApp.flush();\nlock.releaseLock();\n{% endcodeblock %}\n\n### Version\n這問題耗了我整天的時間在測試...當Script更新並重新部署後，接下來卻發現，Ajax送出的請求一直抓不到參數，每個欄位都是呈現Undefined的狀態，但Debug.gs測試結果卻正常的很!!! 真是見鬼了...折騰半天我從測試結果合理推測部署的Web App所執行的不是最新版本，我在Stack Overflow也有找到相關討論:\n- [POST to Google Apps Script web app does use latest version](https://stackoverflow.com/questions/18131157/)\n- [Apps script web change version for each deploy](https://stackoverflow.com/questions/49170665/)\n\n建立一個Web App再另外建立Apps Script把相關邏輯寫成library，然後在Web App去呼叫它，這是一種方式，但我覺得以簡單的應用而言太拐彎抹角了。只要修改並善用debug測試，確認沒問題後再部署為一個新版本，如此外部呼叫就不會有上述的舊版本問題。","tags":["google apps script","spread sheet"],"categories":["Google"]},{"title":"個人化NexT主題","url":"/hexo-next-optimize/","content":"2020/09/17更新。\n<!--more-->\n\b\b＊關於在本機伺服器正常運作，但部署後卻沒有生效的情況，單獨執行\"hexo d\"指令即可，\"hexo d -g\"之類的組合指令會使某些檔案沒有被推送到遠端伺服器上。\n\n---\n## SEO(Search Engine Optimization)\n<p>\n[Google Webmaster tools verification](https://www.google.com/webmasters)\n輸入網址前置字元(部落格網址)，Google提供許多驗證方法，而我選擇的是HTML標記方法，在Hexo根目錄找到/themes/next/layout/_partials/head/head.swig，貼上Google所提供的<meta>標記，部署後按下驗證即可。之後生成sitemap.xml放在根目錄下的public中，並於Google Console中設定提交。\n\n{% codeblock lang:js %}\n<meta name=\"google-site-verification\" content=\"{verification code}\" />\n{% endcodeblock %}\n![](https://i.imgur.com/Z9Kj7x3.png)\n![](https://i.imgur.com/ZQIQDI3.png)\n\n＊讓Hexo於部署時自動生成sitemap：\n在部落格根目錄下安裝sitemap generator\n{% codeblock lang:shell %}\nnpm install hexo-generator-sitemap --save\n{% endcodeblock %}\n接著在部落格根目錄下的_config.yml設定檔中寫入\n{% codeblock lang:yml %}\n# Sitemap\nsitemap:\n    path: sitemap.xml\n{% endcodeblock %}\n\n這樣每次編譯和部署的時候就會自動更新sitemap了。\n\n## Font Awsome Icon\nNexT自帶的版本為v4.7.0，到[官網](https://fontawesome.com/start)找新版本CDN連結，貼在/themes/next/layout/_partials/head/head.swig就能套用更多icon呢。\n![](https://i.imgur.com/bC6ng9U.png)\n\n＊引入新版本後部分icon可能會因為class name改變而無法顯示\n![](https://i.imgur.com/X0Umdjr.png)\n\n### Change Side Bar Icon\n檔案路徑:/themes/next/layout/_macro/sidebar.swig\n修改social icon相關程式碼為:\n{% codeblock lang:js %}\n{ if theme.social_icons.enable }  // ％符號會影響Code Block顯示因此在文章這裡移除\n    { set sidebarIcon = '<i class=\"' + link.split('||')[1] | trim | default('globe') + '\"></i>' }\n{ endif }\n{% endcodeblock %}\n如此在NexT Config就能直接設定Font Awsome的class name:\n{% codeblock lang:yml %}\nsocial:\n  GitHub: https://github.com/username || fab fa-github fa-lg\n  Linkedin: https://www.linkedin.com/ || fab fa-linkedin-in fa-lg\n  Twitter: https://twitter.com/ || fab fa-twitter fa-lg\n  E-Mail: mailto:username@gmail.com || fas fa-envelope fa-lg\n{% endcodeblock %}\n![](https://i.imgur.com/f2Ssx2y.png)\n\n### Change Post Icon\n檔案路徑:themes/next/layout/_macro/post.swig\n{% codeblock lang:js %}\n<span class=\"post-meta-item-icon\">\n    <i class=\"fas fa-calendar-alt\"></i>\n</span>\n\n<span class=\"post-meta-item-icon\">\n    <i class=\"fas fa-folder-open\"></i>\n</span>\n\n<span class=\"post-meta-item-icon\">\n    <i class=\"fas fa-comment-dots\"></i>\n</span>\n{% endcodeblock %}\n\n## Background Style\n檔案路徑:themes/next/source/css/_custom/custom.styl\n\b\b\b參考[Slanceli - 深度美化Hexo(NexT主题)](https://slanceli.top/2019/02/18/深度美化Hexo（NexT主题）/#more)\n\n{% codeblock lang:styl %}\n// Custom styles.\n@media screen and (min-width:1200px){\n    body{\t\n        background-image:url(/images/background.png);\n        background-repeat: no-repeat;\n        background-attachment:fixed;\n        background-position:50% 60%;\n    }\n\n    #footer a{\n        color:#eee;\n    }\n}\n\n// background\n.main-inner{\n    background: #fff;\n    opacity: 0.9;\n}\n\n// menu\n.header-inner{\n    background: #ffffffe8;\n    opacity: 1;\n}\n\n// footer\n.footer{\n    font-size: 14px;\n    color: #fff;\n}\n{% endcodeblock %}\n\n調整響應式斷點，讓行動裝置瀏覽也能顯示背景圖片：\n{% codeblock lang:styl %}\n@media screen and (min-width:768px){\n    body{\t\n        background-image:url(/images/background.png);\n        background-repeat: no-repeat;\n        background-attachment:fixed;\n        background-position:50% 60%;\n    }\n\n    #footer a{\n        color:#eee;\n    }\n}\n\n@media screen and (min-width:320px) and (max-width:768px){\n    body{\t\n        background-image:url(/images/background_768.png);\n        background-repeat: no-repeat;\n        background-attachment:fixed;\n        background-position:70% 0%;\n    }\n\n    #footer a{\n        color:#eee;\n    }\n}\n{% endcodeblock %}\n\n## Hyper-Link Style\n修改內文和項目中的超連結文字樣式：\n{% codeblock lang:css %}\n// hyper-link\n.post-body p a, .post-body li a{\n  color: #003D79;\n  border-bottom: none;\n  border-bottom: 1px solid #003D79;\n  &:hover {  // mouse hover\n    color: #0080FF;\n    border-bottom: none;\n    border-bottom: 1px solid #0080FF;\n  }\n}\n{% endcodeblock %}\n\n## Block Style\n修改側邊欄與文章區塊直角為圓角\n\n檔案路徑:themes/next/source/css/_variables/Gemini.styl\n修改參數如下 : \n{% codeblock lang:css %}\n$border-radius-inner              = 0 0 16px 16px;\n$border-radius                    = 16px;\n{% endcodeblock %}\n\n檔案路徑:themes/next/source/css/_schemes/Gemini/index.styl\n加入CSS :\n{% codeblock lang:css %}\n.sidebar {\n  background-color:transparent;\n}\n{% endcodeblock %}\n![](https://i.imgur.com/MpmS7WU.png)\n\n## Tag Cloud\n雖然NexT有內建標籤雲，因個人喜好故採用[第三方標籤雲](https://github.com/MikeCoder/hexo-tag-cloud)。\n\n## Mobile View Optimization\n於行動裝置瀏覽下，\bsub-title文字和nav-toggle之間的排版、文章標題與內文之間的margin太大，這兩個問題一直讓我覺得很礙眼，不過也一直沒有去調整它，但它終究讓我感覺到難以忍受了。\n\nsub-title於行動裝置瀏覽的時候使左右兩側padding增加15%：\n/themes/next/source/css/_common/components/header/site-meta.styl\n{% codeblock lang:css %}\n.site-subtitle {\n  margin-top: 10px;\n  font-size: $subtitle-font-size;\n  color: $subtitle-color;\n  \n  +mobile(){\n    padding-left: 15%;\n    padding-right: 15%;\n  }\n}\n{% endcodeblock %}\n\n調整文章標題與內文之間的margin-bottom為25px：\n/themes/next/source/css/_common/components/post/post-meta.styl\n{% codeblock lang:css %}\n.posts-expand .post-meta {\n  margin: 3px 0 25px 0;\n  color: $grey-dark;\n  font-family: $font-family-posts;\n  font-size: 12px;\n  text-align: center;\n}\n{% endcodeblock %}\n![](https://i.imgur.com/MzsUuNV.png)\n\n## Continue...","tags":["hexo","github pages"],"categories":["Hexo"]},{"title":"Python自動填寫Google表單","url":"/python-auto-fill-out-google-form/","content":"建個Google表單來測試：現任美國總統究竟是州普？卅普？還是川普？\n<!--more-->\n![](https://i.imgur.com/th41Uch.png)\n\n打開瀏覽器的開發人員模式，切換到Network Panel並試著送出一次表單，可見formResponse有相當明顯的數據傳輸。\n![](https://i.imgur.com/7EDofS9.png)\n\n展開查看詳情，在Header的部分可以找到剛才送出表單的資料結構，確定“entry.1216123536”就是所填寫的表單欄位，那麼可以開始寫程式了。\n![](https://i.imgur.com/O02YylJ.png)\n\n\n### Url\n<p>\n在Header摘要可見到url的格式為表單網址加上”/formResponse\"，使用縮網址會無法重導向至正確的表單位址。\n\n\n### Data\n{% codeblock lang:python %}\npayload = {\n    'entry.1216123536' : '',\n    'fvv' : '0',\n    'draftResponse' : '[]',\n    'pageHistory' : '0',\n    'fbzx' : '9150375950543103543'\n}\n{% endcodeblock %}\n\n### Code\n<p>\n為了讓程式的行為看起來不那麼程式(?)，設置隨機填寫欄位值與隨機延遲時間。\n{% codeblock lang:python %}\nimport re\nimport time\nimport random\nimport numpy as np\nimport requests as rq\n\nurl = 'https://docs.google.com/forms/d/e/********************/formResponse'\nparams = ['州普', '卅普', '川普']\npayload = {\n    'entry.1216123536' : '',\n    'fvv' : '0',\n    'draftResponse' : '[]',\n    'pageHistory' : '0',\n    'fbzx' : '9150375950543103543'\n}\n\nnum = 10  # number of executions\nperiod = np.arange(0.5, 5.0, 0.1)\ndelay = 0  # delay of execution\nwhile num > 0:\n    try:\n        payload['entry.1216123536'] = random.choice(params)  # random choice\n        res = rq.post(url, data=payload)\n        res.raise_for_status()\n        if res.status_code == 200 :\n            delay = round(random.choice(period), 2)  # round off to the 2nd decimal place\n            print('Fill Out : ' + payload['entry.1216123536'] + ' delay : ' + str(delay) + ' sec')\n            time.sleep(delay)\n    except rq.HTTPError:\n        print('HTTP Error!')\n    \n    num -= 1\n{% endcodeblock %}\n\n![](https://i.imgur.com/jKfaOP4.png)\n\n↓ 嗯，只有兩個人答對呢(?)\n![](https://i.imgur.com/zodJ6IR.png)\n\n### Note\n如果表單必須登入Google帳號，那就先登入吧：\n{% codeblock lang:py %}\nlogin_url = 'https://accounts.google.com/ServiceLoginAuth'\nlogin_data = {'Email': '{YOUR_GMAIL}', 'Passwd': '{YOUR_PASSWORD}'}\nsession = rq.session()\nsession.post(login_url, data=login_data)\n# do something...\n# e.g. session.post(form_url, data=payload)\n{% endcodeblock %}\n![](https://i.imgur.com/7TVq7Rq.png)","tags":["python","google form"],"categories":["Python"]},{"title":"Hexo on GitHub Pages:Icarus主題","url":"/hexo-theme-icarus/","content":"[NexT](https://theme-next.iissnan.com\")主題實在是太多人用了，看得有點膩，最近看到Icarus主題覺得很Blog(?)，決定來換個主題。\n<!--more-->\n\n## Download\n{% codeblock lang:shell %}\ncd blog\ngit clone https://github.com/ppoffice/hexo-theme-icarus.git themes/icarus\nhexo s  # run on local host\n{% endcodeblock %}\n![](https://i.imgur.com/KaGH5Gm.png)\n\n---\n## Config\n<p>\n參考[官方文件](https://blog.zhangruipeng.me/hexo-theme-icarus/categories/)，主要配置：\n\n### Favicon & Logo\n{% codeblock lang:yml %}\n# Version of the Icarus theme that is currently used\nversion: 2.3.0\n# Path or URL to the website's icon\nfavicon: /images/favicon.svg\n# Path or URL to RSS atom.xml\nrss: \n# Path or URL to the website's logo to be shown on the left of the navigation bar or footer\nlogo: /images/logo.svg\n{% endcodeblock %}\n＊ 推薦兩個SVG線上製作工具：[Image Vectorizer](https://www.vectorizer.io)、[SVG Editor](http://vectorpaint.yaks.co.nz)\n\n### Navbar & Footer\n{% codeblock lang:yml %}\n# Navigation bar link settings\nnavbar:\n    # Navigation bar menu links\n    menu:\n        Home: /\n        Archives: /archives\n        Categories: /categories\n        Tags: /tags\n        # About: /about\n    # Navigation bar links to be shown on the right\n    links:\n        GitHub_LaplaceTW:\n            icon: fab fa-github\n            url: 'https://github.com/laplacetw'\n# Footer section link settings\nfooter:\n    # Links to be shown on the right of the footer section\n    links:\n        CC BY 4.0:\n            icon: fab fa-creative-commons\n            url: 'https://creativecommons.org/licenses/by/4.0/'\n{% endcodeblock %}\n\n### Comment\n<p>\n評論系統使用DISQUS服務\n{% codeblock lang:yml %}\ncomment:\n    # Name of the comment plugin\n    type: disqus\n    enable: true\n    shortname: {disqus shortname}\n    count: true\n    lazyload: false\n{% endcodeblock %}\n\n### Wiget\n{% codeblock lang:yml %}\nwidgets:\n    -\n        # Widget name\n        type: profile\n        # Where should the widget be placed, left or right\n        position: left\n        # Author name to be shown in the profile widget\n        author: LaplaceTW\n        # Title of the author to be shown in the profile widget\n        author_title: learning by doing\n        # Author's current location to be shown in the profile widget\n        location: Taiwan, Earth\n        # Path or URL to the avatar to be shown in the profile widget\n        avatar: \n        # Email address for the Gravatar to be shown in the profile widget\n        gravatar: \n        # Whether to show avatar image rounded or square\n        avatar_rounded: false\n        # Path or URL for the follow button\n        follow_link: 'https://github.com/laplacetw'\n        # Links to be shown on the bottom of the profile widget\n        social_links:\n            Email:\n                icon: far fa-envelope\n                url: ''\n            Github:\n                icon: fab fa-github\n                url: ''\n            Linkedin:\n                icon: fab fa-linkedin\n                url: ''\n            RSS:\n                icon: fas fa-rss\n                url: /atom.xml\n    -\n        # Widget name (文章內容目錄)\n        type: toc\n        # Where should the widget be placed, left or right\n        position: right\n    -\n        # Widget name (友情連結)\n        type: links\n        # Where should the widget be placed, left or right\n        position: left\n        # Links to be shown in the links widget\n        links:\n            Hexo: 'https://hexo.io'\n    -\n        # Widget name (全站分類)\n        type: category\n        # Where should the widget be placed, left or right\n        position: left\n    -\n        # Widget name (最新文章)\n        type: recent_posts\n        # Where should the widget be placed, left or right\n        position: right\n    -\n        # Widget name (時間軸)\n        type: archive\n        # Where should the widget be placed, left or right\n        position: right\n    -\n        # Widget name (標籤雲)\n        type: tagcloud\n        # Where should the widget be placed, left or right\n        position: right\n{% endcodeblock %}\n＊ hyphen 為每個 Wiget 的起始，多一個少一個都會導致Error\n\n### Plugins\n<p>\n啟用不蒜子網站流量統計設定(預設為關閉)\n{% codeblock lang:yml %}\nplugins:\n    # BuSuanZi site/page view counter\n    # https://busuanzi.ibruce.info\n    busuanzi: true\n{% endcodeblock %}\n\n---\n![](https://i.imgur.com/DXsTbdB.png)\n![](https://i.imgur.com/9t5QT9J.png)\n更進一步個人化ICARUS主題的部分，例如調整文章版面配置、文末版權宣告等，網路教學的版本似乎都有點舊了，自己也是搞了很久...我懶得寫了，因為代碼高亮的問題一直無法順利解決，浪費太多時間了。一番折騰後我又換回NEXT...","tags":["hexo","github pages"],"categories":["Hexo"]},{"title":"Hexo on GitHub Pages:不蒜子統計失效","url":"/hexo-error-busuanzi/","content":"今天PO文後發現...所以我說那個文章閱讀次數呢?頁面底部的流量統計也消失了。\n<!--more-->\n推測是.js檔出了什麼問題，先到[不蒜子](https://busuanzi.ibruce.info)的頁面瞧瞧，發現一行小小的紅字，寫著「因七牛強制過期『dn-lbstatics.qbox.me』域名，與客服溝通無果，只能更換域名到『busuanzi.ibruce.info』!」，雖然不知道七牛到底是什麼牛，但可以確定問題來源是域名更換。\n\n## Solution\n<p>\n在NexT資料夾中找到不蒜子的設定檔，路徑為layout/_third-party/analytics/busuanzi-counter.swig\n![](https://i.imgur.com/rpVQnFj.png)\n\n修改.js路徑為:\n{% codeblock lang:html %}\n<script async src=\"https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js\"></script>\n{% endcodeblock %}\n\n\b重新\bdeploy後便會發現統計數字又回來啦。","tags":["hexo","github pages"],"categories":["Hexo"]},{"title":"Excel:公式、圖表與樞紐分析","url":"/excel-func-chart-pivot-table/","content":"常用公式、圖表與樞紐分析之基本操作。\n<!--more-->\n\n# 常用公式\n<br>\n## IF\n- 用法:IF(條件,符合條件,不符合條件)\n- 範例:判斷訂單金額是否大於70(億)\n![](https://i.imgur.com/wQeP7th.png)\n\n## 多重條件判斷\n- 用法:IF(條件,IF(...),不符合條件)\n- 範例:呈上例，進一步做訂單金額分級\n![](https://i.imgur.com/27kZEy2.png)\n\n## SUM\n- 用法:SUM(範圍1,範圍2...)\n- 範例:計算化學品與塑膠/橡膠年度訂單金額加總\n![](https://i.imgur.com/krLlYE2.png)\n\n## MAX\n- 用法:MAX(範圍1,範圍2...)\n- 範例:找出各類別每月訂單金額中最高者\n![](https://i.imgur.com/uDmIaxx.png)\n\n## INT/ROUND\n- 用法:INT(儲存格)/ROUND(儲存格,小數位數)\n- 範例:INT無條件捨去/ROUND四捨五入\n![](https://i.imgur.com/sZLMI11.png)\n\n## AVERAGE\n- 用法:AVERAGE(範圍1,範圍2...)\n- 範例:計算年度平均值之無條件捨去與四捨五入\n![](https://i.imgur.com/F8FyAzn.png)\n\n## SUMIF\n- 用法:SUMIF(條件範圍,條件,合計範圍)\n- 範例:計算各種商品之銷售總額\n![](https://i.imgur.com/xz1FZ5Z.png)\n\n## COUNTIF\n- 用法:COUNTIF(條件範圍,條件)\n- 範例:統計年度化學品訂單金額分級\n![](https://i.imgur.com/V7LXB0g.png)\n\n## VLOOKUP\n- 用法:VLOOKUP(搜尋條件,範圍,目標欄位,精確度)\n- 範例:搜尋指定月份訂單金額\n![](https://i.imgur.com/sa39mn2.png)\n\n## 多條件搜尋\n- 用法:LOOKUP(1,0/((條件1)*(條件2)*...),目標範圍)\n- 範例:尋找訂單金額分級為Ａ級且大於100(億)之月份\n![](https://i.imgur.com/kJxlPKI.png)\n\n## 重點整理\n\n公式     |說明  \n:------:|:------:\nIF      |條件式\nSUM     |加總\nMAX     |最大值\nINT     |無條件捨去\nROUND   |四捨五入\nAVERAGE |平均值\nSUMIF   |有條件加總\nCOUNTIF |有條件統計\nVLOOKUP |尋找      \n\n---\n# 常用圖表\n<br>\n## 錯誤範例\n說明:折線圖所表達的為<span style=\"color:red;\">趨勢、變化</span>，而下圖中\b\b\b\b\b\b水平軸項目為類別，離散型數據不具連續性，這樣的圖表**不具任何意義**，應使用直條圖比較各項目之大小，或使用圓形圖呈現各項目佔整體之比重。\n![](https://i.imgur.com/UswDs8J.png)\n\n## 基本設定\n- 圖表設計與格式設定在圖表工具的頁籤中\n- 圖表項目細部設定在圖表右側的\"＋\"號中\n![](https://i.imgur.com/67Z3T4H.png)\n\n## 直條圖\n- 使用時機:做<span style=\"color:red;\">比較</span>，呈現數據的「相對大小」\n- 範例:100年度化學品外銷月訂單金額比較\n![](https://i.imgur.com/sHPqEjn.png)\n\n## 堆疊直條圖\n- 範例說明:呈現整體營業額與個別業務人員表現，可明顯看出業務A(藍色區塊)與業務C(灰色區塊)的成長與衰退，以及對整體的影響。\n![](https://i.imgur.com/UcZuOEu.png)\n\n## 折線圖\n- 使用時機:讀<span style=\"color:red;\">趨勢</span>，呈現數據的「變化、走勢」\n- 範例:100年度化學品外銷月訂單金額走勢\n![](https://i.imgur.com/FATm3bE.png)\n\n## 圓形圖\n- 使用時機:看<span style=\"color:red;\">比例</span>，呈現數據的「相對比例」\n- 範例:\b100年度外銷訂單項目比重\n![](https://i.imgur.com/TBfdio3.png)\n\n## 重點整理\n\b數據視覺化須依據所欲呈現之數據統計摘要，進而選擇適當的圖表形式，避免<span style=\"color:red;\">誤用圖表、為分析而分析</span>。\n\n- 直條圖:做<span style=\"color:red;\">比較</span>\n- 折線圖:讀<span style=\"color:red;\">趨勢</span>\n- 圓形圖:看<span style=\"color:red;\">比例</span>\n\n---\n# 樞紐分析\n以經濟部101-106年外銷美國訂單統計資料為例。\n\n## Step 1:選取數據範圍\n**數據範圍中不允許空白欄位**\n\n![](https://i.imgur.com/joDfNB9.png)\n\n## 欄位說明\n- 篩選:報表之篩選條件\n- 欄  :樞紐分析表<span style=\"color:red;\">行</span>數據\n- 列  :樞紐分析表<span style=\"color:red;\">列</span>數據\n- 值  :欲統計之數據，例如加總、平均值\n\n![](https://i.imgur.com/UH01LrN.png)\n\n## Step 2:拖曳調整欄位與排列順序\n![](https://i.imgur.com/E8Alrt1.png)\n↓點選值欄位設定可選擇其他計算類型\n![](https://i.imgur.com/tEI1LCA.png)\n\n## Step 3:插入樞紐分析圖\n樞紐分析工具(頁籤) --> 分析 --> 樞紐分析圖\n\n![](https://i.imgur.com/2bgZqAX.png)\n\n## 樞紐分析-堆疊直條圖\n![](https://i.imgur.com/UGRPdUl.png)\n\n## 樞紐分析-圓形圖\n**注意圖表的行列數據呈現是否合適**\n\n![](https://i.imgur.com/B5bdN0S.png)\n↓調整行列數據\n![](https://i.imgur.com/0WAn7Aa.png)\n↓調整後\n![](https://i.imgur.com/itrWKwo.png)","tags":["excel","pivot table"],"categories":["Excel"]},{"title":"Django2.0筆記(3):軟體架構","url":"/django-software-architecture/","content":"模型、視圖與模板。\n<!--more-->\n\n## Model–View–Controller\n- Model: 資料庫存取\n- View:  使用者介面\n- Controller: 控制整合\n\n說到網頁開發，就不得不提一下MVC架構，維基百科如是說：MVC為軟體工程中的一種軟體架構，將軟體系統分為三個部分：模型(Model)、視圖(View)和控制器(Controller)，目的是為了實現一種<span style=\"color:red;\">動態</span>的程式設計，使後續對程式的修改及擴充簡化，並且使程式某一部分的重複利用成為可能。\n\nMVC是一種<span style=\"color:red;\">設計理念</span>而非技術，旨在提高開發項目的可擴展性及可維護性，而這樣一個從實際開發所歸納出來的抽象概念，事實上其定義是相當模糊的，尤其是在經過了多年發展後...\b在Django筆記就不多做探討了。\n\n## Model-Template-View\n- Model: 資料庫存取\n- Template: 使用者介面\n- View:  控制整合\n\nDjango雖然看似獨樹一格自定義了MTV架構，但MTV和MVC的概念是相同的，我嘗試畫了架構對照圖：\n![](https://i.imgur.com/vAeWv7K.png)\n以較為白話的方式來描述MTV架構，就是依開發需求去定義Model在資料庫中生成對應的Table，透過View所定義的程式邏輯去整合、控制數據，再交由負責前端的Template呈現給使用者，而使用者亦是透過Template和後端數據做互動。\n\n我認為Django初學者只是抽象地討論MTV是無法很好地理解其互動關係的，還是喜歡learning by doing。","tags":["python","django","web"],"categories":["Django"]},{"title":"Django2.0筆記(2):專案設定與應用程式","url":"/django-app-and-settings/","content":"專案下的環境設定、如何建立Django App。\n<!--more-->\n\n## Settings.py\n\n在Windows terminal透過tree指令可查看專案結構\n![](https://i.imgur.com/19G7Lvu.jpg)\nMac環境下要使用tree指令則需另外安裝package :\n{% codeblock lang:shell %}\nbrew install tree\n{% endcodeblock %}\n從專案結構可以發現，根目錄下有個和專案名稱相同的資料夾，其中主要有3個檔案:\n- settings.py : 專案設定檔\n- url.py      : 網頁路徑設定\n- wsgi.py     : 伺服器閘道介面設定\n\n＊ manage.py為負責專案管理的Python指令檔\n＊ 什麼是WSGI(Web Server Gateway Interface)? 簡而言之，WSGI就是Server與Web App之間的溝通介面\n\n開啟settings.py，可以看到官方註解寫得挺詳細的，主要設定：\n\n- 除錯模式設定為True表示網頁拋出Error會直接顯示錯誤訊息，正式發佈網站前務必記得關閉，以免網站弱點就這麼公開了(汗)\n{% codeblock lang:shell %}\n# SECURITY WARNING: don't run with debug turned on in production!\nDEBUG = True\n{% endcodeblock %}\n\n- 新建立的App必須在這裡被定義\n{% codeblock lang:python %}\n# Application definition\nINSTALLED_APPS = [\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n    ‘{app_name}’,\n]\n{% endcodeblock %}\n\n- 網頁模版路徑\n\n在專案目錄下建立templates資料夾:\n{% codeblock lang:shell %}\nmd templates  # build folder for web templates\n{% endcodeblock %}\n＊ Mac terminal建立資料夾指令和Linux同為mkdir\n\n接著在settings.py中設定路徑，於TEMPLATES中的'DIRS'加入：\n<span cstyle=\"color:red;\">os.path.join(BASE_DIR, 'templates')</span>\n{% codeblock lang:python %}\nTEMPLATES = [\n    {\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'DIRS': [os.path.join(BASE_DIR, 'templates')],\n        'APP_DIRS': True,\n        'OPTIONS': {\n            'context_processors': [\n                'django.template.context_processors.debug',\n                'django.template.context_processors.request',\n                'django.contrib.auth.context_processors.auth',\n                'django.contrib.messages.context_processors.messages',\n            ],\n        },\n    },\n]\n{% endcodeblock %}\n\n- 語系、時區\b:修改為繁體中文、台灣時區\n{% codeblock lang:python %}\nLANGUAGE_CODE = 'zh-Hant'\n\nTIME_ZONE = 'Asia/Taipei'\n{% endcodeblock %}\n\n- 靜態文件路徑\n\n在專案目錄下建立static資料夾:\n{% codeblock lang:shell %}\nmd static  # build folder for static files(e.g. css, images...)\n{% endcodeblock %}\n接著在settings.py中設定路徑，於\"STATIC_URL\"後面加上:\n{% codeblock lang:python %}\nSTATICFILES_DIRS = [\n    os.path.join(BASE_DIR, 'static'),\n]\n{% endcodeblock %}\n\n---\n## Django App\n建立應用程式，專案底下可建立多個App，而每個App都可以視為Package\n{% codeblock lang:shell %}\n# start virtual environment first\ncd {project_name}\npython manage.py startapp {app_name}  # build application\n\npython manage.py makemigrations {app_name(optional)}  # build data migration for database\npython manage.py migrate {app_name(optional)}  # data synchronization\n{% endcodeblock %}\n\n＊ makemigrations與migrate為資料庫同步設定，預設為對所有應用程式同步，因此應用程式名稱為選填","tags":["python","django","web"],"categories":["Django"]},{"title":"Django2.0筆記(1):初始化設定","url":"/django-start/","content":"近期耗費大量心力在學習Django，因為Google搜尋到的教學文多數版本停留在Django 1.x，對初學者來說略過太多細節。<!--more-->作為WEB初學者，Django有許多概念並不是很直觀，必須實際測試來幫助自己理解。目前所使用的版本為Django 2.1，於是我踩了相當、相當多的坑，感謝無數撰寫教學文的高手前輩讓自己學習了很多。在各種線索的拼湊之下、終於讓Django Project在Apache Server順利運作了(汗)。\n\n\n# Django:Virtual Environment & New Project\n雖然網路上有許多教學文，但最詳細也最可靠的還是官方文件：[Django2.1 Doc](https://docs.djangoproject.com/en/2.1/)。\n\n\n## Virtual Environment for Django\n開發Django Project建議另建一個乾淨的虛擬環境，只安裝專案所需套件，Python環境建置就不贅述，從安裝及建立虛擬環境開始:\n{% codeblock lang:shell %}\npip install virtualenv  # install virtual environment package\ncd c:\\\nvirtualenv {virtualenv_name}  # build virtual environment for Django\n\ncd {virtualenv_name}\nScripts\\activate  # start virtual environment\npip install django  # install Django package\ndeactivate  # stop virtual environment\n{% endcodeblock %}\n＊ 在Mac環境下啟動虛擬環境的指令為source bin/activate\n＊ 提示字元前面的(virtualenv_name)表示目前已啟動虛擬環境\n\n\n## Start New Django Project\n{% codeblock lang:shell %}\n# start virtual environment first\ndjango-admin startproject {project_name}  # build new project\n{% endcodeblock %}\n\n## Run Django Server\n{% codeblock lang:shell %}\n# start virtual environment first\ncd {project_name}\npython manage.py runserver\n{% endcodeblock %}\n\n＊ 在專案目錄下成功啟動測試Server後，在瀏覽器輸入127.0.0.1:8000，應該要看見以下畫面：\n![](https://i.imgur.com/9pdBamW.jpg)","tags":["python","django","web"],"categories":["Django"]},{"title":"兩個月後的魚缸","url":"/restart-planted-tank-2month/","content":"近況更新。\n\n- 前景的牛毛氈因為長得過高更換為很趴又很會爬的新大珍珠草\n- 綠宮廷一直縮頂...只好汰除...我還得多努力\n<!--more-->\n- 後景增加了紅雨傘...但好景不常，其實是我不會照顧呵，變成綠雨傘了ＱＱ\n- 藍綠藻解決後換黑毛藻...石頭全拿掉...開始投藥(TBS)，目前蝦子全掛ＱＱ\n- 珊瑚莫斯沈木因黑毛藻而被檸檬酸處理後看起來了無生機，目前有恢復的跡象\n\n\n↓紅雨傘剛種植＋紅宮廷重新種植後的樣子(汗)\n![](https://i.imgur.com/po1wwVW.jpg)\n\n![](https://i.imgur.com/UL8a4xC.jpg)\n\n我想，之後重新整理，可能會換成一呎的魚缸，然後底土一樣矽沙，但會嘗試鋪設基肥，大概會用洗衣袋裝著吧，免得造成日後矽沙要重複使用的麻煩。\n\n再努力。\n","tags":["aquarium","planted tank"],"categories":["Aquarium"]},{"title":"正則式與re模組","url":"/data-sci-re/","content":"什麼是正則式(Regex)？常見的說法有正規表示式、正則表達式...等等，維基百科是如此描述的：使用單個字串來描述、符合某個句法規則的字串。在很多文字編輯器裡，正則運算式通常被用來檢索、替換那些符合某個模式的文字，總之就是「描述某種規則的表達式」。\n<!--more-->\n舉例來說，email address其格式具有一定規則，假設要在一堆密密麻麻的html中尋找Gmail郵件地址，就必須使用正則式來描述過濾規則，讓程式能準確判斷出符合Gmail郵件地址格式的字串。\n![](https://i.imgur.com/lZufQJS.png)\n\n## Pythex\n上述示範如何用正則式表達Gmail郵件地址規則的網站為[pythex.org](https://pythex.org)，可以用來驗證Regex正確與否，因為Regex的符號有點複雜，該頁面也相當貼心地放了速查表呢～只要按下regular expression cheatsheet按鈕即可查看。\n![](https://i.imgur.com/DIorI8v.png)\n\n## re module\n在Python中使用正則式需要import re模組，常用的方法有search()、match()、findall()等，可參考[官方文件](https://docs.python.org/2/library/re.html)以取得更詳盡的說明。\n\n\b那麼，search跟match有什麼不同呢？這是我一開始對這兩個方法的疑問，那就[看看官方文件怎麼說](https://docs.python.org/2/library/re.html#search-vs-match)，但實際編寫程式碼會幫助自己理解兩者間的差異。\n\n根據官方文件的解釋：re.match() checks for a match only at the <span style=\"color:red;\">beginning</span> of the string, while re.search() checks for a match <span style=\"color:red;\">anywhere</span> in the string.\n\n- match的搜尋方式為「從字串起始開始搜索，遇到不符合的字元便停止」\n- search的搜尋方式為「整個字串」\n\n個人覺得最常用到的應該是findall()，比對所有符合規則的字串並返回串列：\n{% codeblock lang:py %}\nimport re\n\nstr_ =  '_.Aa123Bb456Cc789Dd3.14'\n\nfind_alphabet = re.findall(r'[A-Za-z]+', str_)\nprint(find_alphabet)  ＃ ['Aa', 'Bb', 'Cc', 'Dd']\n\nfind_rational = re.findall(r'[0-9]+\\.?[0-9]*', str_)\nprint(find_rational)  ＃ ['123', '456', '789', '3.14']\n{% endcodeblock %}\n\n## Code\n在Google首頁中尋找.jpg/.png，雖然只有一張圖片(笑)，另外，常用的Regex可以透過re.compile()轉換為Regex Object，以便於直接呼叫search()、match()、findall()，也可以在使用bs4模組解析網頁時使用:\n{% codeblock lang:py %}\n#!usr/bin/env python3\n# coding:utf-8\n\nimport re\nimport requests as rq\nfrom bs4 import BeautifulSoup as bs\n\npattern = re.compile(r'.+\\.jpg|.+\\.png')\nurl = 'https://www.google.com'\ntry:\n    res = rq.get(url)\n    res.raise_for_status()\nexcept rq.HTTPError:\n    print('HTTP Error!')\n\nsoup = bs(res.text, 'html.parser')\nimgs = soup.find_all(\"meta\", {\"content\":pattern})  # find all images in attr 'content' of tag 'meta'\nfor img in imgs:\n    print(img['content'])  # /images/branding/googleg/1x/googleg_standard_color_128dp.png\n{% endcodeblock %}","tags":["python","regex"],"categories":["Data Science"]},{"title":"以 Requests 取得 Google 搜尋結果","url":"/data-sci-google-search/","content":"## Web Analytics\n首先瞧瞧Google Search的網址，嘗試輸入任意關鍵字執行搜尋後可以發現，搜尋的網址是長這樣的：<!--more-->\n{% codeblock %}\nhttp://www.google.com.tw/search?q=\n{% endcodeblock %}\n\"=\"後面便是搜尋的關鍵字了，再觀察網頁原始碼，搜尋結果就在class=\"g\"的div區塊中。\n\n既然爬蟲能這樣到處玩耍，想必也會有不歡迎爬蟲的網站，畢竟要是放任大量爬蟲在自家網站撒野，可是會給伺服器帶來困擾的呢。所以Web Crawler也會有許多技巧來偽裝，讓自己在伺服器的認知裡看起來像是人為操作：例如，在request加上user agent偽裝成瀏覽器，或在多個request之間設置隨機延遲，除了模擬人為操作，亦避免造成他人伺服器的負擔...\n\n## Code\n{% codeblock lang:py %}\n#!/usr/bin/env python3\n# *** coding : utf-8 ***\n\nimport random\nimport requests as rq\nfrom bs4 import BeautifulSoup as bs\n\nuser_agent = [\"Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1\",\n            \"Mozilla/5.0 (Windows NT 10.0; WOW64; rv:38.0) Gecko/20100101 Firefox/38.0\",\n            \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0\",\n            \"Mozilla/5.0 (Macintosh; Intel Mac OS X x.y; rv:42.0) Gecko/20100101 Firefox/42.0\",\n            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:2.0.1) Gecko/20100101 Firefox/4.0.1\"]\n\ntarget = input('search:')\nurl = 'http://www.google.com.tw/search?q=' + target\ntry:\n    res = rq.get(url=url, headers={'User-Agent': random.choice(user_agent)})\n    res.raise_for_status()\nexcept rq.exceptions.HTTPError:\n    print('[HTTP_Error]')\n\nsoup = bs(res.text, 'html.parser')\nlink = soup.select('.g .r a')\n\nfor index in range(2):\n    print(link[index].string)   # title\n    print(link[index]['href'])  # link\n{% endcodeblock %}\n\n輸出結果：\n![](https://i.imgur.com/EcaezM5.png)","tags":["python","web crawler"],"categories":["Data Science"]},{"title":"以 BeautifulSoup 解析網頁內容","url":"/data-sci-bs4/","content":"發出請求取得網頁內容後，會得到密密麻麻的 HTML，此時便可以讓 BeautifulSoup 來協助解析網頁內容。\n<!--more-->\n## Install\n{% codeblock lang:shell %}\n$pip3 install bs4\n{% endcodeblock %}\n\n## Web Analytics\n寫個簡單的 Web Crawler 去 PTT 西斯版逛逛吧，但因為西斯版有年齡驗證，所以必須利用 Requests.Session()物件去做 post，按下大家在\b美好童年就已經按過的「我已滿18歲按鈕」，讓 Web Crawler 取得伺服器驗證後就可以在西斯版橫行無阻(嘿嘿)。\n\n從截圖可以看到，url 為 https://www.ptt.cc/ask/over18... 這就是取得驗證的網址，注意 url 後頭的 from=%2Fbbs%2Fsex...在 post 驗證的 payload 要寫入 from 這個 key，表示 post 來自西斯版。\n![](https://i.imgur.com/PAuJRHa.png)\n\n關於 BeautifulSoup 更多細節可參考[官方文件](https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.html)，這邊簡單說明，基本上就是把 request 取得的 html 丟給 Soup 去解析，接著可以使用 find(), find_all(), select()等方法來篩選尋找目標數據所在的區塊。\n\n舉例來說，若要讓 Web Crawler 去爬取西斯版的文章標題＆連結，觀察網頁原始碼後可以發現目標數據就在 class＝r-ent 的區塊裡面。\n![](https://i.imgur.com/56hpBfq.png)\n\n## Code\n{% codeblock lang:py %}\nimport requests as rq\nfrom bs4 import BeautifulSoup as bs\n\nurl = 'https://www.ptt.cc/bbs/sex/index.html'\npayload = {\n    'from':url,\n    'yes':'yes'\n}\n\nsession = rq.Session()\nsession.post('https://www.ptt.cc/ask/over18', data=payload)\nres = session.get(url)\n\nsoup = bs(res.text, 'html.parser')\nresult = soup.select('.r-ent .title a')\n\nfor title in result:\n    print(title.text, title['href'])\n{% endcodeblock %}\n\n輸出結果：\n![](https://i.imgur.com/NmCiRB0.png)","tags":["python","web crawler"],"categories":["Data Science"]},{"title":"Requests 模組測試","url":"/data-sci-requests/","content":"## Install\n{% codeblock lang:shell %}\n$pip3 install requests\n{% endcodeblock %}\n<!--more-->\n\n## Get\n範例程式為對網頁做基本請求＆接收回應，raise_for_status()為return檢查，若返回異常則拋出error\n{% codeblock lang:py %}\nimport requests as rq\n\nurl = 'http://www.google.com.tw/search?'  # target url\ntry:\n    res = rq.get(url)\n    res.raise_for_status()\nexcept rq.HTTPError:\n    print('HTTP Error!')\n\nprint(res.text)  # html\n{% endcodeblock %}\n\n## Payload\n必要時可以加上參數，例如Google Search:\n{% codeblock lang:py %}\npayload = {'q':'data science'}\nres = rq.get(url, params=payload)  # http://www.google.com.tw/search?q=data+science\n{% endcodeblock %}\n＊參數的部分為字典結構，key則視url結構而定\n\n## Post\n針對網頁中的表單，可以使用Post來傳送Payload\n{% codeblock lang:py %}\nres = rq.post(url, params=payload)\n{% endcodeblock %}\n\n但...對Google Search頁面做Post會得到這樣的回應：\n{% codeblock lang:html %}\n<a href=//www.google.com/><span id=logo aria-label=Google></span></a>\n<p><b>405.</b> <ins>That’s an error.</ins>\n<p>The request method <code>POST</code> is inappropriate for the URL <code>/search?q=data+science</code>.  \n<ins>That’s all we know.</ins>\n{% endcodeblock %}\n\nGoogle說這樣是不當的行為呢，我只是做個示範，好孩子不要學呀＾.<","tags":["python","web crawler"],"categories":["Data Science"]},{"title":"Hexo on GitHub Pages:從Win轉移到Mac","url":"/hexo-switching-from-win-to-mac/","content":"\n一直以來都有想換筆電的想法，但總是能撐則撐，畢竟會是不小的支出呢...不過前陣子需要帶著筆電趴趴造，而跟著我8年的老Win筆電過於笨重，這實在令人感到非常困擾，經考量後換了Mac Air，讓老Win正式退役。\n<!--more-->\n既然換了電腦換了系統，除了熟悉系統操作，再來就是開發環境的建置，趕緊先把Hexo環境先建置起來才能更新部落格。\n\n## Git\n<p>\n[官方載點](https://git-scm.com)，若是已安裝過自帶Git環境的XCode可以略過。\n\n## Node.js\n<p>\n[官方載點](https://nodejs.org/en/)\n\n## Hexo\n{% codeblock lang:shell %}\nsudo npm install -g hexo-cli\nsudo npm install hexo-deployer-git --save\ncd {blog_name}        # build folder of blog\nhexo init {blog_name}\nhexo\nnpm install\nhexo s --debug  # run local server(127.0.0.1:4000)\n{% endcodeblock %}\n![](https://i.imgur.com/iftnF8e.jpg)\n\n## Data\n<p>\n確定在本機可以正常運作後，接下來只要把根目錄下的_config.yml、scaffolds資料夾及source資料夾覆寫到Blog根目錄下就完成~\n\n## Note\n<p>\n1. 在發佈這篇文章後發現Blog分類及標籤頁面消失了...原來是我只把source底下的“_posts”複製到新的根目錄下，只要重新建立“categories”及\"tags\"兩個new page就行啦。\n2. 原本使用的NexT主題為舊版，這次乾脆就更新到v6.4.0啦，配置檔只有微幅的調整，需注意的是languages的部分，檔名中hyphen後的字改為大寫字母了，如果根目錄配置檔沒有修改，Blog預設語言就會因爲找不到對應檔案而變成英文。","tags":["hexo","github pages"],"categories":["Hexo"]},{"title":"Error:檔案無法載入，因為這個系統已停用指令碼執行","url":"/django-execution-of-scripts-is-disabled/","content":"問題來源 : 今日在Win10作業系統下建立Python virtual environment for Django，接著要用Scripts/activate指令啟動虛擬環境時，CLI顯示了這個令人錯愕的訊息:\n\n「檔案無法載入，因為這個系統已停用指令碼執行」\n\n<!--more-->\n代表目前作業系統的Execution Policy設定為Restricted\\(不允許執行\\)這是我在Win7作業系統下使用虛擬環境從沒遇過的狀況，而Google搜尋結果顯示有許多人在PowerShell執行Script遇到相同問題。\n\n## Solution\n以系統管理員權限執行PowerShell，執行以下指令:\n{% codeblock lang:shell %}\nSet-ExecutionPolicy RemoteSigned\n{% endcodeblock %}\n使作業系統接受所有自訂或信任來源的Script，如此問題便解決啦。","tags":["pyhton","django","error"],"categories":["Django"]},{"title":"VS Code快速建立Python開發環境","url":"/python-vscode-setup/","content":"個人從自學Python到現在，一直都是使用工具書所推薦的IDE:PyCharm，它確實是相當優秀的整合開發環境，但過胖這一點偶爾還是會令人感到困擾...每次打開程式就是要等它大爺暖身一下\\(白眼\\)。而開始學習在GitHub Pages寫Blog以來，我都是用VS Code發文，它的輕量化和豐富的擴充套件真是令人感到愉悅呢ヽ(●´∀`●)ﾉ 所以說，乾脆就在VS Code寫Python就好啦。\n<!--more-->\n## Download VS Code\n<p>\n[官方載點](https://code.visualstudio.com/download)\n\n## Install Python Extension for VS Code\n<p>\n↓點側邊工具列的'擴充功能'，然後搜尋'Python'，就會看到MS官方為Python開發的擴充套件，直接安裝即可。\n![](https://i.imgur.com/HD4254a.jpg)\n\n## Build Working Directory\n<p>\n建立一個工作目錄，理由後面會說明。\n\n## Run Python File\n<p>\n要在VS Code環境執行Python程式，可以直接右鍵-->在終端機\\(CLI\\)執行Python檔案，或者按下ctrl + `叫出CLI用'Python {file_path}'去執行也可以...但每次都這樣搞就太麻煩了，所以來建個任務組態檔吧。\n![](https://i.imgur.com/hT5hAXa.jpg)\n\n重點，首先點選上方工作列'檔案'-->'開啟資料夾'，選擇剛剛建立的工作目錄，若是沒有先選擇工作目錄，那麼接下來的步驟就會發生錯誤，VS Code會告訴你一句莫名其妙的話 :'這些工作只會出現在工作區資料夾中'。選擇好工作目錄後，按下ctrl + shift + P接著搜尋'task'，點選'工作:設定工作\\(Tasks:Configure Task\\)'，然後VS Code會在工作目錄下產生一個'tasks.json'，將下方內容直接覆蓋並存檔 :\n{% codeblock lang:json %}\n\"version\": \"2.0.0\",\n    \"tasks\": [\n            {\n                \"label\": \"Run Python Code\",\n                \"type\": \"shell\",\n                \"command\": \"python\",\n                \"args\": [\n                    \"${file}\"\n                ],\n                \"group\": {\n                    \"kind\": \"build\",\n                    \"isDefault\": true\n                },\n                \"presentation\": {\n                    \"echo\": true,\n                    \"reveal\": \"always\",\n                    \"focus\": true,\n                    \"panel\": \"shared\"\n                }\n            }\n        ]\n{% endcodeblock %}\n\n然後就可以透過快捷鍵'ctrl + shift + B'執行程式了，順帶一提，這是LineBot Web Crawler XD\n![](https://i.imgur.com/PZreIqo.jpg)","tags":["python","vs code"],"categories":["Python"]},{"title":"Hexo on GitHub Pages:發文","url":"/hexo-first-post/","content":"關於發文這件事，正所謂工欲善其事，必先利其器，就從選擇一個好用的文字編輯器或IDE開始，個人私心推薦VSCode。\n<!--more-->\n決定好工具後，首先看到blog根目錄底下有個叫'scaffolds'的資料夾，這裡面放的是Blog頁面模板。打開'post.md'會見到預先寫入的title、date等等，此為發文的模板，當然我們也可以編輯它。例如，模板預設是沒有寫入'categories'的，那我會把它加上去，就不必每次發文還得補上。\n![](https://i.imgur.com/TaK8Wzc.jpg)\n\n在Hexo框架下撰文是使用Markdown，不熟悉語法可以參考[官方文件](https://markdown.tw/)，很簡單的~ 接著就可以開始撰文了，相關指令如下:\n\n## Start New Post\n{% codeblock lang:shell %}\ncd blog\nhexo new post post-title  # 'post-title'請置換為自己的文章標題\n{% endcodeblock %}\n\n## Publish New Post\n{% codeblock lang:shell %}\nhexo d -g  # generate --> deploy\n{% endcodeblock %}\n\n## Note\n<p>\n1.categories是唯一、有序的，tags則沒有區分\\(關鍵字的概念\\)，意思是如果你的文章設定了A、B兩個類別，那麼這篇文章的分類就會變成'類別A底下的類別B'。\n2.在new post指令輸入文章標題時，因為標題也是.md的檔名，所以一開始我用underline做區隔(a_b_c)，但我發現Hexo會自動把underline轉成hyphen(a-b-c，順帶一提這條短線叫hyphen...dash是破折號呀)，所以就配合它啦，反正title可以建立文章後再修改為中文，檔名還是英文命名比較不會有什麼光怪陸離的事情發生(怕.jpg)","tags":["hexo","github pages"],"categories":["Hexo"]},{"title":"關於Python的變數範圍","url":"/python-scope-of-variables/","content":"在Python的世界裡，變數是不需要事先宣告就能直接賦値並使用的，而**變數的作用範圍會在賦値的時候建立**，除非你指定了global或nonlocal關鍵字。\n<!--more-->\n先看看[官方文件](https://docs.python.org/3/faq/programming.html#id9)怎麼說:\n{% blockquote %}\nIn Python, variables that are only referenced inside a function are implicitly global. If a variable is **assigned a value** anywhere within the function’s body, it’s assumed to be a local unless explicitly declared as global.\n\nThough a bit surprising at first, a moment’s consideration explains this. On one hand, requiring global for assigned variables provides a bar against unintended side-effects. On the other hand, if global was required for all global references, you’d be using global all the time. You’d have to declare as global every reference to a built-in function or to a component of an imported module. This clutter would defeat the usefulness of the global declaration for identifying side-effects.\n{% endblockquote %}\n\n簡而言之，在函式區塊內部賦値的變數即為區域變數\\(除非指定global或nonlocal\\)，於函式區塊之外賦値的便是全域變數。\n\n直接敲幾段code來看會更清楚 :\n\n{% codeblock lang:python %}\n#!/usr/bin/evn python3\n# *** coding : utf-8 ***\n\na, b = 1, 2  # Global Variable\n\n\ndef func_a():\n    global a  # Global Variable\n    print(a, \"# Global Variable a\")\n    a = 2\n\n\ndef func_b():\n    b = 3  # Local Variable in func_a()\n\n    def func_c():\n        nonlocal b  # Local Variable in func_a()\n        b = 4\n        print(b, \"# Local Variable b\")\n\n    print(b, \"# Local Variable b\")\n    func_c()\n\nfunc_a()\nfunc_b()\nprint(b, \"# Global Variable b\")\n{% endcodeblock %}\n\n**輸出結果:**\n{% codeblock lang:shell %}\n1 # Global Variable a\n3 # Local Variable b\n4 # Local Variable b\n2 # Global Variable b\n{% endcodeblock %}","tags":["python"],"categories":["Python"]},{"title":"在Heroku環境下使用自訂字型","url":"/line-use-custom-fonts-in-heroku-apps/","content":"事情是這樣子的，持續努力讓Bot能查教師課表的某一天，在經歷了數據蒐集、數據處理、介接imgur api...等等，終於讓Bot傳來了一張圖片啦~但仔細一看似乎不太對勁!\n<!--more-->\n## How to Use Custom Fonts in Heroku Apps?\n<p>\n我X，踩雷了，竟然出現中文亂碼的狀況，這課表鬼才看得懂\\(鬼:口口口口口這鬼也看不懂好嘛\\)於是又開始try&error loop...甚至讓Bot去下CLI指令刪除搬移檔案...繞了好一大圈，終於讓我找到答案了!!!令人難過的是，這方法非常簡單...雖然這是常有的事，可就是白耗了好多時間。但沒關係，讓碰見相同問題的人能快速找到解決方案，這就是學習筆記的意義所在。\n\n## Solution\n<p>\n1.準備好你要的字型，須<span style=\"color:red;\">特別注意</span>的是，該字型必須是<span style=\"color:red;\">Linux/Ubuntu</span>所支援的字型。\n2.在專案根目錄下新增一個名稱為「.fonts」的資料夾\\(tips:在命名時輸入.fonts.\\)\n3.把字型檔案\\(.ttf\\)放到上述資料夾中\n4.重新部署\n\n＊2021/02/21補充說明：因收到來信詢問相關問題，我使用的字體為SimHei。\n{% codeblock lang:py %}\nplt.rcParams['font.sans-serif'] = ['SimHei']\n{% endcodeblock %}\n\n![](https://i.imgur.com/uxdEvJZ.png)\n\n\n關於中文亂碼，似乎是matplotlib無法在Heroku環境下找到可套用的中文字型，但我在本機測試是沒問題的...所以要自己提供字型就是了，真是踩了個莫名其妙的雷，總之中文亂碼問題就這麼解決了。","tags":["python","heroku","matplotlib"],"categories":["LineBot"]},{"title":"翻缸Day21:藍綠藻來襲","url":"/restart-planted-tank-day21/","content":"開始新工作，下了班想發文卻提不起勁...呵。但還是利用假日來紀錄一下魚缸的近況吧。\n<!--more-->\n↓上週三出門辦事發現水族店在隔壁，就進去逛了\n![](https://i.imgur.com/8QSsMfb.jpg)\n↓於是加入新成員\n![](https://i.imgur.com/himpyCZ.jpg)\n↓綠宮廷轉水中葉，全數拔起整理再植草\n![](https://i.imgur.com/k5Jxf0j.jpg)\n↓角螺開心地啃藻...這缸子該刷了\n![](https://i.imgur.com/lSF2Z0A.jpg)\n↓僱來一批除藻小幫手\n![](https://i.imgur.com/pkNizEv.jpg)\n\n\n然後呢，最近幾天發現藍綠藻持續蔓延，底砂、牛毛氈甚至入水口生化棉也染上了噁心的藍綠色...即使拔起來用檸檬酸浸泡清洗試圖阻止，依然無效。經過爬文吸收資訊，也確定不會對魚蝦造成傷害，決定直接使用紅黴素來處理。雖然不會對魚蝦造成影響，但對於硝化菌們來說可就不妙了，所以投藥前必須將濾材另行安置才行。\n\n↓到處生長的藍綠藻\n![](https://i.imgur.com/cEm4u6i.jpg)\n↓移出圓桶中的濾材並加強打氣維持好氧的硝化菌\n![](https://i.imgur.com/umj5hh7.jpg)\n↓然後紅黴素便可以登場了!(決鬥吧藍綠藻!抽牌!)\n![](https://i.imgur.com/X3OmePn.jpg)\n\n## ※關於投藥劑量\n根據[P大](https://www.paludarium.net/aquarium/48)所說的2.5ppm來計算，我的魚缸水量約23L:23000000 * 0.00025% = 57.5(mg)，一顆紅黴素膠囊為250mg，所以我只需要1/5顆左右的劑量、持續投藥四日。\n\n\n## 2018/7/23 連續投藥Day3\n除了每日換水1/2，光源也調整為上午與傍晚開啟、不連續合計8小時(有一說如此中斷能干擾藻類生長)，目前觀察到藍綠藻已停止蔓延，清洗後的入水口綿也沒有藍綠藻生長。\n\n## 2018/7/25 連續投藥Day5\n↓藍綠藻明顯消失，但我決定今日不換水，讓藥物的效用多殘留一天，確保能控制住...別再來啦，真的是挺麻煩的。\n![](https://i.imgur.com/wtmQzkE.jpg)","tags":["aquarium","planted tank","cyanobacteria"],"categories":["Aquarium"]},{"title":"先別管Hexo如何發文了，你聽過NexT嗎?","url":"/hexo-config/","content":"2020/05/29更新。\n部署完部落格別急著發文，先來找個喜歡的佈景主題。\n<!--more-->\nHexo如此熱門的框架，有許多[第三方主題](https://hexo.io/themes/)能套用，或者想[打造一個自己的主題](https://hexo.io/zh-tw/docs/themes.html)也行，而我選擇的是最熱門的經典主題──NexT。\n\n## 安裝NexT主題\n{% codeblock lang:shell %}\ncd blog    # 移動至Blog根目錄下 \ngit clone https://github.com/theme-next/hexo-theme-next themes/next\n{% endcodeblock %}\n\n### 設定主題\n<p>\n打開Blog根目錄下的root配置檔\\(_config.yml\\)，找到\\#Extensions區塊，將theme屬性設置為next\n{% codeblock lang:yml %}\n# Extensions\n## Plugins: https://hexo.io/plugins/\n## Themes: https://hexo.io/themes/\ntheme: next\n{% endcodeblock %}\n\n### Local Host測試\n{% codeblock lang:shell %}\nhexo clean        # 清除hexo cache\nhexo s --debug    # 以debug模式啟動local host server\n{% endcodeblock %}\n如果CLI沒有輸出錯誤訊息，應該會見到這段文字:\n{% codeblock lang:shell %}\nINFO  Hexo is running at http://localhost:4000/. Press Ctrl+C to stop.\n{% endcodeblock %}\n接著打開瀏覽器輸入localhost:4000便能在本機查看、測試Blog囉。\n\n## 配置檔(_config.yml)\n**詳細Config設定請參考官方文件，僅紀錄個人設定部分**\n\n*官方文件:\n  1.[Hexo docs](https://hexo.io/zh-tw/docs/)\n  2.[NexT docs](https://theme-next.org/docs/)\n\n### Root Config\n<p>\n檔案位址:~/_config.yml\n{% codeblock lang:yml %}\n# Site\ntitle:              # 網站標題\nsubtitle:           # 網站副標題\ndescription:        # 網站描述\nkeywords:           # 網站關鍵字\nauthor:             # 作者名稱\nlanguage:           # 網站語言\ntimezone:           # 時區\n\n# URL\n## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'\nurl: https://username.github.io/  # 網站首頁網址\nroot: /\npermalink: :title/                # 文章永久連結，基於SEO考量不建議使用預設值(:year/:month/:day/:title/)\npermalink_defaults:\n\n# Writing\nnew_post_name: :title.md # File name of new posts\ndefault_layout: post\ntitlecase: false # Transform title into titlecase\nexternal_link: true # Open external links in new tab\nfilename_case: 0\nrender_drafts: false\npost_asset_folder: false\nrelative_link: false\nfuture: true\nhighlight:          # 代碼高亮\n  enable: true\n  line_number: true\n  auto_detect: true\n  tab_replace:\n\n# Home page setting\n# path: Root path for your blogs index page. (default = '')\n# per_page: Posts displayed per page. (0 = disable pagination)\n# order_by: Posts order. (Order by date descending by default)\nindex_generator:\npath: ''\nper_page: 5      # 每頁顯示文章數(預設值為10)\norder_by: -date  # 排序\n\n# Deployment\n## Docs: https://hexo.io/docs/deployment.html\ndeploy:\n  type: git\n  repository: https://{username}:{password}@github.com/{username}/{username}.github.io.git\n  branch: master\n{% endcodeblock %}\n\nRoot Config沒什麼複雜設定，不過在\\#site設定部分，我以為subtitle文字會顯示在author下方(紅框處)...結果顯示的文字是description，所以我說內個subtitle呢???\n![](https://i.imgur.com/3YLGWXs.jpg)\n\n### Theme Config\n<p>\n檔案位址:~/themes/next/_config.yml\n\n{% codeblock lang:yml %}\n# Allow to cache content generation. Introduced in NexT v6.0.0.\ncache:\n  enable: false    #啟用cache可改善網站載入速度\n{% endcodeblock %}\n\n#### favicon\n<p>\n尺寸調整好後，修改為同樣的檔名直接取代掉就行(懶)\n圖片位址:~/themes/next/source/images\n{% codeblock lang:yml %}\nfavicon:\nsmall: /images/favicon-16x16-next.png\nmedium: /images/favicon-32x32-next.png\napple_touch_icon: /images/apple-touch-icon-next.png\nsafari_pinned_tab: /images/logo.svg\n#android_manifest: /images/manifest.json\n#ms_browserconfig: /images/browserconfig.xml\n{% endcodeblock %}\n↓SVG Editor\n![](https://i.imgur.com/u9lSfGq.png)\n\n#### subtitle\nindex_with_subtitle改為true依然不見subtitle顯示於何處。\n{% codeblock lang:yml %}\n# If true, will add site-subtitle to index page, added in main hexo config.\n#subtitle: Subtitle\nindex_with_subtitle: false\n{% endcodeblock %}\n\n#### footer\n網站底部顯示起始年份、icon、版權宣告、框架＆主題版本等設定，Config註解相當詳細。\n##### 自定義footer文字\n{% codeblock lang:yml %}\n# Any custom text can be defined here.\n  custom_text: >\n    <span style=\"color:#3b5998;\"><i class=\"fa fa-hand-o-right fa-lg\"></i></span>&nbsp;All articles in this blog are \n    licensed under <a href=\"https://creativecommons.org/licenses/by/4.0/\">CC BY 4.0</a> \n    unless stating additionally.\n{% endcodeblock %}\n#### creative commons\n覺得有點礙眼所以將side bar跟文末的版權宣告拿掉，直接寫在footer。\n{% codeblock lang:yml %}\n# Creative Commons 4.0 International License.\n# See: https://creativecommons.org/share-your-work/licensing-types-examples\n# Available values of license: by | by-nc | by-nc-nd | by-nc-sa | by-nd | by-sa | zero\n# You can set a language value if you prefer a translated version of CC license.\n# CC licenses are available in 39 languages, where you can find the specific and correct abbreviation you need.\n# Valid values of language: deed.zh, deed.fr, deed.de, etc.\ncreative_commons:\n  license: by\n  sidebar: false\n  post: false\n  language:\n{% endcodeblock %}\n\n#### scheme settings\nNexT主題目前有四種[外觀模式](https://github.com/theme-next/hexo-theme-next)可選擇，將偏好的模式取消註解即可。\n{% codeblock lang:yml %}\n# ---------------------------------------------------------------\n# Scheme Settings\n# ---------------------------------------------------------------\n\n# Schemes\n#scheme: Muse\n#scheme: Mist\n#scheme: Pisces\nscheme: Gemini\n{% endcodeblock %}\n\n#### sidebar settings\n側邊欄依設定的Scheme不同，細部設定會有些微差異。\n{% codeblock lang:yml %}\n# ---------------------------------------------------------------\n# Sidebar Settings\n# See: https://theme-next.org/docs/theme-settings/sidebar\n# ---------------------------------------------------------------\n\n# Posts / Categories / Tags in sidebar.  #sidebar顯示統計(文章/分類/標籤)\nsite_state: true\n\n# Social Links                           ＃社群連結設置\n# Usage: `Key: permalink || icon`\n# Key is the link label showing to end users.\n# Value before `||` delimeter is the target permalink.\n# Value after `||` delimeter is the name of FontAwesome icon. If icon (with or without delimeter) is not specified, globe icon will be loaded.\nsocial:\n  GitHub: https://github.com/{username} || github\n  Linkedin: https://www.linkedin.com/ || linkedin-square  #可自行增加項目\n  Twitter: https://twitter.com/ || twitter\n  E-Mail: mailto:{username}@gmail.com || envelope\n  #Weibo: https://weibo.com/yourname || weibo\n  #Google: https://plus.google.com/yourname || google\n  #Twitter: https://twitter.com/yourname || twitter\n  #FB Page: https://www.facebook.com/yourname || facebook\n  #VK Group: https://vk.com/yourname || vk\n  #StackOverflow: https://stackoverflow.com/yourname || stack-overflow\n  #YouTube: https://youtube.com/yourname || youtube\n  #Instagram: https://instagram.com/yourname || instagram\n  #Skype: skype:yourname?call|chat || skype\n\nsocial_icons:\n  enable: true\n  icons_only: true  #省略文字僅顯示社群icon\n  transition: false\n\n# Blog rolls        #友情連結設置\nlinks_icon: link\nlinks_title: Links\n#links_layout: block\nlinks_layout: inline\nlinks:\n  #Title1: http://example.com\n\n# Sidebar Avatar  #頭像設置(方框或圓框/放大倍率/滑鼠游標碰觸旋轉XD)\navatar:\n  # In theme directory (source/images): /images/avatar.gif\n  # In site directory (source/uploads): /uploads/avatar.gif\n  # You can also use other linking images.\n  url: /images/avatar.png\n  # If true, the avatar would be dispalyed in circle.\n  rounded: true\n  # The value of opacity should be choose from 0 to 1 to set the opacity of the avatar.\n  opacity: 1\n  # If true, the avatar would be rotated with the cursor.\n  rotated: true\n\n# Table Of Contents in the Sidebar  ＃文章目錄顯示設置\ntoc:\n  enable: true\n  # Automatically add list number to toc.\n  number: true\n  # If true, all words will placed on next lines if header width longer then sidebar width.\n  wrap: false    #false＝truncate\n  # If true, all level of TOC in a post will be displayed, rather than the activated part of it.\n  expand_all: false\n  # Maximum heading depth of generated toc. You can set it in one post through `toc_max_depth` in Front Matter.\n  max_depth: 6\n\nsidebar:\n  # Sidebar Position, available values: left | right (only for Pisces | Gemini).\n  position: left\n  #position: right\n\n  # Manual define the sidebar width. If commented, will be default for:\n  # Muse | Mist: 320\n  # Pisces | Gemini: 240\n  #width: 300\n\n  # Sidebar Display, available values (only for Muse | Mist):    #sidebar顯示時機設置\n  #  - post    expand on posts automatically. Default.\n  #  - always  expand for all pages automatically.\n  #  - hide    expand only when click on the sidebar toggle icon.\n  #  - remove  totally remove sidebar including sidebar toggle.\n  display: post\n\n  # Sidebar offset from top menubar in pixels (only for Pisces | Gemini).\n  offset: 12\n  # Enable sidebar on narrow view (only for Muse | Mist).\n  onmobile: true\n  # Click any blank part of the page to close sidebar (only for Muse | Mist).\n  dimmer: false\n\nback2top:    #返回頂部按鈕設置\n  enable: true\n  # Back to top in sidebar.\n  sidebar: false\n  # Scroll percent label in b2t button.\n  scrollpercent: true\n{% endcodeblock %}\n\n#### code highlight\n<span style=\"color:red;\">代碼高亮問題</span>讓我困擾了好一段時間，也就是部落格更改為ICARUS主題的時候(只設置了一週又換回NexT)，因此才開始追究代碼高亮無作用的原因。實測後我的結論是，在Hexo框架下使用內建的[Tag Plugins](https://hexo.io/zh-tw/docs/tag-plugins.html)來標記程式碼區塊，最能確保代碼高亮的顯示，縮進跟反引號(backtick)的用法都不是很可靠。另外，自動偵測語言也並非完全準確，建議程式區塊要註記[language](https://highlightjs.readthedocs.io/en/latest/css-classes-reference.html)。\n{% codeblock lang:yml%}\n# Tag Plugins - code block語法\n# {% codeblock [title] [lang:language] [url] [link text] %}\n# your code here\n# {% endcodeblock %}\n\n# Code Highlight theme  #代碼高亮主題設置\n# Available values: normal | night | night eighties | night blue | night bright\n# https://github.com/chriskempson/tomorrow-theme\nhighlight_theme: night eighties\n{% endcodeblock %}\n\n#### mathjax\n{% codeblock lang:yml %}\n# Math Equations Render Support\nmath:\n  enable: True\n\n  # Default (true) will load mathjax / katex script on demand.\n  # That is it only render those page which has `mathjax: true` in Front Matter.\n  # If you set it to false, it will load mathjax / katex srcipt EVERY PAGE.\n  per_page: true\n\n  engine: mathjax\n  #engine: katex\n{% endcodeblock %}\n\nper_page預設值為true，也就是針對個別頁面啟用，不需要對所有頁面進行Latex語法渲染，加速頁面載入。\n所以欲啟用Latex語法渲染的文章須在[Front-matter](https://hexo.io/zh-tw/docs/front-matter)加入：\n{% codeblock lang:md %}\nmathjax: true\n{% endcodeblock %}\n\n#### third party services\n關於NexT所支援之第三方服務可參考[官方文件說明](https://theme-next.org/docs/third-party-services/)\n\n#### note\nNexT config隨著版本演進，設定項目變得更多、更細，就不逐項列出了，只寫重點。","tags":["hexo","github pages"],"categories":["Hexo"]},{"title":"翻缸Day8:除藻生物","url":"/restart-planted-tank-day8/","content":"目前光照時間已拉長至8小時，光源為Johnlen LED 1.5呎19W水草自然混光燈、色溫4000k&7000k的燈珠各3顆，CO2則是24小時不間斷，唯夜間會降低出氣量。重新翻缸後，底床僅有舊矽砂無鋪設基肥，依植草位置適量埋入ISTA水草根肥，因此在每週換水1/2後會酌量添加TBS綠色&紅色水草液肥。雖然目前並無藻類大量滋生的跡象，但除藻生物可是水草缸不可或缺的小幫手呢。\n<!--more-->\n\n因為前景的牛毛氈仍是以相當緩慢的生長速度在蔓延中，大概還要兩三週我才敢放入黑殼蝦...以免維護中的草皮被連根拔起!而說到除藻生物，我偏好可愛的小精靈~但水族店老闆表示折損率太高沒有再引進T.T 看來小精靈真的不好飼養，個人經驗...撐不過半年就上天堂了，我也是搞不懂問題出在哪。唉，只好退而求其次以小猴飛狐代替，以及好飼養又很勤奮工作的角螺~\n\n\n↓換了新環境的小猴飛狐目前看來有點膽小\n![restart_day8_01](https://i.imgur.com/rmBmzwM.jpg)\n\n↓小而圓的綠宮廷水上葉逐漸轉化為細長的水中葉了\n![restart_day8_02](https://i.imgur.com/9C9KqUd.jpg)\n\n\n今早一看，小猴飛狐已經跟黑燈們開始混熟了...再觀察觀察吧，因為北辰大有提過[小猴飛狐的危險性](http://northernstar-aquarium.blogspot.com/2011/09/blog-post.html)，希望這傢伙安份點。","tags":["aquarium","planted tank","algae control"],"categories":["Aquarium"]},{"title":"只要6塊錢~第一次自拍證件照就上手","url":"/take-a-headshot-yourself/","content":"說到 **大頭照** 這個東西，其實使用到的機會不多，但要用的時候總是被要求繳交 **6個月內**的證件照...照相館動輒兩三百塊，拍出來的大頭照多麼不堪我就不說了，大家應該都很有經驗\\(菸\\)。雖說市面上已有證件快照的機器，但也不是說很普及，收費大約是$150，於是我想起有看過在家自拍大頭照的教學，就決定來試試了，也讓我的700D在平淡無奇的日常生活中能有登場的機會。\n<!--more-->\n\n首先呢，找面明亮、乾淨的牆當背景，然後想辦法架好相機，手邊有腳架的話當然是最方便啦...如果相機螢幕能翻轉那就更好囉 : )\n![](https://i.imgur.com/IYuC7Q9.jpg)\n\n接下來就是設定倒數連拍，我覺得10秒比較夠用XD 證件照的規定可以參考[外交部領事局](https://www.boca.gov.tw/cp-16-4123-c2932-1.html)的說明，我就不贅述，總之，拍出理想的照片後就是去背、裁剪。若是不會使用專業的修圖軟體，可以參考[這篇](http://gigikaren1104.pixnet.net/blog/post/383578103)用PPT處理大頭照的教學，還能調膚色呢XD\n\n說到裁剪照片呢，這個**2吋**到底是多大呢?拜了Google大神後得到很多答案...眾說紛紜!我個人認為看起來最順眼、最2吋的是像素寬高比為433x581 pixel、實際寬高比為3.5x5.08的大小，提供參考。\n\n裁剪完成後，在修圖軟體上開一張4x6的畫布...小畫家也是可以，那麼4x6是多大呢?\\(尺寸什麼的好煩\\)像素寬高比為1795x1205 pixel，然後把大頭照貼滿整個畫布吧!\\(說貼滿其實也不過8張啦XD\\)\n![](https://i.imgur.com/7WE4wAb.jpg)\n\n上述準備就緒，[尋找](http://www.likoda.com.tw/info/store/)你附近的 **立可得** 吧~ 許多便利商店及大賣場都有設置喔，可以透過APP將照片傳輸至機器來列印照片，非常方便。\n![](https://i.imgur.com/3Dg9R1U.jpg)\n![](https://i.imgur.com/gZpfIw5.jpg)\n\n我是在便利商店的立可得列印的，傳輸照片、設定列印選項後，機器會列印繳費單，4x6一張6元，拿著它去櫃檯繳費後就可以回到機器前面取照片囉。\n![](https://i.imgur.com/a246LAA.jpg)\n![](https://i.imgur.com/kHUHVTO.jpg)\n\n\n第一次自拍證件照就上手，成功~","tags":["DIY","headshot"],"categories":["Daily"]},{"title":"部署失敗:Failed to Execute Prompt Script","url":"/hexo-failed-to-execute-prompt-script/","content":"在搭建好部落格、龜毛地設定了root配置檔，然後抱持著既期待又怕受傷害的心情，在CLI敲下部署指令後，得到了error: failed to execute prompt script (exit code 1)這這般無情的回應...嗯，部署失敗！ 我X，都還沒發文呢。\n<!--more-->\n\n## Solution\n<p>\n找到Blog根目錄下的root配置檔_config.yml，修正部署設定。\n\n原始設定:\n{% codeblock lang:yml %}\ndeploy:\n  type: git\n  repository: https://github.com/username/username.github.io.git\n  branch: master\n{% endcodeblock %}\n\n修改為:\n{% codeblock lang:yml %}\ndeploy:\n  type: git\n  repository: https://username:userpassword@github.com/username/username.github.io.git\n  branch: master\n{% endcodeblock %}\n\n部署成功 : )\n\n*[參考資料](https://www.zhihu.com/question/38219432)","tags":["error","hexo","github pages"],"categories":["Hexo"]},{"title":"Hexo on GitHub Pages:從零開始","url":"/hexo-on-github-pages/","content":"程式寫了幾年，遇到Bug總是靠著拜Google大神，就這麼一路走來，看過無數高手們手把手的教學文，心裡想著自己哪天也來寫寫學習筆記，紀錄學習歷程以及遇到的問題(以及至今仍在摸索中的水草缸...)，也許在某個夜深人靜的時刻，能幫助到和我一樣經常廢寢忘食、苦苦追尋解決方案的某個誰。於是部落格就這麼建起來了，學習筆記就從部落格的搭建過程開始紀錄吧。\n<!--more-->\n\n## 前置作業\n<br>\n### 安裝Node.js\n<p>\n[官網載點](https://nodejs.org/en/)\n\n接著執行作業系統CLI\\(command-line interface\\)輸入以下安裝指令\n\n### 安裝Hexo\n{% codeblock lang:shell %}\nnpm install hexo-cli -g\nhexo version            # 若安裝成功可查看Hexo版本\n{% endcodeblock %}\n\n### 安裝Hexo Git\n{% codeblock lang:shell %}\nnpm install hexo-deployer-git --save\n{% endcodeblock %}\n\n### 註冊GitHub帳號\n<p>\n[GitHub官網](https://github.com)\n<span style=\"color:red;\">特別注意 : </span>為避免某些文件配置錯誤的發生，使用者名稱(username)務必設定為小寫，使用者名稱也將成為部落格網址的主要部分\n\n### 新增GitHub專案\n* 按下New repository\n![](https://i.imgur.com/hoQ0WZP.jpg)\n* 輸入專案名稱username.github.io，username請填寫自己的使用者名稱，接著按下create repository，前置作業到此告一段落\n![](https://i.imgur.com/wHAh9q5.jpg)\n\n---\n### 開始建置\n<br>\n#### 初始化\n回到CLI輸入以下指令開始建立部落格\n\n{% codeblock lang:shell %}\nhexo init blog    # 初始化\ncd blog           # 移動至上一步所建立的blog資料夾\nnpm install       # 安裝blog相關套件\n{% endcodeblock %}\n\n#### 部署\n至blog資料夾底下找到Hexo root配置檔，文件名稱為_config.yml，打開文件找到部署設定區塊填入相關資訊\n<span style=\"color:red;\">特別注意 </span>: 每個項目的冒號後面一定要空格，username一樣改寫為自己的使用者名稱\n\n{% codeblock lang:yml %}\ndeploy:\n    type: git\n    repository: https://github.com/username/username.github.io.git\n    branch: master\n{% endcodeblock %}\n\n接著就可以部署到GitHub : )\n\n{% codeblock lang:shell %}\nhexo d -g    # generate --> deploy\n{% endcodeblock %}\n\n部署成功後在瀏覽器輸入網址 https://{username}.github.io/ 就可以看到自己的部落格囉~\n\n---\n### 更新版本\n{% codeblock lang:shell%}\ncd hexo root  # CLI移至hexo根目錄\nnpm outdated  # 檢查版本\n{% endcodeblock %}\n\n將package.json相關的package版本號修改為最新然後安裝即可\n{% codeblock lang:shell%}\nnpm install --save\n{% endcodeblock %}\n\n![](https://i.imgur.com/B6Z6Hee.png)\n\n＊CLI如有顯示類似的錯誤訊息\n{% codeblock lang:shell%}\nnpm WARN babel-eslint@10.0.1 requires a peer of eslint@>= 4.12.1 but none is installed. You must install peer dependencies yourself.\n{% endcodeblock %}\n\npeer dependencies是已發佈套件的相依關係，表示使用者需自行安裝額外的相依套件\n{% codeblock lang:shell%}\nnpm install eslint@4.12.1 --save-dev\n{% endcodeblock %}\n\n- [Hexo官網](https://hexo.io/zh-tw/)","tags":["hexo","github pages"],"categories":["Hexo"]},{"title":"1.5呎翻缸重整","url":"/restart-my-1.5ft-planted-tank/","content":"## 放置play很久很久的魚缸\n本來是想撤掉了，因為需要定期維護清洗設備...但又覺得可惜。<!--more-->後來又想改設置好整理的一呎缸，不過又考慮到水體小、水質相對難維持穩定的問題。經過一番掙扎，還是決定翻缸重新設景\\(天啊，水草缸都成了 **水藻缸**，這工程之浩大用想的就覺得累了...\\)。\n因為，我還是想要一個很療癒的水草缸啊。\n\n↓魚缸刷洗完成\n![刷洗後的魚缸](https://i.imgur.com/riEPpd9.jpg)\n↓重新設景、植草\n![植草設景完成](https://i.imgur.com/le3gi6j.jpg)\n\n\n## 設備更換\n  1.不鏽鋼出入水口\\(玻璃美觀但...易髒難洗\\)\n  2.外置CO2霧化器\\(放在缸內各種藻類實在困擾\\)\n  3.致冷晶片冷水機\\(嗯，為了讓水草度過夏天，但經費有限...\\)\n\n↓外置CO2霧化器\n![外置CO2霧化器](https://i.imgur.com/Dd3j2RI.jpg)\n↓本次升級的重磅武器(?)─致冷晶片冷水機\n![致冷晶片冷水機](https://i.imgur.com/F4EQYpT.jpg)\n\n\n↓重新設缸Day3，僅保留一株的溫蒂椒草已經開始冒出新葉了...生長速度如此之快，我用了個養樂多瓶底當草盆再植入底床，希望能限制它的植株大小，當個稱職的中景草。\n![溫蒂椒草](https://i.imgur.com/lmTVpf9.jpg)\n\n\n期盼能順利成景，尤其是前景的草皮。\n※GitHub Pages首PO!! \\(灑花\\)","tags":["aquarium","planted tank"],"categories":["Aquarium"]}]