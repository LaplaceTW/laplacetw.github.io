[{"title":"Python分割影片為指定長度","url":"/python-video-split/","content":"人們經常在通訊軟體分享各種多媒體訊息，而影片長度或檔案大小可能會有上傳限制，只好將其分割成多個片段上傳。<!--more-->就Line而言，我查到的資訊是限制影片長度5分鐘內、檔案大小300MB以下，就能順利傳送並於聊天室中播放。短片的話自己手動分割一下就行了，但你知道的(?)，有些人分享的片段完整加總起來都數十分鐘甚至一個多小時，仔細觀察那些片段的長度竟然都不一樣，而且還有上字(XXX分享之類的)，這...還真是吃力不討好啊，我只能說祝大大一生平安🙆‍♂️。\n\n---\n\b\b還是交給程式來處理吧，指定影片分割秒數，並自動在片頭上字持續3秒做為順序標記。此範例需用到[moviepy](https://pypi.org/project/moviepy/)套件，且需事先安裝[FFmpeg](https://ffmpeg.org/)和[ImageMagick](https://imagemagick.org/script/download.php)這兩個開源軟體。\n\n{% codeblock lang:py %}\n#!/usr/bin/env python3\nimport moviepy.editor as mp\n\n\n# e.g. video_split(\"./LaplaceTW.mp4\", 300)\ndef video_split(filepath, duration):\n    video = mp.VideoFileClip(filepath).resize(width=720)\n    video_length = int(video.duration) # seconds\n    parts = int(video_length / duration)\n    remaining = video_length - (duration * parts)\n    parts = (parts + 1) if remaining > 0 else parts\n    print(\"Video Length:\", video_length, \" | Split Parts:\", parts)\n\n    start, end = 0, duration\n    for part in range(1, parts + 1):\n        title = \"Part.\" + str(part)\n        text = (mp.TextClip(title, fontsize=50, color='yellow')\n            .set_pos((\"right\", \"top\"))\n            .set_duration(3))\n\n        clip = video.subclip(start, end)\n        clip = mp.CompositeVideoClip([clip, text])\n        clip.write_videofile(title + '.mp4')\n        \n        if part == parts - 1 and remaining > 0:\n            start += duration\n            end += remaining\n        else:\n            start += duration\n            end += duration\n{% endcodeblock %}\n\n分割長時間影片 ⬇︎\n![](https://i.imgur.com/IgC7WQW.png)\n\n處理結果 ⬇︎\n![](https://i.imgur.com/XqVlcYG.gif)\n\n---\n＊若沒有安裝ImageMagick則會發生執行錯誤：[Errno 2] No such file or directory: 'unset': 'unset'\n{% codeblock lang:sh %}\nOSError: MoviePy Error: creation of None failed because of the following error:\n\n[Errno 2] No such file or directory: 'unset': 'unset'.\n\n.This error can be due to the fact that ImageMagick is not installed on your computer, \nor (for Windows users) that you didn't specify the path to the ImageMagick binary in \nfile conf.py, or that the path you specified is incorrect\n{% endcodeblock %}\n\nRef. [TextClip Doesn't work at all #1003](https://github.com/Zulko/moviepy/issues/1003)","tags":["python","moviepy","mytoolbox"],"categories":["Python"]},{"title":"COSCUP 2020！","url":"/coscup-2020/","content":"決定得很臨時，但今年不用搶票，只要填寫健康聲明書就能參加了\b\b。<!--more-->雖說COSCUP是免費參加的，但小資如我還是有個人贊助點小錢，希望往後自己每年都能參加。剛好我的三倍券也還沒想到要用在哪，於是趕緊綁定信用卡、光速訂了高鐵票和商旅，週五晚間就飛奔到台北準備參加人生第一場COSCUP😎。\n\nCOSCUP 2020官網：[https://coscup.org/2020/zh-TW](https://coscup.org/2020/zh-TW)\n>開發者 (Coders)、使用者 (Users) 和推廣者 (Promoters) 是讓自由及開放原始碼軟體發光發熱的三大支柱，這個研討會就是專為這三種人舉辦的：你可以是 A 軟體的開發者、B 軟體的推廣者、C 軟體的使用者，不論你是已經踏入自由及開放原始碼軟體領域，還是一直站在門口不知如何入門，歡迎你來參加 COSCUP — Conference for Open Source Coders, Users and Promoters!\n\n這兩天的落腳處⬇︎\n![](https://i.imgur.com/eIUe5PV.jpg)\n\nCOSCUP今年依然在台科大舉辦，我照官網所說的搭捷運到公館站，從2號出口旁沿著舟山路行走至鹿鳴堂，再右轉欒樹道走到底，這才抵達台科大...步行約10分鐘，熱到爆炸。\n\nBadge⬇︎\n![](https://i.imgur.com/7Sy02Dw.jpg)\n\n主議程會場⬇︎\n![](https://i.imgur.com/b80Zd26.jpg)\n\n我在行前有根據議程表稍微規劃了想聽的議程，這次也和多年不見的友人約好在COSCUP碰面，時光飛逝相當有感...不過中午外出用餐回來沒趕上唐鳳政委主講的議題，畢竟現在疫情仍未趨緩，各個議程都是有人數管制的，只好在外頭透過直播觀看天才挨踢大臣的演講。\n\n第一天印象最深刻的就是交大陳志成教授所主講，關於他們的團隊所開發的[free5GC](https://github.com/free5gc/free5gc)，為世界第一套符合國際標準的開放原始碼5G核心網路。\n![](https://i.imgur.com/vxqXSla.jpg)\n![](https://i.imgur.com/RRdmuOt.jpg)\n\n第二天我只能參加上午的議題，然後就要趕搭高鐵回去了，但仍是參加了很棒的兩場議程，其一是Vue的作者、大神[Evan You](https://twitter.com/youyuxi)主講關於Vue第三版的開發過程所涉及的技術難點與設計取捨，雖然受疫情影響是採遠端連線會議，但這依然是令人興奮的議程！有趣的是，在議程最後的QA時間，有人問了Evan You這樣的一個問題：\n\n>請問Vue和React有什麼不同呢？\n\n眾人不禁哄堂大笑😂，Evan You也無奈地笑了笑，但他還是相當耐心地解釋、提出他的看法。\n\n議程結束後，我又立刻趕到另一個會場參加關於Pi Thermal Camera的議題，因為之前用Adafruit AMG8833 Module做過低解析度的熱成像儀，所以個人是相當期待這場議題的，我打算之後購買更高解析度的模組來進行進階實作。\n\n從Mozilla Taiwan Community的攤位獲得了帥氣的Firefox胸章！⬇︎\n![](https://i.imgur.com/3XN2maN.jpg)\n\n\b\b\b收集到了好多貼紙\b呀🙆‍♂️ ⬇︎\n![](https://i.imgur.com/7Jq8Gn9.jpg)\n\n完。","tags":["coscup"],"categories":["Workshop"]},{"title":"Arduino UNO：Coffin Dance","url":"/arduino-uno-r3-buzzer-astronomia/","content":"其實原曲名叫Astronomia啊，只是被幾位知名舞者(?)給抬出名了。<!--more-->看到Arduino範例程式的toneMelody發出了一段像是gameover的音效，我就想讓蜂鳴器播放這段相當知名的迷因歌曲🤣\n\n蜂鳴器分為有(震盪)源蜂鳴器，和無(震盪)源蜂鳴器，有源蜂鳴器就是高電位逼逼叫，低電位不叫，就這樣。而無源的蜂鳴器就好玩了，可以控制其聲音頻率而產生音調高低。\n\n### Music Scales\n參考範例程式中所引入的pitches.h檔案內容：\n{% codeblock lang:c %}\n#define NOTE_B0  31\n#define NOTE_C1  33\n#define NOTE_CS1 35\n.\n.\n.\n#define NOTE_C4  262\n#define NOTE_CS4 277\n#define NOTE_D4  294\n.\n.\n.\n{% endcodeblock %}\n這個.h檔即是定義[唱名](https://zh.wikipedia.org/wiki/%E5%94%B1%E5%90%8D)所對應的聲音頻率(Hz)，其中C4就是鋼琴琴鍵的中央C，亦即C大調的低音Do。如此一來只要有簡譜，像我這樣對樂理沒輒的人也能教Arduino怎麼演奏音樂了呢。\n\n### LCD Screen\n然後我想用個LCD在旁邊顯示播放的曲名，參考[GTW的教學](https://blog.gtwang.org/iot/ywrobot-arduino-lcm-1602-iic-v1-lcd-display)解決了我在編譯時發生的找不到函式庫的問題。要使用HD44780U 1602 LCD須安裝[LiquidCrystal library](https://bitbucket.org/fmalpartida/new-liquidcrystal/downloads/)，下載後解壓縮到Arduino的libraries資料夾底下即可。但這邊又有個小問題：\n{% codeblock lang:shell %}\nArduino:1.8.13 (Mac OS X), 開發板:\"Arduino Uno\"\n/Users/nick/Documents/Arduino/libraries/LiquidCrystal/I2CIO.cpp:35:10: fatal error: ../Wire/Wire.h: No such file or directory\n #include <../Wire/Wire.h>\n{% endcodeblock %}\n\n\b這就要找到剛剛解壓縮的資料夾中的I2CIO.cpp，將#include <../Wire/Wire.h>改為#include <Wire.h>。\n\n*1602 LCD的pin腳說明與像素點控制等教學：[Interfacing 16×2 Character LCD Module with Arduino](https://lastminuteengineers.com/arduino-1602-character-lcd-tutorial/)\n\n### Play Music!\n經過強迫症似的反覆聆聽和調整節拍，我覺得很接近原曲了😆\n{% codeblock lang:c %}\n#include <LiquidCrystal_I2C.h>\n#include \"pitches.h\"\n\n#define PIN_BUZ 8\n\n// Ref. https://youtu.be/miwoTFkiIfQ\nint melody[] = {\n    NOTE_AS4, NOTE_AS4, NOTE_AS4, NOTE_AS4,\n    NOTE_D5, NOTE_D5, NOTE_D5, NOTE_D5,\n    NOTE_C5, NOTE_C5, NOTE_C5, NOTE_C5,\n    NOTE_F5, NOTE_F5, NOTE_F5, NOTE_F5,\n    NOTE_G5, NOTE_G5, NOTE_G5, NOTE_G5, NOTE_G5, NOTE_G5,\n    NOTE_G5, NOTE_G5, NOTE_G5, NOTE_G5, NOTE_G5, NOTE_G5,\n    NOTE_C5, NOTE_AS4, NOTE_A4, NOTE_G4,\n    NOTE_G4, 0, NOTE_G4, NOTE_D5, NOTE_C5, NOTE_AS4, NOTE_A4, NOTE_A4, NOTE_A4,\n    NOTE_C5, NOTE_AS4, NOTE_A4, NOTE_G4, NOTE_G4, NOTE_G4,\n    NOTE_AS5, NOTE_A5, NOTE_AS5, NOTE_A5, NOTE_AS5, NOTE_G4,\n    NOTE_AS5, NOTE_A5, NOTE_AS5, NOTE_A5, NOTE_AS5, NOTE_G4\n};\n\n// note durations: 4 = quarter note, 8 = eighth note, etc.:\nbyte noteDurations[] = {\n    5, 5, 5, 5,\n    5, 5, 5, 5,\n    5, 5, 5, 5,\n    5, 5, 5, 5,\n    5, 5, 5, 5, 5, 5,\n    5, 5, 5, 5, 5, 5,\n    5, 5, 5, 5,\n    5, 5, 5, 5, 3, 3, 3, 5, 5,\n    3, 5, 5, 5, 5, 5,\n    5, 5, 5, 5, 5, 3,\n    5, 5, 5, 5, 5, 3\n};\n\n// Set the pins on the I2C chip used for LCD connections:\n//                    addr, en,rw,rs,d4,d5,d6,d7,bl,blpol\nLiquidCrystal_I2C lcd(0x27, 2, 1, 0, 4, 5, 6, 7, 3, POSITIVE);\n\nvoid setup() {\n    lcd.begin(16, 2); // lcd initial\n    lcd.backlight(); // turn on the backlight\n    lcd.setCursor(0, 0);\n    lcd.print(\"Play:Astronomia\");\n    lcd.setCursor(0, 1);\n    lcd.print(\"(Coffin Dance)\");\n}\n\nvoid loop() {\n    // iterate over the notes of the melody:\n    for (int thisNote = 0; thisNote < 59; thisNote++) {\n\n        // to calculate the note duration, take one second divided by the note type.\n        //e.g. quarter note = 1000 / 4, eighth note = 1000/8, etc.\n        int noteDuration = 1000 / noteDurations[thisNote];\n        tone(PIN_BUZ, melody[thisNote], noteDuration);\n\n        // to distinguish the notes, set a minimum time between them.\n        // the note's duration + 30% seems to work well:\n        int pauseBetweenNotes = noteDuration * 1.30;\n        delay(pauseBetweenNotes);\n        // stop the tone playing:\n        noTone(PIN_BUZ);\n    }\n    delay(3000);\n}\n{% endcodeblock %}\n\n\b\b感謝[這位大叔的彈奏教學](https://youtu.be/miwoTFkiIfQ)。\n{% youtube wqYNDwmzXDE%}","tags":["IoT","arduino"],"categories":["Arduino"]},{"title":"Arduino UNO：RGB模組、PWM、負數","url":"/arduino-uno-r3-rgb-module/","content":"What happens if we give a negative value to analogWrite() ?<!--more-->\b當我看了learning kit提供的、關於RGB模組的範例，在輸出給RGB的數值變化過程中是有出現負值的，於是我困惑了很久，想弄明白analogWrite()如何處理負數。\n\n### PWM\nPWM = Pulse Width Modulation，脈衝寬度調變，是一種利用數位脈衝訊號模擬類比訊號的技術，如何模擬呢？我們知道數位訊號只有0與1兩種狀態，也就是低電位與高電位，\b\b而在頻率不變的狀態下，改變工作週期大小，使整體平均電壓值上升或下降來做到控制或節能的行為，這就是PWM。\b白話點說呢，就是快速的開、關、開、關、開、關...以LED燈來說，就是快到肉眼無法察覺的程度，當我們調整工作週期中\b開和關的持續時間比例，若開的時間較長，那麼LED燈看起來就比較亮，反之則較暗。\n\n在Arduino中可用PWM模擬0~5v之間的電壓。圖片連結自[arduino.cc](https://www.arduino.cc/en/tutorial/PWM)⬇︎\n![](https://www.arduino.cc/en/uploads/Tutorial/pwm.gif)\n\n### RGB Module\n我手邊的是共陽極RGB模組，也就是其4根接腳為VCC、R、G、B。\n![](https://i.imgur.com/R6BxKqA.jpg)\n\nRGB模組範例程式：\n此範例使用有PWM功能的digital I/O pin 9 ~ 11，原始範例是有對這3個腳位設定pin mode，但[Arduino官方說analogWrite()不需要設定pin mode喔](https://www.arduino.cc/reference/en/language/functions/analog-io/analogwrite/)：\n>You do not need to call pinMode() to set the pin as an output before calling analogWrite().\nThe analogWrite function has nothing to do with the analog pins or the analogRead function.\n\n\b\b\b{% codeblock lang:c %}\n#define PIN_G 9\n#define PIN_B 10\n#define PIN_R 11\n\nvoid setup() {\n    Serial.begin(9600);\n}\n\nvoid loop() {\n    for (int i = 255; i > 0; i--) {\n        int blue = 128 -i;\n        //twos_complement(blue);\n\n        analogWrite(PIN_R, i);\n        analogWrite(PIN_B, blue); // 127 -> 0 -> 127 \n        analogWrite(PIN_G, 255 - i);\n\n        delay(50);\n    }\n\n    for (int i = 0; i < 255; i++) {\n        int blue = 128 -i;\n        //twos_complement(blue);\n\n        analogWrite(PIN_R, i); \n        analogWrite(PIN_B, blue); // 128 -> 0 -> 126 \n        analogWrite(PIN_G, 255 - i);\n\n        delay(50);\n    }\n}\n\nvoid twos_complement(int binary) {\n    if (binary < 0) Serial.println((~binary) + 1);\n    else Serial.println(binary);\n}\n{% endcodeblock %}\n![](https://i.imgur.com/WQXvn2G.gif)\n\n### analogWrite()\n從上面的範例程式可以看到，analogWrite()寫入RGB module的B pin值，也就是for loop中的變數blue，它是會出現負值的。但analogWrite()只接受0 ~ 255之間的值呢？？？後來我找到[一篇文章](https://techexplorations.com/blog/arduino/blog-what-happens-if-you-give-a-negative-pwm-value-to-analogwrite/)說Arduino使用二補數來處理負數，於是我寫了twos_complement()來計算二補數\b並print出實際上寫入B pin的值。\n\n### Ref.\n[https://www.arduino.cc/en/tutorial/PWM](https://www.arduino.cc/en/tutorial/PWM)\n[http://wiki.csie.ncku.edu.tw/embedded/PWM](http://wiki.csie.ncku.edu.tw/embedded/PWM)\n[https://www.arduino.cc/reference/en/language/functions/analog-io/analogwrite/](https://www.arduino.cc/reference/en/language/functions/analog-io/analogwrite/)\n[https://techexplorations.com/blog/arduino/blog-what-happens-if-you-give-a-negative-pwm-value-to-analogwrite/](https://techexplorations.com/blog/arduino/blog-what-happens-if-you-give-a-negative-pwm-value-to-analogwrite/)","tags":["IoT","arduino"],"categories":["Arduino"]},{"title":"正確理解YOLO的辨識準確率","url":"/data-sci-yolo-accuracy/","content":"這幾天媒體報導了[YOLOv4](https://arxiv.org/abs/2004.10934)的相關新聞，提到其為中研院研究團隊與俄羅斯開發者所共同研發，而這全世界最快最準的物體偵測演算法，其平均準確率為43.5%，於是這43.5%的準確率迅速引來許多不明就裡的人留言批評。<!--more-->不懂沒有關係，我們可以先查證，再提出質疑，而非只是「我覺得這準確率有夠低」就輕率地批評指責(中研院難道是能隨便誇大其詞的研究機構嗎？)，但你可能連state-of-the-art意味什麼都不明白。這對無私貢獻的[Open Source](https://zh.wikipedia.org/wiki/%E9%96%8B%E6%BA%90%E8%BB%9F%E9%AB%94)開發者一點都不公平，真是站著說話不腰疼、躺著留言不費勁。\n\n## 什麼是YOLO?\n<p>[YOLO官網](https://pjreddie.com/darknet/yolo/)是這麼介紹它自己的：\n>You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Pascal Titan X it processes images at 30 FPS and has a mAP of 57.9% on COCO test-dev. (YOLO是最先進的即時物體偵測系統，在Pascal Titan X GPU上以30 FPS的速度處理影像，於COCO測試開發資料集中的mAP為57.9%)\n\n然後我們可能又會疑惑：FPS? COCO? mAP? 別著急，多理解一下物體偵測。\n\n電腦是如何進行物體偵測？一般做法是透過各種選擇性搜索演算法(selective search)，偵測、分割出影像中可能有物體存在的區域(region proposal)，那麼沒有物體存在的區域就不需要進行無效的運算，也能加快處理速度，接著再對這些可能有物體存在的區域進行辨識分類。如此先搜索region proposal再進行辨識的處理方式稱為Two Stage(e.g. R-CNN)。\n![](https://i.imgur.com/O62Ncev.png)\n\n但這有個潛在問題，假設系統偵測出影像中有數百個甚至上千個region proposal，那麼就得進行上千次的辨識運算...個人電腦即便有高階GPU亦可能做不到即時運算，更遑論行動裝置。\n<p>圖片連結自[https://github.com/ouyanghuiyu/darknet_face_with_landmark](https://github.com/ouyanghuiyu/darknet_face_with_landmark)⬇︎\n![](https://raw.githubusercontent.com/ouyanghuiyu/darknet_face_with_landmark/master/test_imgs/selfie.jpg)\n\n於是我們有了One Stage(e.g. YOLO)，物體偵測和辨識一氣呵成，這樣的做法能大幅提升處理速度。不過有一好沒兩好，要速度快你就得在準確率做點取捨，因此整體辨識準確率相較Two Stage來得差一些，但One Stage在許多應用上仍是可接受範圍內，兩種作法各有其優勢，端看需求。\n![](https://i.imgur.com/OdWNkUk.png)\n\n回到YOLO，自從2015年發佈v1發展至今，最新版本為今年4月底所發佈的v4，處理速度簡直快到沒朋友，但YOLO的創造者[Joseph Redmon](https://pjreddie.com/)今年二月[於推特宣佈退出電腦視覺研究領域](https://twitter.com/pjreddie/status/1230524770350817280)，當時引起相當大的討論，多少人引頸期盼YOLO的下個版本，Joseph Redmon表示自己的工作對人類社會的衝擊性實在太大了，即使熱愛電腦視覺的研究工作，但其終究無法忽視自己的研究成果在軍事科技應用以及個人隱私方面可能導致的問題。因此YOLOv4為俄羅斯開發者、YOLOv3的實現 — Darknet作者[Alexey Bochkovskiy](https://twitter.com/alexeyab84)與中研院資科所所長Hong-Yuan Liao及博士後研究員Chien-Yao Wang等三人基於後兩位研發的CSPNet，對YOLO的最新研究成果。而Joseph Redmon也[更新](https://github.com/pjreddie/darknet#darknet)了YOLOv4的論文與原始碼連結，顯示YOLOv4為官方所認可的後繼版本。\n\n## 什麼是FPS?\n<p>FPS就是影格率或是經常聽到的幀數，[維基百科](https://zh.wikipedia.org/wiki/%E5%BD%B1%E6%A0%BC%E7%8E%87)就有寫了沒啥好說：\n>影格率是用於測量顯示影格數的量度。測量單位為「每秒顯示影格數」(Frame per Second，FPS)或「赫茲」，一般來說FPS用於描述影片、電子繪圖或遊戲每秒播放多少影格。\n\n## 什麼是COCO資料集？\n<p>[COCO資料集(Common Objects in Context)](https://cocodataset.org/)是微軟所發佈、擁有33萬張影像的大型開源資料集：\n>COCO is a large-scale object detection, segmentation, and captioning dataset. COCO has several features:\n- Object segmentation\n- Recognition in context\n- Superpixel stuff segmentation\n- 330K images (>200K labeled)\n- 1.5 million object instances\n- 80 object categories\n- 91 stuff categories\n- 5 captions per image\n- 250,000 people with keypoints\n\n## 什麼是mAP？\n<p>mAP的\"m\"代表\"mean\"，簡而言之，AP(average precision)是用來評估物體識別模型效能表現的指標之一。我參考維基百科[Precison and Recall](https://en.wikipedia.org/wiki/Precision_and_recall)頁面的說明圖片，重新繪製了下方這張圖(原圖為直向)來說明。\n*關於Precision and Recall可參考：[心理學和機器學習中的 Accuracy、Precision、Recall Rate 和 Confusion Matrix](https://medium.com/@ChingTien/529d18abc3a)\n![](https://i.imgur.com/KgFbe8Y.png)\n\n假設我現在要從一些含有各種物體的影像中找出狗的圖片，那麼上圖左側深灰色矩形代表狗的圖片集合，右側淺灰色影像代表其他物體的圖片集合，中間的大圓圈則是被判定為狗的圖片的集合，其中包含真的為狗的圖片(分類正確)以及不是狗的圖片(分類錯誤)。所以precision就代表在「所有被判定為狗的圖片」之中有多少**比例**是「狗的圖片」。\n\n至於average precision的計算則是將precision加總後取平均值：\n\n|判定為狗且真的為狗的圖片數 |  判定為狗的圖片數 |Precision|\n|:---------------------:|:--------------:|:-------:|\n|1                     |1                |1        | \n|1                     |2                |1/2      |\n|1                     |3                |1/3      |\n|2                     |4                |2/4      |\n|2                     |5                |2/5      |\n|...                   |...              |...      |\n\n又物體識別會有許多類別，以COCO資料集而言就有80種object categories，mean average precision便是所有類別AP加總的平均值。\n\n＊COCO資料集究竟有多少個類別？網路上有人說80種，也有人說91種，合理推測是將object categories跟stuff categories搞混了，這兩種分類的差異我也是看了某篇論文的摘要才明白，根據[COCO-Stuff: Thing and Stuff Classes in Context](https://arxiv.org/abs/1612.03716)所述：\n>Semantic classes can be either things (objects with a well-defined shape, e.g. car, person) or stuff (amorphous background regions, e.g. grass, sky).\n\nobject類就是能明確界定形狀的**物體**，例如汽車、人。stuff類則是沒有特定形狀或邊界的**背景區域**，例如草地、天空。懂！\n\n## 效能評估指標\n<p>根據COCO資料集的效能評估頁面所述：\n>Average Precision (AP):\n- AP：AP at IoU=.50:.05:.95 (primary challenge metric)\n- AP IoU=.50：AP at IoU=.50 (PASCAL VOC metric)\n- AP IoU=.75：AP at IoU=.75 (strict metric)\n\b\n\n從這段敘述可以確定COCO資料集效能評估指標的AP指的就是mAP：\n>AP is averaged over all categories. Traditionally, this is called \"mean average precision\" (mAP). We make no distinction between AP and mAP (and likewise AR and mAR) and assume the difference is clear from context.\n\n說到這兒又得理解一個跟AP有關係的詞：IoU(Intersection over Union，並交比)，簡而言之，物體識別的IoU為物體標記範圍與系統偵測範圍這兩個集合的交集和並集之間的比例，有請台北市立動物園的水豚君幫忙示範一下：\n![](https://i.imgur.com/w7sc0Vc.jpg)\n假設紅框為影像的原始標記邊界範圍\b\ba1，黃框為YOLO所偵測的物體邊界範圍a2，那麼IoU則為a1與a2的**交集**除以a1與a2的**聯集**。\n\n因此以COCO資料集的AP指標而言，可以看到其IoU並非一個固定值，而是「.50:.05:.95」，意思是IoU共有{0.5, 0.55,...0.95}10個閾值，以這10個標準做判定、計算AP再取平均，而AP50\b(IoU=.50)或AP75(IoU=.75)則是傳統的評估方式。\n\n## 平均準確率\n<p>說了一堆，可以來看底下這張效能表現比較圖了。\n\n我直接連結[Darknet](https://github.com/AlexeyAB/darknet)其GitHub頁面的圖片⬇︎\n![](https://user-images.githubusercontent.com/4096485/82835867-f1c62380-9ecd-11ea-9134-1598ed2abc4b.png)\n\nYOLOv4的效能表現是相當突出的，在FPS為90的時候，v4的AP比v3多了10%，要不光看它和YOLOv3那條線之間有好大一段垂直距離也不難理解。對於一件事情的難易度若是沒有概念，只看43.5%這個數字能看出什麼呢？\n\nYOLOv4論文摘要：\n>We use new features: WRC, CSP, CmBN, SAT, Mish activation, Mosaic data augmentation, CmBN, DropBlock regularization, and CIoU loss, and combine some of them to achieve state-of-the-art results: 43.5% AP (65.7% AP50) for the MS COCO dataset at a realtime speed of ~65 FPS on Tesla V100.\n\n辨識無數的物體要**即時**又要**快狠準**你說容易嗎？\n![](https://i.imgur.com/NG4nEoT.png)\n{% youtube 1_SiUOYUoOI %}\n\n## Research Papers of YOLO\n<p>\n- [You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640)\n- [YOLO9000: Better, Faster, Stronger](https://arxiv.org/abs/1612.08242)\n- [YOLOv3: An Incremental Improvement](https://arxiv.org/abs/1804.02767)\n- [YOLOv4: Optimal Speed and Accuracy of Object Detection](https://arxiv.org/abs/2004.10934)","tags":["deep learning","computer vision","yolo","darknet"],"categories":["Data Science"]},{"title":"Arduino UNO R3","url":"/arduino-uno-r3-learning-kit/","content":"\b\b終於有時間玩玩買來很久的learning kit。開發版種類繁多，但除了修課玩過Ti OMAP系列的PandaBoard、Devkit8000，也就自己買的樹莓派3B+了，<!--more-->\b\b『這都2020了還沒玩過Arduino，豈不是要給人看笑話了😝』就這麼想著的某天便光速下單買來了套件組合準備試玩。\n\n![](https://i.imgur.com/jWi2s0M.jpg)\n\n先下載[Arduino IDE](https://www.arduino.cc/en/Main/Software)，將Arduino透過USB接上PC，設置好USB連接埠就可以開始玩了，寫段程式碼來測試看看。<br>\n序列埠輸出要先用[Serial.begin()](https://www.arduino.cc/reference/en/language/functions/communication/serial/begin/)方法初始化、設定baud rate⬇︎\n![](https://i.imgur.com/PPlSksQ.png)\n![](https://i.imgur.com/OEk9ppo.png)\n\nArduino的程式架構基本上就是setup()跟loop()兩個函式，用來執行初始化和持續執行的動作，經過編譯後會整合為main()函式。[Arduino維基頁面](https://zh.wikipedia.org/wiki/Arduino)寫著其IDE是源自Processing程式語言，哈！想起大三時曾經修過清大MOOCs\b的玩電玩學程式課程，當時就是使用這有趣的語言，難怪有種熟悉感🤣\n\n環境設置完成，使用幾個LED來測試、學習Arduino程式編寫：\n\n### LED Control\n<br>\n![](https://i.imgur.com/iKiu4BM.png)\n我將PIN 13設為輸出，因此板子上的LED也會跟著閃爍。\n![](https://i.imgur.com/AB5h1WK.gif)\n\n### Traffic Light\n使用黃綠紅3顆LED模擬紅綠燈。\n{% codeblock lang:c %}\n#define PIN_LED_G 2\n#define PIN_LED_Y 3\n#define PIN_LED_R 4\n\nvoid setup() {\n  pinMode(PIN_LED_R, OUTPUT);\n  pinMode(PIN_LED_G, OUTPUT);\n  pinMode(PIN_LED_Y, OUTPUT);\n}\n\nvoid loop() {\n  digitalWrite(PIN_LED_G, HIGH);\n  delay(3000);\n  digitalWrite(PIN_LED_G, LOW);\n\n  digitalWrite(PIN_LED_Y, HIGH);\n  delay(1000);\n  digitalWrite(PIN_LED_Y, LOW);\n\n  digitalWrite(PIN_LED_R, HIGH);\n  delay(3000);\n  digitalWrite(PIN_LED_R, LOW);\n}\n{% endcodeblock %}\n\n![](https://i.imgur.com/rcmlVTs.gif)\n\n### Switch Control\n以按鍵開關控制LED：若偵測到按鍵開關的狀態為HIGH(按下)則使PIN_LED狀態亦為HIGH。\n{% codeblock lang:c %}\n#define PIN_LED 7\n#define PIN_SWITCH 8\n\nvoid setup() {\n  pinMode(PIN_SWITCH, INPUT);\n  pinMode(PIN_LED, OUTPUT);\n}\n\nvoid loop() {\n  int switch_status = digitalRead(PIN_SWITCH);\n  if(switch_status == HIGH){\n    digitalWrite(PIN_LED, HIGH);\n  }\n  else{\n    digitalWrite(PIN_LED, LOW);\n  }\n}\n{% endcodeblock %}\n\n![](https://i.imgur.com/iZzRafD.gif)\n\n### Light Ticker\nEmbedded System的資源都是有限的，UNO R3 Digital I/O僅有13個port，又RX/TX佔了0和1兩個port，所以實際上能用的也就11個port，彌足珍貴呀😌&nbsp;&nbsp;當遇到需要控制多個LED的情況，例如模擬跑馬燈，讓每顆LED都佔用一個port實在太浪費，而此時便是74HC595位移暫存器派上用場的時候，只要佔用Arduino 3個port就能控制74HC595的8個port，超棒der。\n![](https://i.imgur.com/hpNCaiM.jpg)\n關於74HC595詳細的說明與接線可參考[佑來了老師的教學影片](https://www.youtube.com/watch?v=KKdNk5lne50)，他的神解釋相當通俗易懂😆\n\n- 直白的寫法：\n雖然程式碼長了點，但我覺得這是容易理解其運作的寫法。\n{% codeblock lang:c %}\n#define PIN_DATA 2\n#define PIN_STORE 3\n#define PIN_SHIFT 4\n\nvoid setup() {\n  pinMode(PIN_DATA, OUTPUT);\n  pinMode(PIN_SHIFT, OUTPUT);\n  pinMode(PIN_STORE, OUTPUT);\n}\n\nvoid loop() {\n  // left --> right\n  for(int i=7; i>=0; i--){\n    digitalWrite(PIN_STORE, LOW);\n    for(int j=0; j<8; j++){\n      if(j == i){ light_up(); }\n      else{ light_down(); }\n    }\n    digitalWrite(PIN_STORE, HIGH);\n    delay(200);\n  }\n  // right --> left\n  for(int i=0; i<8; i++){\n    digitalWrite(PIN_STORE, LOW);\n    for(int j=0; j<8; j++){\n      if(j == i){ light_up(); }\n      else{ light_down(); }\n    }\n    digitalWrite(PIN_STORE, HIGH);\n    delay(200);\n  }\n}\n\nvoid light_up() {\n  digitalWrite(PIN_SHIFT, LOW);\n  digitalWrite(PIN_DATA, 1);\n  digitalWrite(PIN_SHIFT, HIGH);\n}\n\nvoid light_down() {\n  digitalWrite(PIN_SHIFT, LOW);\n  digitalWrite(PIN_DATA, 0);\n  digitalWrite(PIN_SHIFT, HIGH);\n}\n{% endcodeblock %}\n\n- 簡潔的寫法：\n使用[shiftOut()](https://www.arduino.cc/reference/en/language/functions/advanced-io/shiftout/)方法來推送8-bit的數據，由參數bit_order來控制讀取順序，MSBFIRST為由左至右，LSBFIRST則相反。我自定義了light_ticker()函式，接收bit_order參數來控制跑馬燈方向，所以loop()裡頭僅有兩行code。\n{% codeblock lang:c %}\n#define PIN_DATA 2\n#define PIN_STORE 3\n#define PIN_SHIFT 4\n\nvoid setup() {\n  pinMode(PIN_DATA, OUTPUT);\n  pinMode(PIN_SHIFT, OUTPUT);\n  pinMode(PIN_STORE, OUTPUT);\n}\n\nvoid loop() {\n  light_ticker(MSBFIRST);  // left  --> right\n  light_ticker(LSBFIRST);  // right --> left\n}\n\nvoid light_ticker(bool bit_order) {\n  byte num;\n  for(int i=0; i<8; i++){\n    num =0;\n    digitalWrite(PIN_STORE, LOW);\n    bitSet(num, i);\n    shiftOut(PIN_DATA, PIN_SHIFT, bit_order, num);\n    digitalWrite(PIN_STORE, HIGH);\n    delay(200);\n  }\n}\n{% endcodeblock %}\n\n![](https://i.imgur.com/dhVYF1i.gif)\n\n### Notes\n[Arduino - Data Types - int](https://www.arduino.cc/reference/en/language/variables/data-types/int/)\n[Arduino - Data Types - byte](https://www.arduino.cc/reference/en/language/variables/data-types/byte/)","tags":["IoT","arduino"],"categories":["Arduino"]},{"title":"CIFAR-10分類任務的辨識準確率","url":"/data-sci-vgg-cifar10/","content":"對DL初學者而言，最常用來測試的大概就是MNIST跟CIFAR-10\b這兩個數據集了。或許對大神們來說不過都是些玩具，但我認為CIFAR-10不只是個toy dataset，相較於MNIST那樣使用MLP就能輕易達到近乎99%辨識準確率的灰階影像，CIFAR-10不像\"Hello World!\"這麼容易吧？🤨<!--more-->\n\n關於[CIFAR-10數據集](https://www.cs.toronto.edu/~kriz/cifar.html)，像我這樣略懂略懂的人就不贅言了，網路上介紹CIFAR-10的文章很多。不過，當我爬了許多文章之後，大致上都是介紹數據集和使用簡單的CNN來測試而已(準確率約70%)，如何對現有模型結構優化並提升CIFAR-10準確率還是沒頭緒，雖然可以直接載入Keras內建的預訓練模型，例如VGG-16、ResNet-50，但我認為那樣做沒啥意思，根本上還是沒搞懂，也像是大砲打小鳥。\n\n## Keras Sample Code\n<p>\n看一下[Keras的範例程式](https://keras.io/examples/cifar10_cnn/)，根據頁面說明，該範例於訓練50 epochs後達到79%的驗證準確率。實際訓練了100 epochs也差不多。\n\n- Model Summary\n![](https://i.imgur.com/mgSpvB8.png)\n\n- Train History\n![](https://i.imgur.com/14YO3XH.png)\n\n## More Optimization\n就Keras範例來說，我嘗試以相同結構增加其網路深度，驗證準確率有得到些微提升(約82%)，但持續盲目地加深網路卻會造成反效果。後來我找到了[Jason Brownlee博士的教學](https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/)，那是一個很棒的tutorial，嘗試對模型結構進行優化後，訓練結果在測試數據集取得89%的準確率(Train / Valid : 94.60% / 89.35%)。\n\n- Model Summary\n![](https://i.imgur.com/VxnAUMG.png)\n\n- Train History\n![](https://i.imgur.com/WzberYE.png)\n\n## Fractional Max-Pooling\n\b\b在優化了模型結構後，測試準確率依然無法突破90%，因此我搜尋了state-of-the-art on CIFAR-10，看看大神們超脫凡俗的思路究竟是如何突破問題。於是我[仔細閱讀了Fractional Max-Pooling這篇論文](https://laplacetw.github.io/study-fractional-max-pooling)，並實際應用到我的模型訓練，儘管我沒有使用和原始論文實驗中同樣深的網路結構，依然在測試數據集的準確率達到了93%(Train / Valid : 97.94% / 93.55%)。順帶一提，該模型在我的GTX 1660 Super訓練600 epochs需耗費30個小時左右。\n\n關於Fractional Max-Pooling的實現，TensorFlow已有內建，而Keras可以利用Lambda來引入模型中使用：\n{% codeblock lang:py %}\ndef frac_max_pool(x):\n    return tf.nn.fractional_max_pool(x, [1.0, 1.41, 1.41, 1.0], pseudo_random=True, overlapping=True)[0]\n\nmodel.add(Lambda(frac_max_pool))\n{% endcodeblock %}\n\n- Model Summary\n![](https://i.imgur.com/IW0Z2VC.png)\n\n- Train History\n![](https://i.imgur.com/mLV3eVI.png)\n\n## Comparison\n對參數量和模型大小做個比較：\n\n|            | VGG-16/VGG-19 |VGG-like + FMP|\n|:----------:|:-------------:|:------------:|\n|total params|10M+           |1.5M          |\n| model size |200+ MB        |12.4 MB       |\n\n## Source Code\n<p>\n[https://github.com/laplacetw/vgg-like-cifar10](https://github.com/laplacetw/vgg-like-cifar10)","tags":["keras","deep learning","computer vision","cifar-10"],"categories":["Data Science"]},{"title":"翻譯：Fractional Max-Pooling","url":"/study-fractional-max-pooling/","content":"作者：Benjamin Graham\n原文：[https://arxiv.org/abs/1412.6071](https://arxiv.org/abs/1412.6071)\n<!--more-->\n### 摘要\n卷積網路幾乎總是包含若干特徵空間取樣(pooling)的形式，通常使用α x α max-pooling(α = 2)。最大取樣作用於卷積網路的隱藏層，以整數倍乘因子α來縮減隱藏層的大小。而當你拋棄了75%的數據所獲得的驚人副產物是—在網路中建立了一定程度對於平移與彈性形變的不變性。然而，如果你只是交替使用卷積層與最大取樣，則效能表現將會受限於特徵空間的快速縮減與取樣區域不相交的特性。因此，我們制訂了分數形式的最大取樣，允許α採用非整數值。分數階最大取樣是隨機的，因為構建合適的取樣區域有許多不同的方法。我們發現分數階最大取樣的形式減少了許多數據集的過擬合現象。例如，我們改善了CIFAR-100目前最先進的技術，甚至沒使用隨機去活化(dropout)。\n\n### 卷積神經網路\n\b卷積網路被使用來解決影像辨識問題，主要由兩種類型的分層結構組成：\n- 卷積濾波層\n- 若干形式的空間取樣，例如最大取樣(max-pooling)\n\n聚焦於改善卷積層的研究造就了豐富的技術，例如dropout [[10]](#參考文獻)、DropConnect [[12]](#參考文獻)、deep networks with many small filters [[2]](#參考文獻)、large input layer filters for detecting texture [[5]](#參考文獻)以及deeply supervised networks [[6]](#參考文獻)。\n\n相較之下，不起眼的取樣操作已經被逐漸忽略，長期以來2 × 2 max-pooling(MP2-pooling)已成為構建卷積神經網路的默認選項。MP2-pooling之所以受歡迎有許多原因：執行快速、能迅速縮減隱藏層的大小、對於平移與彈性形變有一定程度的不變性。然而，取樣區域的不相交特性可能限制其泛化能力。此外，由於MP2 pooling如此迅速地縮減了隱藏層的大小，因此需要透過堆疊連續的卷積層，以構建真正的深度網路 [[7, 9, 11]](#參考文獻)。有兩種方法已經被提出來解決此問題：\n- 使用3 x 3取樣區域搭配步長2(strides = 2)的重疊取樣 [[5]](#參考文獻)\n- 隨機取樣，即以大小偏差的取樣形式代替在每個取樣區域選擇最大值的動作 [[13]](#參考文獻)\n\n但是，這兩種技術仍將隱藏層大小縮減了兩倍。這令人不禁想問，是否能有更和緩的方法來有效地應用特徵空間取樣。如果取樣只讓隱藏層大小縮減$ \\sqrt 2 $倍，那麼我們在構建卷積神經網路時能使用的取樣層數便能翻兩倍。每個取樣層都有機會以不同尺度來查看輸入影像，以正確的尺度查看影像，應該能更容易地辨識出線索特徵，並將物件標記為特定類別。\n\n因此，本文的重點是最大取樣的一種特殊形式，我們稱之為分數階最大取樣(Fractional Max-Pooling, FMP)， FMP的想法是，將影像的特徵空間尺寸縮小α倍(1 < α < 2)。如同隨機取樣，FMP在取樣過程中引入了一定程度的隨機性。然而，FMP與隨機取樣不同的是，其隨機性和取樣區域的選擇有關，而非每個取樣區域內的取樣方式。\n\n於第二節中，我們將說明分數階最大取樣的形式。簡而言之，有三種選擇會影響FMP的實現方式：\n- 取樣的非整數值α決定了取樣層輸入和輸出的特徵空間尺寸比例。例如2 × 2最大取樣對應於α = 2的特定情況。\n- 取樣區域可以用隨機或偽隨機的方式來選擇。在FMP的隨機性和使用隨機去活化是否搭配數據增強(data augmentation)之間似乎得做適當的取捨，隨機的FMP或許可以表現得更好，但如果「過度」使用隨機去活化或訓練數據強化，則可能導致欠擬合(underfitting)。\n- 取樣區域可以不相交(disjoint)或重疊(overlapping)。不相交的區域較容易描述，但我們發現重疊區域的效果更好。\n\n我們會在第三節中描述如何設計和訓練我們的卷積網路，並於第四節中展示MNIST手寫數字、CIFAR-10、CIFAR-100、阿薩姆語手寫文字以及CASIA-OLHWDB1.1手寫漢字等數據集的訓練結果。\n\n### 分數階最大取樣\nCNN的每個卷積濾波器都會產生一個隱含變數的矩陣，通常使用某種形式的取樣來縮減矩陣大小。最大取樣是一個採用$ N_{in} \\times N_{in} $矩陣並返回較小的$ N_{out} \\times N_{out} $輸出矩陣的過程，這是透過將$ N_{in} \\times N_{in} $輸入正方形分割為$ N^2_{out} $個取樣區域$ (P_{i,j}) $而實現：\n$$ (P_{i,j}) \\subset \\lbrace 1,2,...,N_{in} \\rbrace ^2 \\ \\text{for each}\\ (i,j) \\in \\lbrace 1,...,N_{out} \\rbrace ^2 $$\n接著令：\n$$ Output_{i,j} = \\displaystyle{\\max_{(k,l)\\in P_{i,j}}} Input_{k,l} $$\n\n以我們的使用慣例2 x 2最大取樣而言，$ N_{in} = 2N_{out}\\ and\\ P_{i,j} = \\rbrace 2i-1,2i \\rbrace \\times \\rbrace 2j-1,2j \\rbrace $。[參考文獻 [5]](#參考文獻)中提到，最大取樣應用於3 x 3重疊取樣區域，因此$ N_{in} = 2N_{out}+1 $，$ P_{i,j} $為3 x 3正方形，以步長2進行擴展。上述兩種情況中，$ N_{in}\\ /\\ N_{out} \\approx 2 $，因此輸入影像中任何有效特徵的空間大小會在每個取樣層中減半。相較之下，如果我們採用$ N_{in}\\ /\\ N_{out} \\approx \\sqrt[n]{2} $，則有效特徵的空間大小之縮小速率減緩N倍。為清楚起見，我們現在將重點放在$ N_{in}\\ /\\ N_{out} \\in (1,2) $，因為我們主要感興趣的是準確率；如果對執行速度相當介意，則FMP可以採用$ N_{in}\\ /\\ N_{out} \\in (2,3) $。\n\n![](https://i.imgur.com/n77VYDM.png)\nFigure 1：由左至右依序為\b36 x 36的網格；4個偽隨機的FMP不相交取樣區域，$ \\alpha \\in \\lbrace \\sqrt[3]{2},\\sqrt 2,2,\\sqrt 5 \\rbrace $；以及$ \\alpha = \\sqrt 2 $的隨機的FMP不相交取樣區域。對$ \\alpha \\in (1,2) $，FMP生成的矩形取樣區域其邊長為1或2。對$ \\alpha \\in (2,3) $，其取樣區域邊長則為2或3。\n\n給定一對特定數值$ (N_{in},N_{out}) $，我們需要一種選擇取樣區域$ (P_{i,j}) $的方法。我們將考慮兩種類型的排列方式：重疊的正方形以及不相交的矩形集合。在Figure 1中我們展示了數種不同的方法來將36 x 36正方形網格分割為不相交的矩形。Figure 1中的第2、第3及第6張影像可以用來定義重疊的2 x 2正方形的排列：將影像中每個矩形的左上角視為其中一個正方形的左上角。為標準化地描述如何生成取樣區域，令：\n$$ (a_i)^{N_{out}}_{i=0}\\ ,\\ (b_i)^{N_{out}}_{i=0} $$\n<a id=\"link-formula-1\"></a>\n\n為兩個以1為起始、$ N_{in} $結束的整數遞增數列，且遞增量皆為1或2(i.e. $ a_{i+1}-a_i \\in \\lbrace 1,2 \\rbrace $)。然後我們可以用以下任一方式定義取樣區域 :\n$$ P = [a_{i-1},a_i-1] \\times [b_{j-1},b_j-1]\\ \\text{or}\\ P_{i,j} = [a_{i-1},a_i] \\times [b_{j-1},b_j]\\ \\ (1) $$\n\n![](https://i.imgur.com/a1uq3oy.png)\nFigure 2：左上角為柯達公司釋出的真實色彩圖片數據集，解析度為384 x 256(原始解析度為768 x 512)。其他五張影像則是以隨機的不相交FMP$ \\sqrt 2 $取樣區域進行6層平均取樣的結果，解析度為左上角的八分之一。\n\n我們稱這兩種情況分別為不相交和重疊，接著嘗試兩種不同的方法來生成整數序列：隨機數列以及偽隨機數列。如果數列的增加是透過對適當數量的1和2進行隨機排列而獲得的，那麼我們稱其為隨機數列。若是透過以下方式則稱之偽隨機數列：\n$$ a_i = ceiling(\\alpha(i+u)),\\ \\alpha \\in (1,2)\\ \\text{with some}\\ u  \\in (0,1) $$\n\n以下是對應$ N_{in} = 25、N_{out} = 18 $之情況的增量模式，左側增量為隨機生成，右側增量則來自偽隨機數列：\n\n211112112211112122 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 112112121121211212\n111222121121112121 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 212112121121121211\n121122112111211212 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 211211212112121121\n\n儘管兩種類型的數列都是不規則的，但偽隨機數列所生成的取樣區域較隨機數列來得穩定。為顯示取樣區域隨機化的效果，請參考Figure 2。我們拍攝了一張影像，接著疊代使用不相交的隨機取樣區域來縮減影像大小(在每個取樣區域中取平均值)。結果按比例縮減的影像顯示出彈性形變。相反地，若我們使用偽隨機取樣區域，則生成的影像僅為原始影像的真實比例縮小版本。\n\n### 實作方法\n<br>\n![](https://i.imgur.com/WRZu8v6.png)\nFigure 3：微型FMP$ \\sqrt 2 $網路各層的空間大小如圖所示。分數$ \\frac32,\\frac64,\\frac{10}{7} $近似於$ \\sqrt 2 $。\n\n我們將使用稀疏卷積網路的實例來進行訓練，這實際上意味著我們能逐層依序指定卷積網路的結構。例如：\n$$ 10C2-FMP \\sqrt 2 -20C-30C2-FMP \\sqrt 2 -40C2-50C1-output $$\n\n輸入層的空間大小是透過由右至左的運算所獲得的：每個C2卷積層將空間大小增加為2倍，FMP$ \\sqrt 2 $層則是將空間大小增加為2倍(四捨五入至最接近的整數)；參見Figure 3。輸入層通常會大於輸入影像—必要時會自動以0來補齊。分數階最大取樣也能輕易地在常用的卷積神經網路套件中實現。為簡單起見，我們使用的所有網路中每個卷積層的濾波器數量都呈線性增長。因此，我們能簡要地說明上述的網路結構為\n\n$$ (10_nC2-FMP \\sqrt 2)_3-C2-C1-output $$\n\n$ 10_n $代表第n個卷積層中的濾波器數量為$ 10_n $，下標的3表示3對交替使用的C2/FMP層。使用隨機去活化時，進入的網路越深，所使用的隨機去活化數量就越多。我們在第一個隱藏層中使用0％隨機去活化，並在最後一個隱藏層中線性增加至50％。所使用的活化函數為leaky ReLU(帶滲漏整流線性函數)。\n\n#### 模型平均\n每次我們基於訓練或測試目的而應用FMP網路時，都會使用不同的隨機或偽隨機序列來生成取樣區域。因此FMP網絡可以被視為相似網路的集合，而每個不同的取樣區域設定都定義了該集合的不同成員。 這類似於隨機去活化[[10]](#參考文獻)；隨機去活化其遮罩的不同數值可以用來定義相關網路的集合。如同隨機去活化，FMP網路的模型平均可以幫助提升效能。如果你對同一張測試影像進行多次分類，可能會得到許多不同的預測結果。對每個測試影像進行多次分類後，使用多數決可以大幅提升準確度；參見Figure 4。\n\n![](https://i.imgur.com/NXYLssj.png)\nFigure 4：重複測試對於一個由MNIST所訓練的FMP網路之影響\n\n### 實驗結果\n<br>\n\n#### 不使用數據增強或隨機去活化\n為比較不同種類的分數階最大取樣，我們在$ \\text{MNIST}^1 $以及CIFAR-100數據集上訓練FMP網路[[4]](#參考文獻)。對於MNIST，我們使用了小型的FMP網路：\n$$ \\text{input layer size 36 x 36：}\\ (36_nC2-FMP \\sqrt 2)_6-C2-C1-output $$ \n\n對於CIFAR-100則使用了較大的網路：\n$$ \\text{input layer size 94 x 94：}\\ (64_nC2-FMP \\sqrt[3]{2})_{12}-C2-C1-output $$ \n\n在不使用訓練數據增強的情況下，這兩個數據集最新的測試誤差分別為0.39%以及34.57%[[6]](#參考文獻)。FMP網路的結果如Table 1所示。使用重複測試12次的模型平均，我們發現使用隨機重疊取樣的FMP對這兩個數據集的表現最佳。對於CIFAR-100而言，此方法相較於常規的最大取樣有著相當程度的改進。就網路的複雜程度概括來說，CIFAR-100的網路擁有1200萬個權重參數，且經過250次訓練數據的重複訓練(在GeForce GTX 780上需耗費18小時)。我們嘗試改變CIFAR-100每層的隱藏單元數量，搭配隨機重疊取樣：\n\n- 使用$ {16}_nC2 $(0.8M weights)的測試結果誤差為42.07% / 34.87\n- 使用$ {32}_nC2 $(3.2M weights)的測試結果誤差為35.09% / 29.66\n- 使用$ {96}_nC2 $(27M weights)結合隨機去活化以及較為和緩的學習率衰減，測試結果誤差為27.62% / 23.82\n\n![](https://i.imgur.com/NblVtwE.png)\nTable 1：MNIST以及CIFAR-100的測試誤差\n\n註1：[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)\n\n#### 阿薩姆語手寫文字\n為比較FMP和MP2兩種取樣方式搭配訓練數據增強的影響，我們使用線上線上阿薩姆語手寫文字數據集來測試。此數據集包含了183個印度-雅利安文字中每個文字的45個樣本。「線上」的意思是指每一筆畫皆代表(x, y)座標序列。我們使用每個文字的前36個樣本做為訓練集，剩餘的9個樣本做為測試集，並將樣本縮放為64 x 64的大小來訓練一個有6層MP2的網路：\n$$ 32_nC3-MP2-(C2-MP2)_{12}-C2-output $$\n\n以及使用10層隨機的重疊FMP$ \\sqrt 2 $取樣的FMP網路：\n$$ (32_nC2-FMP\\sqrt 2)_{10}-C2-C1-output $$\n\n我們訓練了沒有使用隨機去活化的網路，以及：\n- 不使用數據增強\n- 使用隨機平移來位移文字\n- 使用仿射轉換(平移、旋轉、拉伸以及剪切的隨機組合)\n\n![](https://i.imgur.com/fNDKsYO.png)\nTable 2：以阿薩姆語手寫文字數據集搭配不同類型的數據增強來訓練網路的測試誤差\n\n參照Table 2。某種意義上來說，我們對於「在某種程度的輕微失真下，筆跡的意義通常是不變的」的認知，來自最大取樣與訓練數據增強這兩種不同的方式。有趣的是，不使用數據增強的FMP網路比起使用數據增強的MP2網路表現更好，顯示FMP網路更適合處理該數據集。\n\n#### 線上中文手寫文字\nCASIA-OLHWDB1.1數據集包含了3755個獨立的GBK 1級漢字手寫樣本[[8]](#參考文獻)，每個類別大約有240個訓練樣本與60個測試樣本。使用4層的MP2取樣層可以達到5.61%的測試誤差[[2]](#參考文獻)。\n\n我們使用[[3]](#參考文獻)所描述的線上字符表示法；以64 x 64的大小繪製文字，加上量測筆跡方向的特徵，生成64 x 64 x 9的陣列。使用2 x 2最大取樣、隨機去活化以及仿射訓練數據增強，測試結果誤差為3.82% [[3]](#參考文獻)。以偽隨機的重疊FMP取代最大取樣：\n$$ (64_nC2-FMP\\sqrt 2)_7-(C2-MP2-C1)_2-C2-C1-output $$\n\n測試結果誤差為3.26%(1 test)以及2.97%(12 tests)。\n\n#### CIFAR-10搭配隨機去活化與訓練數據增強\n對於CIFAR-10數據集，我們使用了隨機去活化和透過仿射轉換來擴充訓練數據：隨機對數據集執行平移、旋轉、反射、拉伸及剪切的預處理。相較之下，人類在CIFAR-10數據集的表現估計為6%$ {}^2 $ 。而近期(2015)於Kaggle平台上的CIFAR-10競賽，獲勝者的測試誤差為4.47%$ {}^3 $, 使用上述的數據增強策略和以下的網路結構：\n$$ (300_nC2-300_nC2-MP2)_5-C2-C1-output $$\n\n使用偽隨機的重疊FMP網路：\n$$ (160_nC2-FMP\\sqrt[3]{2})_12-C2-C1-output $$\n\n我們得到了4.50%(1 test)，3.67%(12 tests)及3.47%(100 tests)的測試誤差。\n\n註2：[http://karpathy.github.io/2011/04/27/manually-classifying-cifar10/](http://karpathy.github.io/2011/04/27/manually-classifying-cifar10/)\n註3：[https://www.kaggle.com/c/cifar-10/](https://www.kaggle.com/c/cifar-10/)\n＊原文中註2的原始網址(http://karpathy.ca/myblog/?p=160)已失效，推測是網站搬遷。\n\n### 結論\n我們在許多受歡迎的數據集上訓練搭配分數階最大取樣的卷積網路，並於效能方面發現有顯著的改善。取樣區域重疊的FMP比起不相交的似乎表現得更好。使用訓練數據增強時，偽隨機取樣區域比隨機取樣區域的表現更佳。若微調隨機去活化的使用數量，隨機取樣可能會重新取得優勢。\n\n再次查看Figure 2由隨機取樣所創造的失真，請注意此「失真」可以分解為「X軸的失真」和「Y軸的失真」，探究無法以[方程式(1)](#link-formula-1)表達的取樣區域可能會很有趣，因為它們可能將更為通用的失真編碼至結果的卷積網路。\n\n### 參考文獻\n[1] K. Bache and M. Lichman. UCI machine learning repository, 2013.\n\n[2] D. Ciresan, U. Meier, and J. Schmidhuber. Multi-column deep neural networks for image classification. In Computer Vision and Pattern Recognition(CVPR), 2012 IEEE Conference on, pages 3642–3649, 2012.\n\n[3] Ben Graham. Spatially-sparse convolutional neural networks. 2014.\n\n[4] Alex Krizhevsky. Learning Multiple Layers of Features from Tiny Images.Technical report, 2009.\n\n[5] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolutional neural networks. In F.Pereira, C.J.C. Burges, L. Bottou, and K.Q. Weinberger, editors, Advances in Neural Information Processing Systems 25, pages 1097–1105. Curran Associates, Inc., 2012.\n\n[6] Chen-Yu Lee, Saining Xie, Patrick Gallagher, Zhengyou Zhang, and Zhuowen Tu. Deeply-Supervised Nets, 2014.\n\n[7] Min Lin, Qiang Chen, and Shuicheng Yan. Network in network. ICLR, 2014.\n\n[8] C.-L. Liu, F. Yin, D.-H. Wang, and Q.-F. Wang. CASIA online and offline Chinese handwriting databases. In Proc. 11th International Conference on Document Analysis and Recognition (ICDAR), Beijing, China, pages 37–41, 2011.\n\n[9] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. 2014.\n\n[10] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: A Simple Way to Prevent Neural Networks from Overfitting. Journal of Machine Learning Research, 15:1929–1958, 2014.\n\n[11] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed,Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. 2014.\n\n[12] Li Wan, Matthew Zeiler, Sixin Zhang, Yann Lecun, and Rob Fergus. Regularization of Neural Networks using DropConnect, 2013. JMLR W&CP 28 (3) : 1058–1066, 2013.\n\n[13] Matthew D. Zeiler and Rob Fergus. Stochastic Pooling for Regularization of Deep Convolutional Neural Networks. ICLR 2013.","tags":["deep learning","computer vison"],"categories":["Study"]},{"title":"樹莓派：紅外線熱像儀","url":"/rspi-thermal-cam-amg8833/","content":"看到火車站架設熱像儀監控旅客們的體溫，然而並非每個車站都能設置如此昂貴的儀器，出於好奇也想做個低成本的來看看，雖然解析度與精確度都比不上昂貴的精密儀器，但在近距離下能做到快速、自動偵測體溫的話，比起讓站務人員逐一量測後進站，這應該堪用且有效率多了。\n<!--more-->\n### AMG8833 Intro\n![](https://i.imgur.com/JATdb1S.jpg)\n於是我買來了Adafruit AMG8833模組，這模組上頭裝著Panasonic所生產的紅外線陣列感測器。\nDatasheet：[Panasonic IR Array Sensor Grid-EYE](https://b2b-api.panasonic.eu/file_stream/pids/fileversion/1819)\n\n![](https://i.imgur.com/gQseBWz.jpg)\n![](https://i.imgur.com/DBrxsGu.jpg)\n\n參考[Adafruit官網](https://www.adafruit.com/product/3538)的技術參數說明：\n1. 感測器為8x8紅外線陣列\n2. 溫度感測區間為攝氏0度～攝氏80度(精度為正負2.5度)\n3. 人體最大感測距離為7米\n4. 透過[I2C協定](https://zh.wikipedia.org/wiki/I%C2%B2C)進行數據傳輸\n\n\n### Setting & Installing\n接下來將於運行Raspbian作業系統的樹莓派上進行環境設置，我習慣[使用VNC Server與樹莓派進行遠端連線操作](https://laplacetw.github.io/rspi-meet-raspberry-pi-b3-plus/#Remote)。\n\n#### 系統更新\n{% codeblock lang:shell %}\n$ sudo apt-get update\n$ sudo apt-get upgrade\n{% endcodeblock %}\n\n#### 啟用I2C & SPI介面\n{% codeblock lang:shell %}\n$ sudo raspi-config\n{% endcodeblock %}\n\n在選項5的介面設定中啟用它們，然後測試是否成功啟用\n{% codeblock lang:shell %}\n$ ls /dev/i2c* /dev/spi*\n{% endcodeblock %}\n\n#### Package Installing\n直接安裝Adafruit的AMG88XX Package，pip會處理其他依賴的函式庫(e.g. Adafruit-Blinka)。\n{% codeblock lang:shell %}\n$ sudo pip3 install adafruit-circuitpython-amg88xx\n{% endcodeblock %}\n![](https://i.imgur.com/sANUgo1.png)\n\n#### Blinka Test\n使用Adafruit的測試範例來確認環境設定是否完成。\n{% codeblock lang:py %}\nimport board\nimport digitalio\nimport busio\n\nprint(\"Hello blinka!\")\n\n# Try to great a Digital input\npin = digitalio.DigitalInOut(board.D4)\nprint(\"Digital IO ok!\")\n\n# Try to create an I2C device\ni2c = busio.I2C(board.SCL, board.SDA)\nprint(\"I2C ok!\")\n\n# Try to create an SPI device\nspi = busio.SPI(board.SCLK, board.MOSI, board.MISO)\nprint(\"SPI ok!\")\n\nprint(\"done!\")\n{% endcodeblock %}\n![](https://i.imgur.com/msoQDyb.png)\n\n#### I2C Test\n依照[樹莓派GPIO](https://pinout.xyz/)與AMG8833進行連接：\n1. 3V Power連接到Vin\n2. \b\bGND連接到GND\n3. 連接SDA & SCL\n![](https://i.imgur.com/ilmXszn.jpg)\n\n試著透過I2C讀取感測器數據並印出來\n{% codeblock lang:py %}\nimport time\nimport busio\nimport board\nimport adafruit_amg88xx\n\ni2c = busio.I2C(board.SCL, board.SDA)\namg = adafruit_amg88xx.AMG88XX(i2c)\n\nwhile True:\n    for row in amg.pixels:\n        # Pad to 1 decimal place\n        print([\"{0:.1f}\".format(temp) for temp in row])\n        print(\"\")\n    print(\"\\n\")\n    time.sleep(1)\n{% endcodeblock %}\n![](https://i.imgur.com/DK85IXe.png)\n\n### Build Thermal Camera\n安裝溫度數據視覺化所需的函式庫\n{% codeblock lang:shell %}\n$ sudo apt-get install -y python3-scipy python3-pygame\n$ sudo pip3 install colour\n{% endcodeblock %}\n\nAdafruit官方範例程式：\n{% codeblock lang:py %}\n\"\"\"This example is for Raspberry Pi (Linux) only!\n   It will not work on microcontrollers running CircuitPython!\"\"\"\nimport os\nimport math\nimport time\n\nimport busio\nimport board\n\nimport numpy as np\nimport pygame\nfrom scipy.interpolate import griddata\n\nfrom colour import Color\n\nimport adafruit_amg88xx\n\ni2c_bus = busio.I2C(board.SCL, board.SDA)\n\n#low range of the sensor (this will be blue on the screen)\nMINTEMP = 26.\n\n#high range of the sensor (this will be red on the screen)\nMAXTEMP = 32.\n\n#how many color values we can have\nCOLORDEPTH = 1024\n\nos.putenv('SDL_FBDEV', '/dev/fb1')\npygame.init()\n\n#initialize the sensor\nsensor = adafruit_amg88xx.AMG88XX(i2c_bus)\n\n# pylint: disable=invalid-slice-index\npoints = [(math.floor(ix / 8), (ix % 8)) for ix in range(0, 64)]\ngrid_x, grid_y = np.mgrid[0:7:32j, 0:7:32j]\n# pylint: enable=invalid-slice-index\n\n#sensor is an 8x8 grid so lets do a square\nheight = 240\nwidth = 240\n\n#the list of colors we can choose from\nblue = Color(\"indigo\")\ncolors = list(blue.range_to(Color(\"red\"), COLORDEPTH))\n\n#create the array of colors\ncolors = [(int(c.red * 255), int(c.green * 255), int(c.blue * 255)) for c in colors]\n\ndisplayPixelWidth = width / 30\ndisplayPixelHeight = height / 30\n\nlcd = pygame.display.set_mode((width, height))\n\nlcd.fill((255, 0, 0))\n\npygame.display.update()\npygame.mouse.set_visible(False)\n\nlcd.fill((0, 0, 0))\npygame.display.update()\n\n#some utility functions\ndef constrain(val, min_val, max_val):\n    return min(max_val, max(min_val, val))\n\ndef map_value(x, in_min, in_max, out_min, out_max):\n    return (x - in_min) * (out_max - out_min) / (in_max - in_min) + out_min\n\n#let the sensor initialize\ntime.sleep(.1)\n\nwhile True:\n\n    #read the pixels\n    pixels = []\n    for row in sensor.pixels:\n        pixels = pixels + row\n    pixels = [map_value(p, MINTEMP, MAXTEMP, 0, COLORDEPTH - 1) for p in pixels]\n\n    #perform interpolation\n    bicubic = griddata(points, pixels, (grid_x, grid_y), method='cubic')\n\n    #draw everything\n    for ix, row in enumerate(bicubic):\n        for jx, pixel in enumerate(row):\n            pygame.draw.rect(lcd, colors[constrain(int(pixel), 0, COLORDEPTH- 1)],\n                             (displayPixelHeight * ix, displayPixelWidth * jx,\n                              displayPixelHeight, displayPixelWidth))\n\n    pygame.display.update()\n{% endcodeblock %}\n<br>\n迷你紅外線熱像儀就這麼運作起來囉～🙆‍♂️ 可依照自己的測試環境，嘗試調整感測溫度上下限讓影像清晰一些。\n![](https://i.imgur.com/KtWuOfU.gif)\n\n＊參考\n1. [I2C-協定用法原理簡介-晶片溝通的橋樑](https://www.strongpilab.com/i2c-introduction/)\n2. [Installing CircuitPython Libraries on Raspberry Pi](https://learn.adafruit.com/circuitpython-on-raspberrypi-linux/installing-circuitpython-on-raspberry-pi)\n3. [Adafruit AMG8833 8x8 Thermal Camera Sensor](https://learn.adafruit.com/adafruit-amg8833-8x8-thermal-camera-sensor/python-circuitpython)\n4. [Raspberry Pi Thermal Camera](https://learn.adafruit.com/adafruit-amg8833-8x8-thermal-camera-sensor/raspberry-pi-thermal-camera)","tags":["IoT","raspberry pi","adafruit","thermal camera"],"categories":["Raspberry Pi"]},{"title":"Python批次影片轉GIF","url":"/python-batch-video-to-gif/","content":"\b\b\b\b\b\b\b\b\b偶爾會為了DEMO用途，需要將影片\b轉換為GIF的形式，便於穿插在文章裡頭，但我不想為了這小小的需求安裝什麼軟體。<!--more-->而線上服務就是圖個方便打到很多使用者的痛點，但你必須將圖片上傳，這對某些使用者而言可能有疑慮...雖然我見到的線上轉檔服務使用者都是莫名安心地上傳的(?)\n\nPython是非常美好的程式語言，自己寫段程式碼來處理就行了😎&nbsp;&nbsp;我們只需要先在電腦安裝[FFmpeg](https://ffmpeg.org/)，然後引入[moviepy](https://pypi.org/project/moviepy/)這個套件就行了，作者zulko在他的個人網站有[詳細的教學](http://zulko.github.io/blog/2014/01/23/making-animated-gifs-from-video-files-with-python/)。\n\n---\n範例程式：\n\n設置參數可更換影片輸入格式、是否加入浮水印以及生成的GIF和浮水印的縮放倍率。\n{% codeblock lang:py %}\n#!/usr/bin/env python3\nfrom glob import glob\nimport moviepy.editor as mp\n\n\n# setting\nfiletype = '.mov'\nwatermark = './devilcat.png'\nscale_gif = 0.3\nscale_mark = 0.3\n\nvideos = glob('./*' + filetype)\nvideos.sort()\nfor video in videos:\n    output = video.replace(filetype, '.gif')\n    with mp.VideoFileClip(video).resize(scale_gif) as clip:\n        if watermark == '':  # no watermark\n            clip.write_gif(output, fps=5)\n        else:\n            mark_image = (mp.ImageClip(watermark)\n            .resize(scale_mark)\n            .set_duration(clip.duration)\n            .set_pos((\"left\", \"top\")))\n            \n            # add watermark to video\n            mark_video = mp.CompositeVideoClip([clip, mark_image])\n            mark_video.write_gif(output, fps=5)\n{% endcodeblock %}\n＊關於resize的錯誤參考：[stackoverflow — Moviepy does not recognize resize function](https://stackoverflow.com/questions/57696343/moviepy-does-not-recognize-resize-function)\n\n---\n我使用[YT頻道哈哈台訪問浪漫Duke經典片段](https://youtu.be/H4Cn4taeuA4)當範例，實際執行將影片轉換為GIF動圖並加上浮水印。\n\n- 首先來畫一個浮水印...惡魔貓男！你今晚的惡夢！(\b激動 ⬇︎\n![](https://i.imgur.com/FwCJqVN.png)\n\n- 接著準備幾個要轉成GIF的片段，開始轉換⬇︎\n![](https://i.imgur.com/6FNRGii.png)\n\n- 轉檔結果，可以看到GIF左上角出現剛剛畫的浮水印🤣&nbsp;&nbsp;⬇︎\n\n世界要有愛!|雞肉飯❤️\n:----------------------------------:|:-----------------------------------:\n![](https://i.imgur.com/tLDHNqj.gif)|![](https://i.imgur.com/IaS7v3K.gif)\n好看!|浪漫Duke❤️\n![](https://i.imgur.com/XLTZUVm.gif)|![](https://i.imgur.com/aKcPhnH.gif)","tags":["python","moviepy","mytoolbox"],"categories":["Python"]},{"title":"eMask口罩預購&取貨","url":"/taiwan-emask-pre-order/","content":"Taiwan No.1❤️<!--more-->\n\n### 口罩預購\n<br>\n\b[eMask口罩預購系統](https://emask.taiwan.gov.tw/msk/index.jsp)於3/12~3/18開放首波預購，今天終於開始取貨啦！取貨時間為3/26~4/1，若沒有在期限內完成領取就視同放棄唷。(這可不是什麼愚人節梗！\n\n第二波預購期間為3/25~3/27晚上8點截止，詳情見[衛福部公告](https://mrmad.com.tw/emask-taiwan-gov-20-app)，我個人是使用健保快易通APP來預購的，相關設定可以參考這篇教學：[點我](https://mrmad.com.tw/emask-taiwan-gov-20-app)，無須讀取我們的~~地表最強~~健保卡，非常方便。\n\n預購完成後就等待抽籤，首波預購人數不多，因此有參加預購的人都能買到(儘管有18萬人沒有繳費...)，第二波就未知數了＠＠\n3/28 更新：因為第二波預購人數依然未超過上限，因此登記預購者都能買到。\n![](https://i.imgur.com/vRZqnCX.jpg)\n\n### 預購繳費\n<br>\n第二波預購開放APP也能刷卡繳費囉～話說填寫信用卡資訊的這個「卡片後三碼」反而讓我有點錯愕，就檢核碼呀😅\n![](https://i.imgur.com/Hi10jKK.png)\n繳費成功！\n![](https://i.imgur.com/t3NxohE.png)\n\n### 口罩領取\n<br>\n統一超商ibon首頁就能看到口罩取貨專區😷\n![](https://i.imgur.com/c0mPcLA.jpg)\n\n輸入身分證後4碼以及取貨通知簡訊中的取貨序號\n![](https://i.imgur.com/jEZxkSq.jpg)\n\n拿著小白單到超商櫃檯就能領取到珍貴的口罩！\n![](https://i.imgur.com/CW90CFq.jpg)\n\n\n\n希望這糟糕的一切能盡快結束😬，祝福我們都健健康康💪。","tags":["covid-2019"],"categories":["Daily"]},{"title":"Manjaro安裝NVIDIA Driver＆CUDA","url":"/linux-manjaro-nvidia-driver-and-cuda/","content":"搞定Manjaro的基本環境後，接下來要設定GTX 1660 Super以利後續的運算任務...噢，又折騰了不少時間，得好好紀錄過程與問題才行吶。<!--more-->\n\n### Manjaro freezing at boot screen after NVIDIA driver installed\n透過Manjaro硬體偵測安裝non-free driver：\n{% codeblock lang:bash %}\n$ sudo mhwd -a pci nonfree 0300\n{% endcodeblock %}\n![](https://i.imgur.com/mfQGFmj.png)\n\n重新開機後，很好，畫面就停在黑螢幕了，進不去登入畫面(傻眼。原來在安裝了NVIDIA驅動後還必須手動修改硬體設定，否則視窗服務的運作會異常，導致系統看起來掛了，所以安裝N卡驅動的正確姿勢應該是要先修改設定文件後再重新啟動。首先，在黑螢幕的畫面按下ctrl + alt + F3來進入Terminal：\n\n查詢GPU BusID\n{% codeblock lang:bash %}\n$ lspci | grep -E \"VGA|3D\"\n{% endcodeblock %}\n輸出訊息前三組數字即為BusID(忽略前綴0)，例如「01:00.0」則BusID為「1:0:0」。\n\n備份設定\n{% codeblock lang:bash %}\n$ sudo mv /etc/X11/xorg.conf.d/90-mhwd.conf /etc/X11/xorg.conf.d/90-mhwd.conf.bak\n{% endcodeblock %}\n\n寫入 /etc/X11/xorg.conf.d/90-mhwd.conf，BusID改為你要設定的GPU，我是設定為內顯的AMD GPU。\n{% codeblock lang:bash %}\nSection \"Module\"\n    Load \"modesetting\"\nEndSection\n\nSection \"Device\"\n    Identifier \"nvidia\"\n    Driver \"nvidia\"\n    BusID \"PCI:1:0:0\"\n    Option \"AllowEmptyInitialConfiguration\"\nEndSection\n{% endcodeblock %}\n\n修改完成後重新啟動即可。\n\n參考：https://blog.csdn.net/baidu_33340703/article/details/103977592\n\n### CUDA＆cuDNN\n在安裝CUDA之前，先確認N卡驅動是否正確安裝：\n{% codeblock lang:bash %}\n$ nvidia-smi\n{% endcodeblock %}\n![](https://i.imgur.com/UKIf8U1.png)\n\n安裝CUDA、cuDNN以及後續會用到的Python函式庫：\n{% codeblock lang:bash %}\n$ sudo pacman -Syu tensorflow-cuda cuda cudnn python-pycuda python-tensorflow-cuda python-matplotlib\n{% endcodeblock %}\n＊為避免和pacman軟體庫提供的版本衝突，Arch/Manjaro移除了pip軟體庫中的tensorflow-gpu，以tensorflow-cuda取代之。\n\n將CUDA安裝目錄中的samples複製到home目錄下，編譯然後測試CUDA是否安裝成功：\n{% codeblock lang:bash %}\n$ cp -r /opt/cuda/samples ~\n$ ~/samples\n$ sudo make -k\n{% endcodeblock %}\n編譯過程需要點時間，大概30分鐘，編譯完成後執行deviceQuery：\n{% codeblock lang:bash %}\n$ cd ~/samples/1_Utilities/deviceQuery\n$ ./deviceQuery\n./deviceQuery Starting...\n\nCUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"GeForce GTX 1660 SUPER\"\n CUDA Driver Version / Runtime Version          10.2 / 10.2\n CUDA Capability Major/Minor version number:    7.5\n Total amount of global memory:                 5945 MBytes (6233391104 bytes)\n (22) Multiprocessors, ( 64) CUDA Cores/MP:     1408 CUDA Cores\n \n(略...)\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.2, CUDA Runtime Version = 10.2, NumDevs = 1\nResult = PASS  # PASS表示CUDA安裝成功\n{% endcodeblock %}\n\n### Test\n用[MNIST手寫數字辨識](https://laplacetw.github.io/data-sci-ml-hello-world-mnist/)\b來做測試，每批次都1秒就運算完了，雖然實際應該不到1秒XD\n\n\n### Keras could not create cudnn handle: cudnn_status_alloc_failed\n噢，正想說一切都配置好了，趕緊來繼續實驗放置了半個月的cifar-10模型訓練(因為Google CoLab的免費資源太熱門導致經常斷線而白忙，只好自己建置運算環境了😂)，結果出現了一個看起來很厲害的錯誤訊息(傻眼x2。查詢後發現是GPU記憶體配置問題，[Tensorflow為了避免記憶體碎片化](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth)，預設會盡可能把可見的GPU記憶體都映射給當前的進程：\n\n>By default, TensorFlow maps nearly all of the GPU memory of all GPUs (subject to CUDA_VISIBLE_DEVICES) visible to the process. This is done to more efficiently use the relatively precious GPU memory resources on the devices by reducing memory fragmentation.\n\n結果就是cifar-10這樣的運算量就導致記憶體不足而拋出錯誤訊息，所以我們必須讓Tensorflow按需求配置GPU記憶體：\n{% codeblock lang:py %}\nconfig = tf.compat.v1.ConfigProto()  # tensorflow-gpu 2.1.0\nconfig.gpu_options.allow_growth=True\ntf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))\n{% endcodeblock %}\n\n解決～每批次的運算速度比我在CoLab上面快10秒呢，$$沒有白花了QQ\n\n參考：\n- https://blog.csdn.net/weixin_42769131/article/details/88848478\n- https://blog.csdn.net/zuoyouzouzou/article/details/104329286","tags":["keras","linux","manjaro","nvidia"],"categories":["Linux"]},{"title":"Manjaro:You need to load kernel first","url":"/linux-need-to-load-kernel-first/","content":"Manjaro在安裝完成並執行同步軟體庫&更新後，重新開機黑屏顯示「error: file '/boot/vmlinuz-4.19-x86_64' not found」<!--more-->、「\berror: You need to load kernel first」，這問題在我重新安裝並更新後依然發生了，到Manjaro Forum爬文才\b得知此問題來自pacman原始碼的變更，若使用低於18.1.5的舊版本ISO檔進行安裝就可能會受到影響，而我是使用18.0.1來安裝的😅\n\n### Solution\n\n使用live USB來開機啟動Manjaro，在terminal執行以下指令 :\n{% codeblock lang:bash %}\n$ sudo manjaro-chroot -a\n$ pacman -S linux419 linux419-headers\n$ mkinitcpio -P\n$ update-grub\n$ sync\n$ exit\n{% endcodeblock %}\n\nheader版本依照錯誤訊息顯示哪個版本not found，重新安裝該版本就行了，指令執行完畢重新開機即可。\n\n參考 :\n- [Rescue your system: error: hook … Invalid value Path](https://forum.manjaro.org/t/howto-rescue-your-system-error-hook-invalid-value-path/123226)\n- [error: file ‘/boot/vmlinux-4.19-x86_64’ not found](https://forum.manjaro.org/t/error-file-boot-vmlinux-4-19-x86-64-not-found/123303)","tags":["error","linux","manjaro"],"categories":["Linux"]},{"title":"Manjaro KDE 安裝＆個人化","url":"/linux-manjaro-install-and-optimization/","content":"前陣子組了一台新主機，安裝了Manjaro Linux。\n<!--more-->\n\b其實是為了NVIDIA GPU的運算力，礙於窮學生經費有限僅能擠出20K左右的預算，取捨後實際花費為18K。\n\n- AMD AM4 Ryzen 5 2400G\n- ASUS PRIME A320M-K\n- Crucial 16GB DDR4-3200 Ballistix SportLT\n- WD Blue 250GB(M.2 SATA 3D TLC)\n- Power Master N9 RGB/ATX\n- Antec NX650\n- Zotec GTX1660 SUPER Twin Fan 6G(T16620F-10L)\n\n![](https://i.imgur.com/E7LsmEN.jpg)\n![](https://i.imgur.com/9waIGr8.jpg)\n\n### About Manjaro\n目前實際接觸過的Linux版本也就Ubuntu跟Raspberry Pi的Raspbian，本來也是預計要裝Ubuntu，但無意間看到Manjaro的相關文章，決定安裝KDE桌面環境版本，內建的下拉式terminal真香😋\n\nManjaro是基於Arch的Linux發行版(這意味著許多問題都能在[Arch Wiki](https://wiki.archlinux.org)找到答案)，初始版本發行日期為2011年7月10日，目標為使強大的Arch Linux能被人們更容易地使用，硬體檢測與核心切換是Manjaro相當突出的特色。[官方](https://manjaro.org/download/)支援桌面環境有XFCE、KDE Plasma、GNOME，另外社群也支援了其他桌面環境，例如MATE、LXDE等。Manjaro雖然和Arch同樣採用滾動更新，但[根據Manjaro官方所述](https://manjaro.org/features/fresh-and-stable/)，為避免滾動更新可能引發的相容性問題或錯誤，Manjaro有3個軟體庫:Stable、Testing、Unstable，Arch的滾動更新在經過Manjaro官方測試後才會正式發佈給Manjaro的使用者，所以Manjaro的滾動更新相對於Arch會有一定的延遲。至於安全性相關的更新則採用「快速追蹤」的做法，其有較高的優先測試等級，甚至是略過測試，以便盡快修復安全性問題。(↓官網圖片)\n![](https://manjaro.org/img/features/repositories.png)\n\n社群資源 :\b\b\b\b\n- [Manjaro Forum](https://forum.manjaro.org)\n- [Manjaro Wiki](https://wiki.manjaro.org/) / [Manjaro Wiki(繁中)](https://wiki.archlinux.org/index.php/Main_page_(正體中文) )\n- [Manjaro＠中文](https://manjaro-zh.blogspot.com/p/blog-page_7.html)\n\n＊Wiki頁面亦有列出官方推特、臉書與Reddit討論版的連結。另外，官方論壇雖然也有(簡體)中文討論區，但目前活躍程度跟Manjaro＠中文(繁體)討論區差不多...主要還是英文討論區較為活躍。\n\n### Install\nISO載點 : [官網](https://manjaro.org/download/)、[OSDN(含社群版本)](https://osdn.net/projects/manjaro/storage/)\n接下來就是找支閒置的4GB+ USB來製作開機隨身碟，燒錄工具推薦[BalenaEtcher](https://www.balena.io/etcher/)。完成後就使用這支隨身碟來開機，Manjaro啟動選項的驅動設定建議選擇non-free，進入桌面環境後啟動安裝程式~~然後就是下一步下一步下一步~~。\n![](https://i.imgur.com/BdZpaEz.png)\n\nManjaro的安裝就跟M$的作業系統一樣簡單沒啥好說😁\n\n### Setting\n\n核心切換\n![](https://i.imgur.com/VP0nbJW.png)\nMHWD - Manjaro Hardware Detection\n![](https://i.imgur.com/890z6MZ.png)\n\n#### Network\n\n↓DSL就是設定一般家用有線網路，例如CHT ADSL。\n![](https://i.imgur.com/i3sv4Dh.png)\n\n#### WiFi\n這部分有點折騰🤪，原本買了某知名A牌廠商的USB網卡，外盒寫了支援WIN、MAC、LINUX，而Manjaro早就內建該網卡的WiFi晶片驅動了...但無論是內建或是AUR下載來的，怎麼搞就是抓不到，我耗了好幾個晚上的時間在爬文跟測試，最後還在Manjaro Forum發問仍是沒有解決，於是我決定棄用(狀態顯示為很混怒)。\n\n查了一下直接買來TP-Link TL-WN722N，我他X什麼設定都沒搞！什麼驅動都沒裝！一插就爽！！！\n![](https://i.imgur.com/hp7z3aA.jpg)\n\n#### Chinese IME(Input Method Editor)\n中文輸入法安裝參考 : [Manjaro@中文](https://manjaro-zh.blogspot.com/2015/05/manjaro-linux-gcin.html)\n安裝gcin\n{% codeblock lang:bash %}\n$ sudo pacman -S gcin\n{% endcodeblock %}\n\n編輯.xprofile\n{% codeblock lang:bash %}\n$ kate ~/.xprofile\n{% endcodeblock %}\n寫入以下設定 :\n{% codeblock lang:bash %}\nexport GTK_IM_MODULE=gcin\nexport QT_IM_MODULE=gcin\nexport LC_CTYPE=zh_TW.UTF-8\nexport XMODIFIERS=\"@im=gcin\"\ngcin &\n{% endcodeblock %}\n\n打開terminal執行下列指令 :\n{% codeblock lang:bash %}\n$ sudo gtk-query-immodules-2.0 --update-cache\n$ sudo gtk-query-immodules-3.0 --update-cache\n{% endcodeblock %}\n\n然後重新登入即可使用。\n\n#### Google Chrome / Chromium\n{% codeblock lang:bash %}\n$ sudo pacman -S chromium\n$ sudo pacman -S google-chrome\n{% endcodeblock %}\n\n#### VS Code\n{% codeblock lang:bash %}\n$ sudo pacman -S code\n{% endcodeblock %}\n\n### MacOS-like KDE\n\n全域主題 : Glassy\n圖示 : McMojave-circle-dark\n游標 : McMojave-circle-dark \n安裝 Latte Dock桌面元件 :\n{% codeblock lang:bash %}\n$ sudo pacman -S latte-dock\n{% endcodeblock %}\n\n↓看起來跟Mac OS桌面環境有87%像🤣🤣🤣\n![](https://i.imgur.com/5xQmNUU.png)\n![](https://i.imgur.com/8jMN6Zb.png)\n![](https://i.imgur.com/W5KyxXn.png)\n![](https://i.imgur.com/EvXxv3m.png)\n\n虛擬桌面切換 :\n![](https://i.imgur.com/F2H0OyB.gif)\n\n### Update\n查詢Pacman Mirror來源\n{% codeblock lang:bash %}\n$ pacman-mirrors -l\n{% endcodeblock %}\n\n變更Mirror來源為Taiwan\n{% codeblock lang:bash %}\n$ sudo pacman-mirrors -t 5 -c Taiwan\n{% endcodeblock %}\n\n同步軟體庫＆更新\n{% codeblock lang:bash %}\n$ sudo pacman -Syyu\n{% endcodeblock %}\n\n![](https://i.imgur.com/yHCOIyM.png)\n\n### Error\n原則上會在此條目持續紀錄自己使用Manjaro Linux所遇到的問題，特別是系統更新後\bOrz\n<br>\n\n#### Mojibake(Garbled Text)\n系統更新後若發生中文亂碼的情況，則需安裝字體並重新登入：\n{% codeblock lang:bash %}\n$ sudo pacman -S noto-fonts-cjk\n{% endcodeblock %}\n\n我所安裝的Noto Fonts為Google的開源字型，[Arch Wiki](https://tinyurl.com/uhwvs4w)亦有其他推薦的中文字體可選擇。\n\n#### Dolphin Launch Error\n系統更新後於啟動Dolphin時無法正常顯示檔案，並顯示錯誤訊息：\nUnable to create io-slave. klauncher said: Error loading '/usr/lib/qt/plugins/kf5/kio/file.so'\n\n在[Manjaro Forum](https://forum.manjaro.org/t/unable-to-create-io-slave-klauncher-said-error-loading-usr-lib-qt-plugins-kf5-kio-file-so/25866)找到問題的發生原因是Qt版本衝突導致的，因為系統當下仍載入舊版本Qt，然後我們執行了系統更新。\n\n將電腦重新啟動，或在terminal執行以下命令重新啟動Dolphin即可：\n{% codeblock lang:bash %}\n$ dbus-launch dolphin\n{% endcodeblock %}","tags":["linux","manjaro","kde"],"categories":["Linux"]},{"title":"Python批次加密PDF文件","url":"/python-pdf-batch-encrypt/","content":"又好一段時間沒更新了(忙，然後就2020年了...紀錄一下前陣子寫了段程式碼幫人處理批次加密PDF。\n<!--more-->\n\n### Description\n事實上這需求與薪資系統有關，我只知道那系統似乎很瞎，但人工處理這種大量重複性的問題更瞎🙄\n於是我們會有無數個PDF文件和一個txt文件，PDF內容是個人機密😎，而txt裡頭則是對照表，當程式讀進路徑下所有PDF文件後，會依照PDF檔名去對照每個人的ID Number，以作為PDF文件加密的密碼，然後使用PyPDF2這個模組來進行加密。需注意讀取跟寫入的檔名不能相同，因為加密完會遇到檔案已存在而無法回寫的情況，只好在讀檔之前一律先把檔名改為\"tmp.pdf\"，讀進來加密完再另存回原檔名，然後刪除\"tmp.pdf\"，如此完成一個PDF文件的加密。\n\n\b＊PDF檔名即為code，而txt檔裡頭的對照表有兩個欄位：code | id_number\n\n\n### Code\n{% codeblock lang:python %}\n# *** coding:utf-8 ***\nimport os, glob\nfrom PyPDF2 import PdfFileReader as pdfReader\nfrom PyPDF2 import PdfFileWriter as pdfWriter\n\n\ndef find_id_by_code(code, table):\n    pswd = \"123456\"  # default password\n    for i in table:\n        if code in i:\n            pswd = str(i).split()[1]\n            print(code, \"-->\", pswd)\n    \n    return pswd\n\nid = open(\"ID.txt\")\nID_table = list(id)\nid.close()\n\npdf_files = glob.glob(r\"*.pdf\")\nfor path in pdf_files:\n    code = path.replace(\".pdf\", \"\")\n    os.rename(path, \"tmp.pdf\")\n    in_file = open(\"tmp.pdf\", \"r+b\")\n    in_pdf = pdfReader(in_file)\n\n    out_pdf = pdfWriter()\n    out_pdf.appendPagesFromReader(in_pdf)\n    pswd = find_id_by_code(code, ID_table)\n    out_pdf.encrypt(pswd)\n\n    out_file = open(path, \"wb\")\n    out_pdf.write(out_file)\n\n    in_file.close()\n    out_file.close()\n    os.remove(\"tmp.pdf\")\n\ndel in_pdf, out_pdf\ninput(\"Encrypt Complete! Now you can close the window.\")\n{% endcodeblock %}\n","tags":["python","mytoolbox","pdf"],"categories":["Python"]},{"title":"大眾運輸x穿戴裝置x感應進站","url":"/apple-watch-with-ipass/","content":"自從改用icash 2.0搭台鐵以來，在感應進站的時候，明顯感覺icash 2.0需要大約2秒的感應時間😒 於是我想到並馬上設定了line pay一卡通，但想要做到「感應進站」這件事，似乎沒有這麼順利...<!--more-->當我仔細研究了line pay的「[乘車碼](https://www.i-pass.com.tw/IPS/Event/LINEPay-iPASS/an006.html)」功能，才知道\b\b目前僅有高雄捷運、高雄客運橘12以及東南客運橘20能用啊😬 另外，高雄捷運已經和Mastercard合作啦，所以是可以搭配Apple Pay或其他電子支付來感應進站的。\n\n花了點時間做資訊收集，總之，要用我手上的iPhone逼～進台鐵或搭公車目前還是做不到的(台鐵目前只允許台鐵E訂通產生的對號座QR碼讀取進站)。看來，只能透過「物理」的方式來達成我的需求了，目標是讓隨身物品附加上電子票證的功能，例如手錶。\n\n立馬找了網拍賣家，買來一卡通貼片，將錶帶用酒精清潔乾淨後，仔細地貼上。\n\n![](https://i.imgur.com/ZyhdWvs.png)\n![](https://i.imgur.com/A2ujMAY.png)\n![](https://i.imgur.com/jtjIOaj.png)\n\n\b之所以會選擇一卡通，是打算綁定到line pay一卡通帳戶上來使用其自動加值的功能。首先，到手機上的line pay頁面，點選設定-->連結一卡通-->輸入卡號，設定完成後，因為一卡通尚未完成記名設定，因此line pay會提示使用者要到全家FamiPort完成卡片更新。\n\n![](https://i.imgur.com/GoVhvle.png)\n![](https://i.imgur.com/joqo0wD.png)\n![](https://i.imgur.com/OytTTZS.png)\n\n\b\b不過...[自動加值](https://www.i-pass.com.tw/IPS/Event/LINEPay-iPASS/an009.html)只適用於一卡通的特約商店，不包含7-ELEVEN、台鐵、高鐵、公車、捷運等🙄 算了，反正我還是帶著Apple Watch到超商完成加值並開始使用了。\n\n---\n\n使用電子票證貼片來搭乘台鐵約一週後，我認為它是仍有改善空間的解決方案 :\n- 貼片的邊緣部分會沾黏灰塵而逐漸減弱黏性，黏貼的方式或許比較適合封閉的環境，例如前陣子爆紅的寶貝球悠遊卡或其他吊飾的內部\n- \b台鐵自動驗票閘門的感應區域在右側，但手錶配戴之慣用手則是因人而異，以我配戴於左手為例，感應進站需要稍微蹲低並轉動手腕才能順利感應...\n\n因為受不了貼片黏膠，就把貼片給撕下來了，錶帶整個黏呼呼的，還得用橡皮擦把殘膠嚕個乾淨。有了貼片的使用經驗，目前順利使用中的是網路賣家客製的電子票證手機貼片，但我可沒想再黏貼於任何地方了，就讓它在手機和保護殼之間的夾縫中生存吧，這樣一來無論是換手機還是換保護殼都很方便，搭乘台鐵就直接拿出手機來感應吧","tags":["apple watch","ipass","e-payment"],"categories":["Daily"]},{"title":"動手更換老舊的電源插座","url":"/replace-electrical-socket/","content":"\b\b\b突然想起很久、很久以前，似乎在五金賣場買了兩個插座要來更換，但買回來後就一直擱著...然後就忘了這件事😅<!--more-->雖然插座不知道為什麼某天就突然插不緊了，我一開始還以為是裡頭的簧片變形之類的，\b不過就一直忘了換，儘管插頭插上去不是很穩固，但也還算得上堪用。\n\n＊<span style=\"color:red;\">安全至上，插座是有電的，更換前務必切掉總開關。</span>\n\n但我終於想起來啦，趕緊把兩個放到長灰塵的新插座挖出來，開始拆掉舊的插座，卸下蓋板、轉開兩顆固定螺絲...草泥馬呀！😱我想說怎麼看起來怪怪的，原來是插座本體的塑膠外殼竟然劣化斷掉了，所以才會直接看到裡頭的簧片...我以為只是簧片變形 ＝＝\n![](https://i.imgur.com/VVpK0Au.png)\n\n接著用一字起子往電線旁紅圈處的卡榫插進去，就可以把電線給卸除了，不過我手邊沒有一字起子，所以用之前魚缸用的不鏽鋼長夾代替XD 如果怕忘了怎麼裝(或原本裝設的人裝反了)，卸除電線之前可以先拍照紀錄，通常紅色的為火線(有電)、白色的為水線(無電)，如果是三孔插座的話還會有綠色的接地線。\n\n話說這插座還真是裂得誇張...\n![](https://i.imgur.com/wID59J9.png)\n\n\b電線都卸除後就可以安裝新的插座啦，電線安裝的孔位旁邊會有圖示，較短的橫槓表示為火線安裝處，較長的橫槓則為水線，或有標示一個大寫英文字母W的字樣，中間則是接地線，務必確認電線有插到底不會鬆脫。而我當初買的是兩孔插座並沒有接地的設計，所以兩條接地線稍微整個線收好，就可以把插座面板鎖回去啦。\n\b\b\b![](https://i.imgur.com/hqiXjor.png)\n\n打開電源總開關測試一下插座是否安裝正確，裝上插座蓋板，完成～😎\n![](https://i.imgur.com/uLTa5wO.png)","tags":["DIY","plug socket"],"categories":["Daily"]},{"title":"南科自造基地研習Part 2","url":"/maker-space-workshop-part-2/","content":"人工智慧―自然語言處理與聊天機器人開發。\n<!--more-->\nPart 2於8/26 ~ 8/27在成大系統系館進行，講師為A.P. Wen-Hsiang Lu。\n\n### 研習內容大綱\n<br>\n- 自然語言處理(NLP)技術和應用簡介\n- 自然語言處理工具練習\n- 命名實體識別(NER)語意分析練習\n- 聊天機器人(ChatBot)實作練習\n---\n\n### 筆記\n<br>\n- NLP的最終目標—自動化的語言理解/處理/分析/推理\n- NLP的重要性—使人機互動能做到真正的「溝通」\n- 語言句法結構\n    - 例1：日文為SOV結構(動詞在句尾)\n    - 例2：原民語為VSO結構(動詞在句首)\n- 語言學相關知識類型\n    - 聲學知識(音譯)\n    - 詞彙學知識(字根)\n    - 詞性知識\n    - 文法知識\n    - 語意學知識\n    - 實用知識：情境如何影響句子的解釋\n    - 世界知識：\b\b\b我的理解是common sense，例如「I read an article about ＯＯＯ in the paper.」，我們會「直覺」地認為句子中的paper指的是「論文」。\n- NLP相關技術\n    - 概率與資訊理論\n    - 語言學知識\n    - 字彙/詞庫/語料庫/片語/詞義辨識\n    - Ｎ-gram語言建模／隱性馬可夫模型\n    - 詞性標記\n    - 文法解析\n    - 深度學習\n    - 計算語言學\n        - 語言描述：普遍性與跨語言研究\n        - 計算模型的實現\n            - 演算法與資料結構\n            - 知識表徵模型\n            - 推理過程模型\n    - 心理語言學\n        - 人類為語言理解可計算性的存在證明\n        - 心理學研究可以被用來解釋計算模型\n- NLP技術問題\n    - 龐大的字彙量/無數的現象與規則\n    - 不規則變化(例外、例外中的例外...)\n    - 字彙/情境/文法中的歧義\n    - 網路時代的多語言問題\n        - 語言障礙(人類語言據估算約有5000到7000種)\n        - 資訊過載\n- NLP相關應用\n    - 機器翻譯\n    - 自動語音識別\n    - (跨語言)資訊檢索\n    - (跨語言)問題回答\n    - 文本摘要\n    - 資訊抽取\n    - 對話系統/聊天機器人\n- NLP基本機率模型\n    - N-gram Language Model\n    - Hidden Markov Model(HMM)\n- NLP深度學習模型\n    - 模型發展：訓練結果的詞向量由非上下文相關 --> 上下文相關(詞彙於不同句子中有各自的向量表示)\n    - Word2Vec\n        - CBOW(Continuous Bag of Words)：利用周圍的詞預測中心的詞\n        - Skip-gram：利用中心的詞預測周圍的詞，訓練時間久、結果較CBOW準確\n    - RNN(Recurrent Neural Network)\n    - LSTM(Long Short-Term Memory)\n    - Seq2Seq(Sequence to Seqence)\n    - Seq2Seq with Attention\n- 命名實體識別(NER)\n    - 擷取文字資料中的人名、地名、組織名等目標實體進行分析、標記\n    - 模型構建\n        - Rule-based:\n            - Pos Tagging Pattern + statistic\n            - Dictionary-based\n        - Traditional ML-based:\n            - Hidden Markov Model(HMM)\n            - CRF(Conditional Random Field) + template\n        - DL-based:\n            - LSTM(Long Short-Term Memory)\n            - LSTM with Attention\n    - Viterbi Algorithm(維特比演算法)\n        - 動態規劃演算法\n        - 在語音辨識中，聲音訊號做為觀察到的事件序列，而文字字串被視為隱含產生聲音訊號的原因，因此可對聲音訊號應用維特比演算法尋找出最有可能的文字字串。\n    - CRF++：條件隨機域詞性標記工具\n- 線上工具\n    - [中研院E-HowNet繁體知網系統](http://ehownet.iis.sinica.edu.tw/index.php)\n    - [中研院CKIP中文斷詞系統](http://ckipsvr.iis.sinica.edu.tw)\n    - [中研院CKIP中文剖析器線上測試版](http://parser.iis.sinica.edu.tw)\n    - [Stanford Parser](http://nlp.stanford.edu:8080/parser/)\n\n### 實作練習\n\b\n#### 中文斷詞工具\n此工具使用了教育部國語辭典(16萬詞)來協助斷詞比對，練習用Python實作一個中文斷詞工具，大致上的概念為「先斷句，再斷詞」。\n\n程式範例：先用正則式比對各種標點符號進行斷句後，再逐句來處理斷詞。斷詞的部分，則是由左至右循序比對、抽取出句子中最長的詞，然後再比對剩下的句子...透過重複前述步驟來拆解句子。\n\b\b\b\b{% codeblock lang:py %}\n#!usr/bin/env python3\n# coding:utf-8\nimport re\nbook = {}\nresult = \"\"\n\n\ndef segment(sentences):\n    lines = re.split(r'[，。；：！？／（）「」『』【】]', sentences)\n    end = len(lines) - 1\n    if lines[end] == '':\n        del lines[end]\n    return lines\n\n\ndef compare(txt):\n    end = len(txt)\n    res = \"\"\n    while end != 0:\n        if txt[0:end] in book:\n            res = txt[0:end]\n            break\n        end -= 1\n    res = res if res != \"\" else txt\n    return res\n\n\ndef breakSen(txt):\n    global result\n    str_len = len(txt)\n    start = 0\n    end = str_len + 1\n    while start < str_len:\n        _slice = txt[start:end]\n        word = compare(_slice)\n        result += word\n        start += len(word)\n        if start != str_len:\n            result += \"/\"\n\n\nwith open('words.txt', 'r', encoding='utf-8') as file:\n    lines = file.read().splitlines()\n    for line in lines:\n        book[line] = line\ntxt = \"長頸鹿屬是一屬生長在非洲的反芻偶蹄動物，共有四個物種，是現存世界上最高的陸生動物。一般雄性個體高達4.8到5.5公尺高，重達900公斤。雌性個體一般要小一些。\"\nprint(\"\\ntxt : \\n\\n\", txt, \"\\n\")\nsentences = segment(txt)\nprint(\"segment : \\n\\n\", sentences, \"\\n\")\nfor s in sentences:\n    breakSen(s)\n    if s != sentences[len(sentences) - 1]:\n        result += \"/\"\nprint(\"result : \\n\\n\" + result, \"\\n\")\n{% endcodeblock %}\n\n![](https://i.imgur.com/1DFMiqJ.png)\n\n#### 聊天機器人\n使用Google Dialogflow負責NLP，並與Line Channel串接為可自動回應的Chatbot。網路上[基礎教學](https://www.appcoda.com.tw/chatbot-dialogflow-ios/)很多，因此設定過程省略，基本上就是建立一個Agent來負責處理回應的接收和傳送，在Agent底下可以建立Intents以及Entities來設定對話流程、關鍵字。\n\n![](https://i.imgur.com/NNhEuJO.png)\n![](https://i.imgur.com/WWiDs8E.png)\n![](https://i.imgur.com/Aqqcwxy.png)\n\n---\n\n### 心得\n<br>\n透過盧老師的詳細講解，讓大家了解到自然語言處理(NLP)所涉及包含社會科學等各方面的技術知識，以及在NLP領域還有許多難題尚待解決，如果少了NLP相關技術的話，未來的人機互動將會缺少相當重要的一塊，而人類的語言是如此多元、複雜，絕非單純把數據無腦地丟進深度學習模型就能解決(自從Google DeepMind讓阿發狗秀了一波騷操作後，人們聽到AI深度學習什麼的就像聽到傳說中的~~EX咖哩棒~~Excalibur呀😂)。\b\n\n經過Part 2的研習，對於NLP中所謂的「斷詞」總算是有較完整的概念了，雖然自己在工作上有寫過Line與Web聊天機器人，但我自己明白那有多粗糙，就只是抓取關鍵字做出相對的回應罷了，一點兒都不智慧😕雖然使用者還是會很認真和機器人對話，但看在龜毛的人眼裡是很介意的~~，我絕對不會承認我很介意~~。我想我接下來可以嘗試使用NLP來做點什麼，並從經驗中更進一步理解關於NLP的知識。\n\n感謝A.P. Wen-Hsiang Lu與助教們的用心講解，受益良多。","tags":["NLP","semantic analysis","chatbot"],"categories":["Workshop"]},{"title":"什麼是兒童急性壞死性腦病(ANEC)？","url":"/study-acute-necrotizing-encephalopathy-of-childhood/","content":"前幾天於PTT看到某篇[媽寶版的文章](https://www.ptt.cc/bbs/BabyMother/M.1566400996.A.FC7.html)，才知道如此令人心碎的疾病。<!--more-->作者的孩子(1Y10M)其病況始於突然反覆發燒，於短短幾天內病情便急轉直下、陷入昏迷，神經科醫師診斷可能有腦部損傷，疑似兒童急性壞死性腦病(ANEC)，經緊急安排腦部核磁共振檢查，結果發現視丘及腦幹受損相當嚴重！\b\b\b去年遇到相同狀況的[賴教授與其夫人](https://www.parenting.com.tw/article/5079996)得知此事，便和作者聯繫並給予鼓勵，我也和大家留言鼓勵作者，無論如何都希望奇蹟能出現。\n\n這樣的事令我感到相當震驚與難過，無知的我以為都2019年了，除了那些罕見遺傳性疾病，我們對於大多數的已知疾病應該都有所掌握才對...我這想法真可笑。出於好奇，我在網路上搜尋了關於ANEC的資訊，想知道關於其預防及治療的進展。\n\n---\n### 什麼是兒童急性壞死性腦病(ANEC)？\n\b\b\b吳昌騰醫師今年1月曾於其[臉書貼文](https://zh-tw.facebook.com/TaiwanPerDoctor/posts/268050263890017)說到：\n{% blockquote %}\n兒童急性壞死性腦病(acute necrotizing encephalopathy of children，ANEC)絕對是令兒科急診醫師人人驚心動魄的疾病。ANEC是一種高死亡率的腦病變，主要好發於日本、台灣和韓國。目前為止全世界已經有許多的病例報告。雖然致病機轉尚未完全明瞭，不過目前認為此病與人體的免疫系統和代謝有關。不同病毒皆能引發ANEC，包括A型及B型流感、副流感、帶狀泡疹病毒(水痘)、德國痲疹、HHV-6 及 HHV-8、腸道病毒及柯薩奇病毒 A9；ANEC亦分偶發性或遺傳性，死亡率達70%。ANEC具有病情急、進展快、死亡率高等特點，兒童患者常伴隨嘔吐、快速的意識喪失、不同程度肝功能障礙，預後差，存活者常伴有嚴重的神經系統後遺症。目前ANEC尚缺乏有效的治療方法，治療方法通常為支持療法，如抗生素、抗病毒藥物、IVIG等等治療。\n{% endblockquote %}\n\n＊「預後」: 疾病發生後，對疾病未來發展的病程和結果(痊愈、複發、惡化、致殘、 併發症及死亡等)的預測。\n\n### 疾病管制署致醫界通函第369號\n\b衛福部疾管署曾於今年2/26發佈[醫界通函](https://www.cdc.gov.tw/Bulletin/Detail/RZNFvB_786v_kT6tQ2HTBQ?typeid=48)，呼籲臨床醫師針對流感併發腦炎之病例提高警覺：\n{% blockquote %}\n全國醫界朋友，您好：\n\n國內自2018年10月1日起累計406例流感併發重症病例(以217例感染H1N1、166例感染H3N2為多)，34例死亡(21例H1N1、13例H3N2)，包含4名孩童死亡病例，其中3名孩童未接種本季流感疫苗。此4名死亡孩童皆併發腦炎，其病毒學檢驗結果皆為H1N1，又其發病至出現神經學症狀中位數為1天(範圍0–4天)，且病程快速惡化，雖均使用流感抗病毒藥物治療，仍於發病後2至5天內死亡。\n\n根據國內研究，兒童感染流感後約有1–2%出現腦炎症狀，然而其最嚴重的表現為急性壞死性腦病變(acute necrotizing encephalopathy)，死亡率可高達30-40%。<span style=\"color:red;\">疾管署籲請醫師提高警覺，於流感流行季，對於出現疑似腦炎的神經學症狀，如意識改變、抽搐、局部神經學症狀等個案，應儘速進行流感相關檢驗並使用流感抗病毒藥物</span>；另根據日本少數病例治療經驗，針對未侵犯腦幹之急性壞死性腦病變部分個案，早期使用類固醇可能對個案預後有幫忙，請臨床醫師評估個案狀況審慎使用。\n\n感謝您與我們共同維護全民的健康安全。\n{% endblockquote %}\n\n因為發現疾管署曾發佈此醫界通函，便找了找相關的新聞報導，但我對於ANEC的新聞搜尋結果感到疑惑，只找到幾則於今年2月所發佈關於流感併發腦炎的報導，這才提到兒童急性壞死性腦病這個詞...呵呵。\n\n### 相關文獻\n\n#### Acute necrotising encephalopathy of childhood: a new syndrome presenting with multifocal, symmetric brain lesions\nANEC\b係由[日本國立神經科學研究中心](https://www.ncnp.go.jp/nin/english/department.html)的Mizuguchi等人於1995年發表的[論文](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1073485/)所提出，文件中回顧了13位接受治療的連續患者與28份報告的病例記錄，描述日本兒童中普遍存在著一種未被識別的急性腦病類型之臨床病理學特徵，於呼吸道感染後，原本健康的兒童開始出現<span style=\"color:red;\">昏迷，抽搐，嘔吐，高燒以及肝腫大等症狀</span>。此急性腦病被認為是多發性兒童急性壞死性腦病的新型實體，<span style=\"color:red;\">電腦斷層掃描與核磁共振結果顯示，ANEC\b於視丘、白質、腦幹及小腦造成之腦損傷呈現對稱分佈</span>。\n\n#### Neuropsychological outcomes of childhood acute necrotizing encephalopathy\n此[論文](https://www.sciencedirect.com/science/article/abs/pii/S0387760419301627)描述了3位ANEC患者的神經心理學結果，研究於經歷ANEC後的18個月至10年之間，對患者長期認知與心理的影響。3個病例均表現出<span style=\"color:red;\">注意力不集中、精細動作困難(例如:書寫、下棋)、焦慮，甚至社交障礙</span>。長期損害的嚴重程度與急性症狀表現及恢復期的神經成像有關，這些研究結果強調了詳細的神經心理學評估和長期恢復之必要性。\n\n#### Acute Necrotizing Encephalopathy of Childhood with Novel Influenza A (swH1) Infection : A Case Report\n此病例報告為發表於童綜合醫學雜誌(2018，P.123-P.128)上的[論文](http://zh-tw.sltung.com.tw/uploadfiles/files/20190510_092057_4490.pdf)，病患為4歲8個月的女童，發病前相當健康。其初始症狀為間歇性發燒與嘔吐表現，隨著發生<span style=\"color:red;\">抽搐與快速的意識喪失</span>，以及鼻腔檢體分離出豬流感病毒，腦部神經成像出現典型的兒童急性壞死性腦病特徵。此女童於醫療團隊積極使用Oseltamivir(克流感)，搭配immunoglobulin(免疫球蛋白)和methylprednisolone(類固醇)治療後存活下來。\n\n---\n### 結論\n這幾天看了些相關資訊與近一年內的文獻，除上述所提到的，還有[ANEC患者之臨床特徵](https://jcpsp.pk/archive/2019/Jul2019/13.pdf)、[發展小鼠急性腦病模型以釐清致病機制](https://journals.sagepub.com/doi/abs/10.1177/1535370219846497)以及針對成人ANE患者的相關研究，於前述臨床特徵的研究中甚至發現，抗病毒藥物搭配免疫調節治療並未改變疾病進程。看來，ANEC至今仍是缺乏有效的治療方法，但我相信醫學研究很快就會找到答案的。","tags":["ANEC","influenza"],"categories":["Study"]},{"title":"南科自造基地研習Part 1","url":"/maker-space-workshop-part-1/","content":"\b系統晶片應用―以無線心律檢測為例。\n<!--more-->\nPart 1於8/14 ~ 8/16在成大系統系館進行，講師為Prof. Shuenn-Yuh Lee。\n\n### 研習內容大綱\n<br>\n- 應用於智慧互動照護與監控系統之體外感測網路簡介\n- 應用於身體感測網路之低功率無線心電訊號擷取電路與系統\n    - ZigBee\b\b\b無線心電訊號擷取系統晶片\n    - 身體感測網路之低功率無線心電訊號擷取與分類系統\n- 應用於神經調節之植入式身體感測網路\n- 應用於植入式身體感測網路之低功率雙向遙測裝置結合微型心臟起搏器\n---\n\n### 筆記\n<br>\n- IP-Based vs. Solution-Based\n- 遠距醫療照護服務的潛在市場與預期成長\n- 心肌於心搏週期中之極化、去極化、再極化\n- 心電圖(ECG)之P波、QRS波群和T波之簡易判讀\n- 從實驗室走向產品化所面臨的挑戰\n    - 居家照護系統\n    - 裝置續航力―低功耗設計\n    - 使用便利性―無線傳輸\n    - 訊號解析度對診斷精確度之影響\n    - 診斷結果對醫生與使用者之呈現\n- Wi-Fi/Bluetooth/ZigBee應用於穿戴式裝置無線傳輸之可行性評估\n- 無線生物訊號擷取SoC\b所整合之元件架構介紹\n    - 涉及過多電子學知識，個人認知無法消化...QQ\n- 植入式微型電刺激器之應用\n    - 心臟起搏器\n    - 人工耳蝸\n    - 人工視網膜\n    - 功能性神經肌肉電刺激器\n    - 膀胱控制\n    - 深層腦部電刺激\n\n### 實作練習\n- 使用HSPICE進行電路模擬測試驗證\n\n\b＊HSPICE筆記\n- 以電晶體、二極體、電阻和電容等各種電子元件模型為基礎，經數值模擬分析計算出電路中各結點之電壓、電流\n- 主要提供直流穩態(DC)、暫態(TRAN)以及小信號頻率響應(AC)的模擬，使用者可依照所設計之電路自行編寫模擬分析等控制指令\n- 語法規則\n    - 指令檔(.sp)第一行預設不會執行，使用慣例為撰寫標題用\n    - 英文字母大小寫無區分\n    - \b\b指令執行並無先後順序\n    - 註解符號為 '*'(星號)\n    - 指令檔需以 '.END'宣告結束\n    - 引入元件庫 : .lib 'filepath' TT\n    - 引入子電路 : .include 'filepath'\n    - 將引入元件庫指令放在.protect & .unprotect之間，可於模擬時不顯示元件之製程參數\n    - 宣告變數 : .param param_name = value\n    - 呼叫元件―MOSFET : M11 n1 n2 n3 n4 N_18 W=10u L=1u m=2\n        - M11的M代表MOSFET，11為自定義元件名稱，如同程式語言中的變數名稱\n        - MOSFET為四端元件，因此n1 ~ n4依序代表其D、G、S、B端點所連接的節點\n        - N_18表示呼叫元件庫中名稱為N_18的MOSFET元件\n        - W & L參數為指定MOSFET元件之寬度與通道長度\n        - m = 2代表將兩個Ｍ11元件並聯，此為“抽象上的並聯”，也就是說呼叫這個MOSFET元件時，實際寬度為W x m，當所需的MOSFET寬度超出製程規定區間時，可適當地利用此參數來做調整\n\n元件代號  |對應元件  \n:------:|:------:\nV       |Voltage Source\nI       |Current Source\nR       |Resistor\nL       |Inductor\nC       |Capacitor\nM       |MOSFET\nX       |Sub-Circuit\n\n控制指令 :\n\n指令       |作用  \n:--------:|:--------:\n.AC       |交流分析(頻率響應)\n.DC       |直流分析\n.OP       |靜態點分析\n.NOISE    |雜訊分析\n.TRAN     |暫態分析\n.SUBCKT   |定義子電路\n.ENDS     |子電路定義結束\n.OPTIONS  |設定參數及其他功能\n.PRINT    |指定輸出內容\n.PLOT     |視覺化輸出\n.TEMP     |指定模擬環境溫度\n.END      |指令檔編寫結束\n\n---\n\n### 心得\n<br>\n很幸運能參與自造基地這一系列的研習，關於Part 1的研習內容，雖然資工人沒學過電子學\b(我想我該找本電子學來研讀😅)，De Morgan's laws也不大記得了😂，但知識不嫌多，聽在心裡想在腦子裡，總是有個概念。而李教授除了課程內容，也講了許多受用的觀念，特別是Solution-Based的概念令我相當有感，投入職場至今確實見到台廠普遍沒有系統整合的概念，撇開台積電那樣將晶圓代工做到極致的特例不談，即使我們有先進工業製程能生產各種精密機械與零組件，卻無法發揮其最大價值，因為我們習慣當打工仔，不負責兜出完整的終端產品。\n\n\b\b\b研習課程的最後由李老師所指導的優秀博士生助教帶大家使用HSPICE來模擬電路，雖然我不懂如何完整編寫出模擬電路，但資工人對於電腦語言總是有點Sense😎，理解語法規則後，也是看得懂每一行在做些什麼的，例如元件庫和子電路的概念，就如同程式語言中的函式庫及自訂函式。\n\n感謝Prof. Shuenn-Yuh Lee與助教們的用心講解，受益良多。","tags":["ecg","wireless","hspice"],"categories":["Workshop"]},{"title":"MLP with Keras 手寫數字辨識測試","url":"/data-sci-ml-hello-world-mnist/","content":"## Load MNIST Data Set\n<!--more-->\n載入60000筆訓練數據與10000筆測試數據。\n{% codeblock lang:py %}\n(train_feature, train_label), (test_feature, test_label) = mnist.load_data()\n{% endcodeblock %}\n\n## Data Preprocessing\n<p>\n\n### Reshape\n將28x28特徵值Raw Data(圖片)轉換為32位元浮點數一維數據。\n{% codeblock lang:py %}\ntrain_feature_vector = train_feature.reshape(len(train_feature), 784).astype('float32')\ntest_feature_vector = test_feature.reshape(len(test_feature), 784).astype('float32')\n{% endcodeblock %}\n\n### Feature Normalization\n對特徵值進行正規化處理，也就是將數據按比例縮放至[0, 1]區間，且不改變其原始分佈，以收斂速度與預測精準度。\n{% codeblock lang:py %}\ntrain_feature_normal = train_feature_vector / 255\ntest_feature_normal = test_feature_vector / 255\n{% endcodeblock %}\n\n### One-Hot Encoding\n對離散型資料標籤進行獨熱編碼處理轉換為布林陣列，便於進行矩陣運算。\n{% codeblock lang:py %}\ntrain_label_onehot = np_utils.to_categorical(train_label)\ntest_label_onehot = np_utils.to_categorical(test_label)\n{% endcodeblock %}\n\n## Model Definition\n定義循序模型之結構、訓練方法、準確率評估\n{% codeblock lang:py %}\nmodel = Sequential()\n{% endcodeblock %}\n\n### Layer Definition\n定義輸入層、隱藏層、輸出層 :\n- Units : 784 -> 256 -> 10\n- 常態分佈亂數初始化weight＆bias\n- 隱藏層活化函數使用ReLU\n- 輸出層活化函數使用Softmax\n\n{% codeblock lang:py %}\nmodel.add( Dense(units=256, input_dim=784, init='normal', activation='relu') )\nmodel.add( Dense(units=10, init='normal', activation='softmax') )\n{% endcodeblock %}\n\n### Training Definition\n定義訓練方法 : \n- 損失函數為 CrossEntropy Loss\n- 優化器使用 Adam\n- 驗證數據分割比例為0.2(將6萬筆訓練數據進一步分割為4.8萬筆訓練數據和1.2萬筆驗證數據)\n- 訓練週期(epoch)為10\n- 每批次樣本數為200(因此一個訓練週期為4.8萬/200=240批次)\n\n{% codeblock lang:py %}\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(x=train_feature_normal, y=train_label_onehot, validation_split=0.2, epochs=10, batch_size=200, verbose=2)\n{% endcodeblock %}\n\n### Accuracy Evaluation\n{% codeblock lang:py %}\naccuracy = model.evaluate(test_feature_normal, test_label_onehot)\nprint('\\n[Accuracy] = ', accuracy[1])\n{% endcodeblock %}\n\n### Save & Load Model\n{% codeblock lang:py %}\n# save\nmodel.save(\"mdl_mlp_mnist.h5\")\n# load\nmodel = load_model(\"mdl_mlp_mnist.h5\")\n{% endcodeblock %}\n\n---\n## Full Code\n{% codeblock lang:py %}\n#!/usr/bin/env python3\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.utils import np_utils\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.models import load_model\nnp.random.seed(1234)  # for reproducibility\n\n\ndef showPredict(imgs, lbls, predictions):\n    plt.gcf().set_size_inches(10, 10)\n    for i in range(0, 10):\n        fig = plt.subplot(2, 5, i + 1)\n        fig.imshow(imgs[i], cmap='binary')\n\n        title = 'prediction = ' + str(predictions[i])\n        if predictions[i] != lbls[i]:\n            title += '(X)'\n\n        title += '\\nlabel = ' + str(lbls[i])\n        fig.set_title(title, fontsize=10)\n        fig.set_xticks([])\n        fig.set_yticks([])\n    \n    plt.show()\n\n\ndef mdlTrain(train_feature, train_label, test_feature, test_label):\n    # model definition\n    model = Sequential()\n\n    # input:784, hidden:256, output:10\n    model.add( Dense(units=256, input_dim=784, init='normal', activation='relu') )\n    model.add( Dense(units=10, init='normal', activation='softmax') )\n\n    # training definition\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    model.fit(x=train_feature, y=train_label, validation_split=0.2, epochs=10, batch_size=200, verbose=2)\n\n    # accuracy evaluation\n    accuracy = model.evaluate(test_feature, test_label)\n    print('\\n[Accuracy] = ', accuracy[1])\n\n    return model\n\n\n# load mnist data\n(train_feature, train_label), (test_feature, test_label) = mnist.load_data()\n\n# data preprocessing\n# reshape\ntrain_feature_vector = train_feature.reshape(len(train_feature), 784).astype('float32')\ntest_feature_vector = test_feature.reshape(len(test_feature), 784).astype('float32')\n\n# feature normalization \ntrain_feature_normal = train_feature_vector / 255\ntest_feature_normal = test_feature_vector / 255\n\n# one-hot encoding\ntrain_label_onehot = np_utils.to_categorical(train_label)\ntest_label_onehot = np_utils.to_categorical(test_label)\n\naction = input(\"1: Model Testing\\n2: Model Training\\n\")\nif action == \"1\":\n    print(\"Load mdl_mlp_mnist.h5\")\n    model = load_model(\"mdl_mlp_mnist.h5\")\n    prediction = model.predict_classes(test_feature_normal)\n    showPredict(test_feature, test_label, prediction)\n    del model\nelse:\n    print(\"===== Start training =====\")\n    model = mdlTrain(train_feature_normal, train_label_onehot, test_feature_normal, test_label_onehot)\n    model.save(\"mdl_mlp_mnist.h5\")\n    print(\"===== Model has been saved =====\")\n    prediction = model.predict_classes(test_feature_normal)\n    showPredict(test_feature, test_label, prediction)\n    del model\n{% endcodeblock %}\n\n![IPC8oCO.png](https://i.imgur.com/IPC8oCO.png)\n![qCt4QIA.png](https://i.imgur.com/qCt4QIA.png)\n\n---\n\n## Test Your Own Handwritten Numbers Image\n為了讓訓練好的模型預測看看資料集以外的圖片，我用FireAlpaca\b「手寫」了10張28x28的數字圖片😆，並將圖片命名為「真實數字_圖片順序編碼.jpg」這樣的格式，例如「8_image2.jpg」代表這張圖片為我製作的第2張圖片，內容為數字8，這樣的命名規則是為了方便讀取圖片時能從檔名擷取其label。\n\n### import blob & opencv\n{% codeblock lang:py %}\nfrom glob import glob\nfrom cv2 import cv2 as cv\n{% endcodeblock %}\nP.S. 在VS Code中若只寫「import cv2」的話會報錯...\n\n### data preprocessing\n{% codeblock lang:py %}\ndef get_test_process(files):\n    test_image = []\n    test_label = []\n    for file in files:\n        label = int(file[0:1])  # get label from file name\n        image = cv.imread(file, cv.IMREAD_GRAYSCALE)  # read image as grayscale\n        # retval, dst = cv.threshold(src, thresh, maxval, type[,dst])\n        image = cv.threshold(image, 120, 255, cv.THRESH_BINARY_INV)[1]  # binary invert\n        test_image.append(image)\n        test_label.append(label)\n\n    # list -> numpy.array\n    test_image = np.array(test_image)\n    test_label = np.array(test_label)\n\n    # reshape(flatten) & normalization\n    test_image_normal = test_image.reshape(len(test_image), 784).astype('float32') / 255\n    # one-hot encoding\n    test_label_onehot = np_utils.to_categorical(test_label)\n\n    return (test_image, test_label), (test_image_normal, test_label_onehot)\n{% endcodeblock %}\n\n### Prediction\n{% codeblock lang:py %}\nmodel = load_model(\"mdl_mlp_mnist.h5\")\nprint(\"=== Load mdl_mlp_mnist.h5 ===\")\nfiles = glob('*.jpg')  # find all images (path)\n\n# data preprocessing\n(test_image, test_label), (test_image_normal, test_label_onehot) = get_test_process(files)\n\nprediction = model.predict_classes(test_image_normal)\nshowPredict(test_image, test_label, prediction)\ndel model\n{% endcodeblock %}\n\n### Result\n哎呀，其中一張數字8的圖片預測錯誤😂\n![1eJE60d.png](https://i.imgur.com/1eJE60d.png)\n\n和數據集的圖片比較起來，我的手寫圖片經過影像處理完筆跡變得超細，或許特徵相對不那麼明顯吧，把原圖多點幾個像素上去再預測一次就過了呢。\n![0MsDeaK.png](https://i.imgur.com/0MsDeaK.png)\n\n---\n＊測試程式指定隨機亂數種子是為了[再現性](https://keras.io/zh/getting-started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development)\n\n＊下載MNIST數據集時若發生 [ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed](https://stackoverflow.com/questions/41691327/ssl-sslerror-ssl-certificate-verify-failed-certificate-verify-failed-ssl-c/41692664?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa)，在\b Terminal 執行以下命令 :\n{% codeblock lang:shell %}\n/Applications/Python\\ 3.6/Install\\ Certificates.command\n{% endcodeblock %}\n\n📄[Keras中文說明文件](https://keras.io/zh/)","tags":["keras","mnist","deep learning","computer vision"],"categories":["Data Science"]},{"title":"使用 Selenium 模組控制瀏覽器","url":"/data-sci-use-selenium-with-chrome-driver/","content":"自從開發環境轉移到 Mac OS 後，倒是沒有在這環境下測試用 Selenium 去控制瀏覽器，不過我並不想控制 Safari ，因為它不是一個跨平台的瀏覽器。\n<!--more-->\n第一次使用 Selenium 是學習 Web Crawler 的過程中發現，在瀏覽器中可見的物件並不代表一定爬得到(初心者😗)，於是我了解到那些自己抓不到的數據是由 JavaScript 所動態產生的，因為我向目標伺服器所發出的 request 只能取得靜態的數據，若要進行進階的動態網頁資料擷取，那麼我就必須學習如何用程式碼去控制瀏覽器。\n\n---\n## Install Selenium\n{% codeblock lang:bash %}\n$ pip3 install selenium\n{% endcodeblock %}\n\n## Download Chrome Driver\n要讓 Selenium 能夠控制 Chrome 瀏覽器，需要<span style=\"color:red;\">對應版本</span>的 [ChromeDriver](https://chromedriver.storage.googleapis.com/index.html)，例如我的 Chrome 為目前的最新版本 76.0.3809.100，那麼我就下載 ver.76 最新的 76.0.3809.68 版本 ChromeDriver，然後把 ChromeDriver 放在適當的路徑下，以便在程式中呼叫。\n\n## Test\n{% codeblock lang:py %}\n#!/usr/bin/env python3\n# coding:utf-8\n\nimport time\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\n\n\ndef getChrome(show=False):  # return chrome handler\n    WINDOW_SIZE = \"1366, 768\"  # screen size\n    CHROMEDRIVER_PATH = r\"/Users/nick/Downloads/chromedriver\"\n\n    options = Options()  # config\n    options.add_argument(\"log-level=3\")  # shut the logging\n    options.add_argument(\"--window-size=%s\" % WINDOW_SIZE)\n    if not show: options.add_argument(\"--headless\")  # headless mode\n\n    return webdriver.Chrome(CHROMEDRIVER_PATH, chrome_options=options)\n\n\nchrome = getChrome()\nchrome.get(\"https://laplacetw.github.io/categories/\")\ntime.sleep(1)\nchrome.save_screenshot(\"screenshot.png\")\nchrome.quit()\n{% endcodeblock %}\n\n測試程式若順利執行的話，在檔案目錄下應該會發現多了個執行畫面的截圖 :\n![5qmRipW.png](https://i.imgur.com/5qmRipW.png)\n\ngetChrome()預設會用 headless 模式啟動 Chrome，若想顯示使用者介面的話可以將 \"show\" 這個參數設為 True，如此便能看到自動化執行 Chrome 的過程。但實際應用的情況下非必要就別啟動圖形介面了，執行速度會快很多的😎","tags":["python","web crawler","selenium","chromedriver"],"categories":["Data Science"]},{"title":"關於 SharePoint REST API","url":"/sharepoint-rest-api/","content":"這是一段關於沒有伺服器權限的開發者\b於 SharePoint 進行網站開發的恐怖故事。\n<!--more-->\n這段故事實在是太可怕了，伺服器權限在資訊單位手裡，而完全不懂 SharePoint 也不會 .NET 的我只有使用者權限帳號(黑人問號.jpg)，看著一點幫助都沒有的 training kit 文件，我必須想辦法把它寫成一個入口網站...\n\n經過摸索研究最終想出了解決方法，我自製母版定義了導航列與頁腳，並利用內容編輯器這個 Web Part 在每個頁面「填入」我要的 HTML 內容，但不得不放棄內建的其他 Web Part，因為我根本無法完全控制那些頑固的東西，它們讓整個頁面佈局看起來相當糟糕!!!\n\n但如此我便擁有整個頁面內容的控制權了，前端頁面佈局樣式就交給 Bootstrap 去搞定啦，而後端就只能依賴 SharePoint REST API 去處理 CRUD。\n\n雖然很荒謬但我還是硬著頭皮上了，最後寫了個多功能的 SharePoint 企業內網 :\n\n- 公告\n- 行事曆(支援批次匯入事件)\n- 會議室預約\n- 工時追蹤填報(支援統計圖表)\n- 出勤狀況發佈(系統通知信)\n- 討論區\n- Smart Chat Bot(答覆公司系統與網站相關問題)\n\n這任務至此告一段落了，紀錄一下 SharePoint REST API 如何使用 : \n\n{% codeblock lang:js %}\nvar api_create = \"https://server/site/_api/web/lists('{ your_list_guid }')/items\",\n    api_read = \"https://server/site/_api/web/lists('{ your_list_guid }')/items( { your_list_item_id } )\",\n    api_update = \"https://server/site/_api/web/lists('{ your_list_guid }')/items( { your_list_item_id } )\",\n    api_delete = \"https://server/_api/web/lists('{ your_list_guid }')/items( { your_list_item_id } )\",\n    data ={\n        __metadata: { 'type': 'SP.Data.{ your_list_item_entity_type_fullname }' },\n        { list_column_name } : { value }\n    };\n \nfunction sp_create(api_create){\n    $.ajax({\n        url: api_create,\n        method: \"POST\",\n        data: JSON.stringify(data),\n        contentType: \"application/json; odata=verbose\",\n        headers:{\n            \"Accept\": \"application/json; odata=verbose\",\n            \"X-RequestDigest\": $(\"#__REQUESTDIGEST\").val()\n        },\n        success: function(res){\n            let data = res.d; // the data you create\n            // do something\n        },\n        error: function(error){\n            console.log(JSON.stringify(error));\n        }\n    });\n}\n \nfunction sp_read(api_read){\n    $.ajax({\n        url: api_read,\n        type: \"GET\",\n        headers: {\n            \"accept\":\"application/json; odata=verbose\"\n        },\n        success: function(res){\n            let data = res.d; // the data you read\n            // do something\n        },\n        error: function(error){\n            console.log(JSON.stringify(error));\n        }\n    });\n}\n \nfunction sp_update(api_update){\n    $.ajax({\n        url: api_update,\n        method: \"POST\",\n        data: JSON.stringify(data),\n        contentType: \"application/json; odata=verbose\",\n        headers: {\n            \"Accept\": \"application/json;odata=verbose\",\n            \"X-RequestDigest\": $(\"#__REQUESTDIGEST\").val(),\n            \"IF-MATCH\": \"*\",\n            \"X-Http-Method\": \"MERGE\"\n        },\n        success: function(res){\n            let data = res.d; // the data you update\n            // do something\n        },\n        error: function(error){\n            console.log(JSON.stringify(error));\n        }\n    });\n}\n \nfunction sp_delete(api_delete){\n    $.ajax({\n        url: api,\n        method: 'DELETE',\n        headers: {\n            \"Accept\": \"application/json;odata=verbose\",\n            \"X-RequestDigest\": $(\"#__REQUESTDIGEST\").val(),\n            \"IF-MATCH\": \"*\"\n        },\n        success: function(res){\n            // do something\n        },\n        error: function(error){\n            console.log(JSON.stringify(error));\n        }\n    });\n}\n \n/* filter & select & order(asc / desc)\n\"https://server/_api/web/lists('{ your_list_guid }')/items?$filter={ list_column_name } eq { keyword }&$select=ID,AuthorId,Created,...&$orderby={ list_column_name } desc\"\n*/\n\n{% endcodeblock %}\n\n特別留意 SharePoint REST API 返回的資料筆數預設值是100筆，這在我寫的會議室預約功能所依賴的資料庫筆數超過100之後，因為使用者反應預約完成的會議卻沒有顯示在頁面上而發現。此問題只要在 API 裡頭加上一個 \"TOP\"參數並指定返回的資料筆數即可解決，例如「TOP=5000」，而 API 能返回的最大值為5000筆。如果需要返回更多筆資料，印象中看過網路上相關討論，但我用在查詢會議室預約這樣有時效性的資料，估計5000筆已經綽綽有餘了XDD","tags":["web","sharepoint"],"categories":["SharePoint"]},{"title":"第一次吃樹莓派","url":"/rspi-meet-raspberry-pi-b3-plus/","content":"\b\b\b\b樹莓派3B+初始化安裝。\n<!--more-->\n\n![](https://i.imgur.com/wIdoqQ8.jpg)\n![](https://i.imgur.com/Dec2LcF.jpg)\n\n### \b\bOperation System\n參考了[IT技術家](http://blog.itist.tw/2016/12/34-best-operating-systems-for-raspberry-pi.html)所整理的作業系統清單，我決定直接安裝官方發行的Raspbian OS。\n\n- [Raspbian載點](https://www.raspberrypi.org/downloads/raspbian/)\n- [Raspbian安裝指南](https://www.raspberrypi.org/documentation/installation/installing-images/README.md)\n- [更新Raspbian](https://www.raspberrypi.com.tw/20004/faq-how-to-update-and-upgrade-raspbian/)\n\n由於Raspberry Pi是以SD Card\b\b來當硬碟([官方說明](https://www.raspberrypi.org/documentation/installation/sd-cards.md))，網路上大多建議儲存容量至少8G、寫入速度class 10，加上系統更新考量，於是我準備了一張儲存容量16G、寫入速度class 10的SD Card\b來當系統儲存空間，以及一支隨身碟來當資料儲存空間。不過官方有特別強調，較高的寫入速度並非記憶卡性能的唯一標準，因為寫入速度通常是藉由犧牲讀取速度和尋軌效能而提升的。\n\n>The card class determines the sustained write speed for the card; a class 4 card will be able to write at 4MB/s, whereas a class 10 should be able to attain 10 MB/s. However, it should be noted that this does not mean a class 10 card will outperform a class 4 card for general usage, because often this write speed is achieved at the cost of read speed and increased seek times.\n\nRaspbian鏡像檔目前有3種版本:\n- Raspbian Stretch with desktop and recommended software\n- Raspbian Stretch with desktop\n- Raspbian Stretch Lite\n![](https://i.imgur.com/c8sOf6D.png)\n\nRaspberry Pi安裝作業系統有許多方式，直接刷進去SD Card應該是最簡單的方式，官方推薦[Etcher](https://www.balena.io/etcher/)燒錄工具。\n![](https://i.imgur.com/lr2zQQi.png)\n\n\n### Connect to Wi-Fi Networks\n將作業系統刷進SD Card後，讓電腦重新讀取記憶卡，在根目錄下建立wpa_supplicant.conf，寫入網路連線參數，可寫入多筆。\n\n{% codeblock lang:conf %}\ncountry=TW\nctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev\nupdate_config=1\nnetwork={\n    priority=9\n    ssid=\"{SSID}\"\n    psk=\"{Password}\"\n    key_mgmt=WPA-PSK\n} \n{% endcodeblock %}\nP.S. 優先度Priority數字越大，優先度越高。\n\n### Remote\n<p>\nSSH連線預設為關閉狀態，如同無線網路設定，在根目錄下建立名稱為'ssh'的檔案即可強制啟用SSH連線。\n![](https://i.imgur.com/5X2bahA.png)\n\n我忘了在網路連線設定country參數，所以連線時系統有提醒可以進config設定。\n![](https://i.imgur.com/QI8vFEc.png)\n\n#### 在Raspberry Pi安裝VNC Remote Server\n{% codeblock lang:shell %}\n$ sudo apt-get install tightvncserver -y\n$ vncserver  # run server\n{% endcodeblock %}\n\n首次遠端桌面連線時，系統會要求設置連線密碼。\n{% codeblock lang:shell %}\npi@raspberrypi:~ $ vncserver\nYou will require a password to access your desktops.\n\nPassword: \nWarning: password truncated to the length of 8.\nVerify:   \nWould you like to enter a view-only password (y/n)? n\n\nNew 'X' desktop is raspberrypi:1\n\nCreating default startup script /home/pi/.vnc/xstartup\nStarting applications specified in /home/pi/.vnc/xstartup\nLog file is /home/pi/.vnc/raspberrypi:1.log\n{% endcodeblock %}\n\n#### 在Google Chrome安裝VNC Viewer擴充程式\n*[VNC Viewer for Google Chrome](https://chrome.google.com/webstore/iabmpiboiopbgfabjmgeedhcmjenhbla)\n\b\b\b\b\b\b![](https://i.imgur.com/mKcoeaT.png)\n\n連線Address需指定VNC Server Port，連接阜編碼規則為5900+Display編號。\ne.g. 192.168.0.2:5901\n![](https://i.imgur.com/fnD2RQc.png)\n![](https://i.imgur.com/dYVH37J.png)\n\n\n### Shutdown\n{% codeblock lang:shell %}\n$ sudo shutdown -h now\n{% endcodeblock %}","tags":["IoT","linux","raspberry pi"],"categories":["Raspberry Pi"]},{"title":"QArt Coder:客製化QR Code產生器","url":"/create-qrcode-with-image-by-qart-coder/","content":"~~這是一款真正的~~影像合成QR Code產生器😎<!--more-->\n\n無意間看到[電腦玩物的Esor大](https://www.playpcesor.com/2019/03/qart-coder-qr-code-logo.html)分享一個很特別的[QArt Coder](https://research.swtch.com/qr/draw)，於是我滿心期待地跑去試用，之前用過的QR Code產生器都是很直白地在QR Code正中央呈現一個縮圖，但這個QArt Coder是將影像用點陣圖的方式呈現～跟QR Code漂亮地結合在一起！\n\n這個線上工具介面並不複雜，圖片上傳後微調一下，接著點選Save this QR Code，頁面就會產生3種尺寸的QR Code讓人下載\n![](https://i.imgur.com/Z1UITpy.png)\n\n但下載的時候有點問題，所以我才寫了這篇XD 直接右鍵儲存影像的話，會發現下載了一個.html檔，在新分頁開啟影像或者下載得到的.html檔都是呈現亂碼的狀態(~~黃捷式~~白眼\n![](https://i.imgur.com/MZ0yKBM.png)\n\n只好檢查一下網頁原始碼，什麼在新標籤頁打開還是直接拷貝都是不起作用的，對著這張圖片的網頁元件按下**擷取螢幕快照**，就可以成功下載這些QR Code了，但上述是在Mac OS下的操作，我也挺好奇Win OS是否也有個相同狀況XD\n![](https://i.imgur.com/AN5xk3Q.png)","tags":["qr code"],"categories":["Tools"]},{"title":"Mac Safari網頁檢閱器顯示位置","url":"/mac-safari-show-web-inspector/","content":"這東西竟然困擾我兩天，我只記得在Safari檢視網頁原始碼的時候，意外點了某個按鈕，然後它就變成獨立視窗了、然後它就變成獨立視窗了、然後它就變成獨立視窗了...<!--more-->於是我開始把Safari的選單找了一遍又一遍，然後中文關鍵字搜尋只能告訴你該如何在Safari上面叫出這個網頁檢閱器🙄🙄🙄\n\n最後終於讓我發現，有個國外的老兄在網路上問了[How Do I Make the Web Inspector Appear In the Bottom Half Of My Browser Window?](https://macmost.com/forum/how-do-i-make-the-web-inspector-appear-in-the-bottom-half-of-my-browser-window.html)這樣的問題，我的老天鵝呀，感恩網路！讚嘆網路！\n\n原來我誤觸的按鈕，會讓網頁檢閱器顯示為獨立視窗\n![](https://i.imgur.com/EfnEXsd.png)\n\n按下置於視窗底部的按鈕就回到Safari的底部啦！\n![](https://i.imgur.com/lrdRwJV.png)\n\n因為這按鈕在<span style=\"color:red;\">全螢幕模式下不可見</span>，所以我才一直沒注意到這按鈕(傻眼)","tags":["mac","safari"],"categories":["Mac"]},{"title":"Google App Script ＋ Spread Sheet = 微後端","url":"/google-app-script-and-spreadsheet/","content":"若想以Google表單來做一個簡易的daily time tracking，提交一次表單就是一筆數據，但每天的時間總是會適當地分配，如此就得重複填寫並送出表單...這真是一個不聰明的方法，若自己寫個網頁表單，request又被瀏覽器同源政策擋下來...就試著用App Script來解決這件事吧，我也沒寫過呢。<!--more-->\n\n### Create\n[Google App Script Doc : Web Apps](https://developers.google.com/apps-script/guides/web)\n\n> #### Requirements for web apps <p>\n> A script can be published as a web app if it meets these requirements:\n>\n> -It contains a doGet(e) or doPost(e) function.\n> -The function returns an HTML service HtmlOutput object or a Content service TextOutput object.\n\n首先建立Google雲端試算表和App Script，複製試算表網址“docs.google.com/spreadsheets/d/{Sheet ID}/edit#gid=0\"當中的{Sheet ID}，寫App Script的時候會需要這部分的資訊。\n<p>\n![](https://i.imgur.com/UiGda9u.png)\n\n若找不到App Script，點選連結更多應用程式，過濾Google的應用程式就能看到了，然後就將它連結至個人的雲端硬碟。\n![](https://i.imgur.com/4BsYTfE.png)\n\n建好表格欄位後就可以來寫App Script了\n![](https://i.imgur.com/NUIlhKk.png)\n\n### App Script\n{% codeblock lang:js %}\nfunction doGet(e) {\n  // parameter\n  var params = e.parameter,\n      date = params.Date,\n      name = params.Name,\n      proj = params.Proj,\n      hours = params.Hours,\n      des = params.Des;\n\n  // google sheet\n  var spreadSheet = SpreadsheetApp.openById({Sheet ID}),       # 需要Sheet ID\n      sheet = spreadSheet.getSheets()[0],  // focus on sheet 1\n      lastRow = sheet.getLastRow();\n  \n  // set value <= getRange(row, col)\n  sheet.getRange(lastRow + 1, 1).setValue(date);\n  sheet.getRange(lastRow + 1, 2).setValue(name);\n  sheet.getRange(lastRow + 1, 3).setValue(proj);\n  sheet.getRange(lastRow + 1, 4).setValue(hours);\n  sheet.getRange(lastRow + 1, 5).setValue(des);\n\n  // complete => return true\n  return ContentService.createTextOutput(true);\n}\n{% endcodeblock %}\n\napp script寫好之後，可以另外寫個debug.gs來執行看看\n{% codeblock lang:js %}\nfunction debug() {\n  var status = doGet({\n      \"parameter\": {\n        \"Date\" : \"2019-05-06\",\n        \"Name\" : \"LaplaceTW\",\n        \"Proj\" : \"Proj-19-05-06\",\n        \"Hours\" : \"4\",\n        'Des' :\"Daily Time Tracking\",\n      }\n   });\n  Logger.log(\"Status : %s\" , status);\n} \n{% endcodeblock %}\n\n沒問題的話，就部署為網路應用程式，部署成功後可取得API網址\n![](https://i.imgur.com/f6YkDkO.png)\n\n### Test\n<p>\n用瀏覽器的開發人員模式console發送request測試\n![](https://i.imgur.com/DNfVP7p.png)\n![](https://i.imgur.com/4dbIvcw.png)\n\n### Passing an array into Google App Script ?\n官方文件對參數的解釋是這樣的:\n>e.parameter\t\n>An object of key/value pairs that correspond to the request parameters. Only the first value is returned for parameters that have multiple values.\n>{\"name\": \"alice\", \"n\": \"1\"}\n\n>e.parameters\t\n>An object similar to e.parameter, but with an array of values for each key\n>{\"name\": [\"alice\"], \"n\": [\"1\", \"2\"]}\n\n但實際測試的時候我也遇到如同[Webduino官方教學文](https://tutorials.webduino.io/zh-tw/docs/socket/useful/google-sheet-1.html)所說的，怎麼試就是無法透過e.parameters這個欄位傳遞參數呀！最後我也採用了相同的做法(汗)，直接傳遞字串到App Script裡頭再分割數據。\n{% codeblock lang:js %}\n// doGet(e)\nvar params = e.parameter,\n    data = ['d1', 'd2', 'd3', 'd4', 'd5'],\n    len = data.length,\n    counter = 1.0;\n\nwhile(counter <= len){\n  var index = (counter - 1.0),\n      arr = params[data[index]];\n  if(arr != undefined){\n    arr = arr.split(',');\n    // set value <= getRange(row, col)\n    sheet.getRange(lastRow + counter, 1).setValue(arr[0]);\n    sheet.getRange(lastRow + counter, 2).setValue(arr[1]);\n    sheet.getRange(lastRow + counter, 3).setValue(arr[2]);\n    sheet.getRange(lastRow + counter, 4).setValue(arr[3]);\n    sheet.getRange(lastRow + counter, 5).setValue(arr[4]);\n  }\n  counter ++;\n}\n{% endcodeblock %}\n\n### Lock\n在透過Ajax對App Script發送請求寫入Spread Sheet的測試過程中，原本前端會對User填寫的每筆數據個別送出Ajax請求，雖然過於頻繁並非好的處理方式，但這也才讓我意識到同時間多個寫入請求的衝突及數據覆寫問題，所以後來整合成一次性的Ajax請求，改為在App Script處理、分割數據的方式。但這樣還沒解決衝突問題，偉大的Google當然也有考量到潛在的寫入衝突問題:\n\n> #### [Class Lock](https://developers.google.com/apps-script/reference/lock/)\n>\n> A representation of a mutual-exclusion lock.\n>\n> This class allows scripts to make sure that only one instance of the script is executing a given section of code at a time. This is particularly useful for callbacks and triggers, where a user action may cause changes to a shared resource and you want to ensure that aren't collisions.\n\n藉由鎖定Script的方式，確保每個時刻只會有唯一的讀寫動作，來避免衝突問題。另外，SpreadsheetApp.flush()的使用也需特別留意。\n{% codeblock lang:js %}\n// get a script lock for modifying a shared resource\nvar lock = LockService.getScriptLock();\nlock.waitLock(30000);\n\n// Do Something\n\n// you should call SpreadsheetApp.flush() prior to releasing the lock,\n// to commit all pending changes to the spreadsheet\nSpreadsheetApp.flush();\nlock.releaseLock();\n{% endcodeblock %}\n\n### Version\n這問題耗了我整天的時間在測試...當Script更新並重新部署後，接下來卻發現，Ajax送出的請求一直抓不到參數，每個欄位都是呈現Undefined的狀態，但Debug.gs測試結果卻正常的很!!! 真是見鬼了...折騰半天我從測試結果合理推測部署的Web App所執行的不是最新版本，我在Stack Overflow也有找到相關討論:\n- [POST to Google Apps Script web app does use latest version](https://stackoverflow.com/questions/18131157/)\n- [App script web change version for each deploy](https://stackoverflow.com/questions/49170665/)\n\n建立一個Web App再另外建立App Script把相關邏輯寫成library，然後在Web App去呼叫它，這是一種方式，但我覺得以簡單的應用而言太拐彎抹角了。只要修改並善用debug測試，確認沒問題後再部署為一個新版本，如此外部呼叫就不會有上述的舊版本問題。","tags":["google","spread sheet"],"categories":["Google"]},{"title":"個人化NexT主題","url":"/hexo-next-optimize/","content":"2020/02/27更新。\n<!--more-->\n\b\b＊關於在本機伺服器正常運作，但部署後卻沒有生效的情況，單獨執行\"hexo d\"指令即可，\"hexo d -g\"之類的組合指令會使某些檔案沒有被推送到遠端伺服器上。\n\n---\n## SEO(Search Engine Optimization)\n<p>\n[Google Webmaster tools verification](https://www.google.com/webmasters)\n輸入網址前置字元(部落格網址)，Google提供許多驗證方法，而我選擇的是HTML標記方法，在Hexo根目錄找到/themes/next/layout/_partials/head/head.swig，貼上Google所提供的<meta>標記，部署後按下驗證即可。之後生成sitemap.xml放在根目錄下的public中，並於Google Console中設定提交。\n\n{% codeblock lang:js %}\n<meta name=\"google-site-verification\" content=\"{verification code}\" />\n{% endcodeblock %}\n![](https://i.imgur.com/Z9Kj7x3.png)\n![](https://i.imgur.com/ZQIQDI3.png)\n\n＊讓Hexo於部署時自動生成sitemap：\n在部落格根目錄下安裝sitemap generator\n{% codeblock lang:shell %}\nnpm install hexo-generator-sitemap --save\n{% endcodeblock %}\n接著在部落格根目錄下的_config.yml設定檔中寫入\n{% codeblock lang:yml %}\n# Sitemap\nsitemap:\n    path: sitemap.xml\n{% endcodeblock %}\n\n這樣每次編譯和部署的時候就會自動更新sitemap了。\n\n## Font Awsome Icon\nNexT自帶的版本為v4.7.0，到[官網](https://fontawesome.com/start)找新版本CDN連結，貼在/themes/next/layout/_partials/head/head.swig就能套用更多icon呢。\n![](https://i.imgur.com/bC6ng9U.png)\n\n＊引入新版本後部分icon可能會因為class name改變而無法顯示\n![](https://i.imgur.com/X0Umdjr.png)\n\n### Change Side Bar Icon\n檔案路徑:/themes/next/layout/_macro/sidebar.swig\n修改social icon相關程式碼為:\n{% codeblock lang:js %}\n{ if theme.social_icons.enable }  // ％符號會影響Code Block顯示因此在文章這裡移除\n    { set sidebarIcon = '<i class=\"' + link.split('||')[1] | trim | default('globe') + '\"></i>' }\n{ endif }\n{% endcodeblock %}\n如此在NexT Config就能直接設定Font Awsome的class name:\n{% codeblock lang:yml %}\nsocial:\n  GitHub: https://github.com/username || fab fa-github fa-lg\n  Linkedin: https://www.linkedin.com/ || fab fa-linkedin-in fa-lg\n  Twitter: https://twitter.com/ || fab fa-twitter fa-lg\n  E-Mail: mailto:username@gmail.com || fas fa-envelope fa-lg\n{% endcodeblock %}\n![](https://i.imgur.com/f2Ssx2y.png)\n\n### Change Post Icon\n檔案路徑:themes/next/layout/_macro/post.swig\n{% codeblock lang:js %}\n<span class=\"post-meta-item-icon\">\n    <i class=\"fas fa-calendar-alt\"></i>\n</span>\n\n<span class=\"post-meta-item-icon\">\n    <i class=\"fas fa-folder-open\"></i>\n</span>\n\n<span class=\"post-meta-item-icon\">\n    <i class=\"fas fa-comment-dots\"></i>\n</span>\n{% endcodeblock %}\n\n## Background Style\n檔案路徑:themes/next/source/css/_custom/custom.styl\n\b\b\b參考[Slanceli - 深度美化Hexo(NexT主题)](https://slanceli.top/2019/02/18/深度美化Hexo（NexT主题）/#more)\n\n{% codeblock lang:styl %}\n// Custom styles.\n@media screen and (min-width:1200px){\n    body{\t\n        background-image:url(/images/background.png);\n        background-repeat: no-repeat;\n        background-attachment:fixed;\n        background-position:50% 60%;\n    }\n\n    #footer a{\n        color:#eee;\n    }\n}\n\n// background\n.main-inner{\n    background: #fff;\n    opacity: 0.9;\n}\n\n// menu\n.header-inner{\n    background: #ffffffe8;\n    opacity: 1;\n}\n\n// footer\n.footer{\n    font-size: 14px;\n    color: #fff;\n}\n{% endcodeblock %}\n\n2020/02/27更新：\n調整響應式斷點，讓行動裝置瀏覽也能顯示背景圖片\n{% codeblock lang:styl %}\n@media screen and (min-width:768px){\n    body{\t\n        background-image:url(/images/background.png);\n        background-repeat: no-repeat;\n        background-attachment:fixed;\n        background-position:50% 60%;\n    }\n\n    #footer a{\n        color:#eee;\n    }\n}\n\n@media screen and (min-width:320px) and (max-width:768px){\n    body{\t\n        background-image:url(/images/background_768.png);\n        background-repeat: no-repeat;\n        background-attachment:fixed;\n        background-position:70% 0%;\n    }\n\n    #footer a{\n        color:#eee;\n    }\n}\n{% endcodeblock %}\n\n## Hyper-Link Style\n修改超連結文字樣式：\n{% codeblock lang:css %}\n// hyper-link\n.post-body p a{\n  color: #003D79;\n  border-bottom: none;\n  border-bottom: 1px solid #003D79;\n  &:hover {  // mouse hover\n    color: #0080FF;\n    border-bottom: none;\n    border-bottom: 1px solid #0080FF;\n  }\n}\n{% endcodeblock %}\n\n## Block Style\n使側邊欄與文章區塊邊角變為圓角\n\n檔案路徑:themes/next/source/css/_variables/Gemini.styl\n修改參數如下 : \n{% codeblock lang:css %}\n$border-radius-inner              = 0 0 16px 16px;\n$border-radius                    = 16px;\n{% endcodeblock %}\n\n檔案路徑:themes/next/source/css/_schemes/Gemini/index.styl\n加入CSS :\n{% codeblock lang:css %}\n.sidebar {\n  background-color:transparent;\n}\n{% endcodeblock %}\n![](https://i.imgur.com/MpmS7WU.png)\n\n## Tag Cloud\n雖然NexT有內建標籤雲，因個人喜好故採用[第三方標籤雲](https://github.com/MikeCoder/hexo-tag-cloud)。\n\n## Continue...","tags":["hexo","github pages"],"categories":["Hexo"]},{"title":"Python自動填寫Google表單","url":"/python-auto-fill-out-google-form/","content":"建個Google表單來測試：現任美國總統究竟是州普？卅普？還是川普？\n<!--more-->\n![](https://i.imgur.com/th41Uch.png)\n\n打開瀏覽器的開發人員模式，切換到Network Panel並試著送出一次表單，可見formResponse有相當明顯的數據傳輸。\n![](https://i.imgur.com/7EDofS9.png)\n\n展開查看詳情，在Header的部分可以找到剛才送出表單的資料結構，確定“entry.1216123536”就是所填寫的表單欄位，那麼可以開始寫程式了。\n![](https://i.imgur.com/O02YylJ.png)\n\n\n### url\n<p>\n在Header摘要可見到url的格式為表單網址加上”/formResponse\"，使用縮網址會無法重導向至正確的表單位址。\n\n\n### data\n{% codeblock lang:python %}\npayload = {\n    'entry.1216123536' : '',\n    'fvv' : '0',\n    'draftResponse' : '[]',\n    'pageHistory' : '0',\n    'fbzx' : '9150375950543103543'\n}\n{% endcodeblock %}\n\n### code\n<p>\n為了讓程式的行為看起來不那麼程式(?)，設置隨機填寫欄位值與隨機延遲時間。\n{% codeblock lang:python %}\nimport re\nimport time\nimport random\nimport numpy as np\nimport requests as rq\n\nurl = 'https://docs.google.com/forms/d/e/********************/formResponse'\nparams = ['州普', '卅普', '川普']\npayload = {\n    'entry.1216123536' : '',\n    'fvv' : '0',\n    'draftResponse' : '[]',\n    'pageHistory' : '0',\n    'fbzx' : '9150375950543103543'\n}\n\nnum = 10  # number of executions\nperiod = np.arange(0.5, 5.0, 0.1)\ndelay = 0  # delay of execution\nwhile num > 0:\n    try:\n        payload['entry.1216123536'] = random.choice(params)  # random choice\n        res = rq.post(url, data=payload)\n        res.raise_for_status()\n        if res.status_code == 200 :\n            delay = round(random.choice(period), 2)  # round off to the 2nd decimal place\n            print('Fill Out : ' + payload['entry.1216123536'] + ' delay : ' + str(delay) + ' sec')\n            time.sleep(delay)\n    except rq.HTTPError:\n        print('HTTP Error!')\n    \n    num -= 1\n{% endcodeblock %}\n\n![](https://i.imgur.com/jKfaOP4.png)\n\n↓ 嗯，只有兩個人答對呢(?)\n![](https://i.imgur.com/zodJ6IR.png)","tags":["python","google form"],"categories":["Python"]},{"title":"Hexo on GitHub Pages:Icarus主題","url":"/hexo-theme-icarus/","content":"[NexT](https://theme-next.iissnan.com\")主題實在是太多人用了，看得有點膩，最近看到Icarus主題覺得很Blog(?)，決定來換個主題。\n<!--more-->\n\n## Download\n{% codeblock lang:shell %}\ncd blog\ngit clone https://github.com/ppoffice/hexo-theme-icarus.git themes/icarus\nhexo s  # run on local host\n{% endcodeblock %}\n![](https://i.imgur.com/KaGH5Gm.png)\n\n---\n## Config\n<p>\n參考[官方文件](https://blog.zhangruipeng.me/hexo-theme-icarus/categories/)，主要配置：\n\n### Favicon & Logo\n{% codeblock lang:yml %}\n# Version of the Icarus theme that is currently used\nversion: 2.3.0\n# Path or URL to the website's icon\nfavicon: /images/favicon.svg\n# Path or URL to RSS atom.xml\nrss: \n# Path or URL to the website's logo to be shown on the left of the navigation bar or footer\nlogo: /images/logo.svg\n{% endcodeblock %}\n＊ 推薦兩個SVG線上製作工具：[Image Vectorizer](https://www.vectorizer.io)、[SVG Editor](http://vectorpaint.yaks.co.nz)\n\n### Navbar & Footer\n{% codeblock lang:yml %}\n# Navigation bar link settings\nnavbar:\n    # Navigation bar menu links\n    menu:\n        Home: /\n        Archives: /archives\n        Categories: /categories\n        Tags: /tags\n        # About: /about\n    # Navigation bar links to be shown on the right\n    links:\n        GitHub_LaplaceTW:\n            icon: fab fa-github\n            url: 'https://github.com/laplacetw'\n# Footer section link settings\nfooter:\n    # Links to be shown on the right of the footer section\n    links:\n        CC BY 4.0:\n            icon: fab fa-creative-commons\n            url: 'https://creativecommons.org/licenses/by/4.0/'\n{% endcodeblock %}\n\n### Comment\n<p>\n評論系統使用DISQUS服務\n{% codeblock lang:yml %}\ncomment:\n    # Name of the comment plugin\n    type: disqus\n    enable: true\n    shortname: {disqus shortname}\n    count: true\n    lazyload: false\n{% endcodeblock %}\n\n### Wiget\n{% codeblock lang:yml %}\nwidgets:\n    -\n        # Widget name\n        type: profile\n        # Where should the widget be placed, left or right\n        position: left\n        # Author name to be shown in the profile widget\n        author: LaplaceTW\n        # Title of the author to be shown in the profile widget\n        author_title: learning by doing\n        # Author's current location to be shown in the profile widget\n        location: Taiwan, Earth\n        # Path or URL to the avatar to be shown in the profile widget\n        avatar: \n        # Email address for the Gravatar to be shown in the profile widget\n        gravatar: \n        # Whether to show avatar image rounded or square\n        avatar_rounded: false\n        # Path or URL for the follow button\n        follow_link: 'https://github.com/laplacetw'\n        # Links to be shown on the bottom of the profile widget\n        social_links:\n            Email:\n                icon: far fa-envelope\n                url: ''\n            Github:\n                icon: fab fa-github\n                url: ''\n            Linkedin:\n                icon: fab fa-linkedin\n                url: ''\n            RSS:\n                icon: fas fa-rss\n                url: /atom.xml\n    -\n        # Widget name (文章內容目錄)\n        type: toc\n        # Where should the widget be placed, left or right\n        position: right\n    -\n        # Widget name (友情連結)\n        type: links\n        # Where should the widget be placed, left or right\n        position: left\n        # Links to be shown in the links widget\n        links:\n            Hexo: 'https://hexo.io'\n    -\n        # Widget name (全站分類)\n        type: category\n        # Where should the widget be placed, left or right\n        position: left\n    -\n        # Widget name (最新文章)\n        type: recent_posts\n        # Where should the widget be placed, left or right\n        position: right\n    -\n        # Widget name (時間軸)\n        type: archive\n        # Where should the widget be placed, left or right\n        position: right\n    -\n        # Widget name (標籤雲)\n        type: tagcloud\n        # Where should the widget be placed, left or right\n        position: right\n{% endcodeblock %}\n＊ hyphen 為每個 Wiget 的起始，多一個少一個都會導致Error\n\n### Plugins\n<p>\n啟用不蒜子網站流量統計設定(預設為關閉)\n{% codeblock lang:yml %}\nplugins:\n    # BuSuanZi site/page view counter\n    # https://busuanzi.ibruce.info\n    busuanzi: true\n{% endcodeblock %}\n\n---\n![](https://i.imgur.com/DXsTbdB.png)\n![](https://i.imgur.com/9t5QT9J.png)\n更進一步個人化ICARUS主題的部分，例如調整文章版面配置、文末版權宣告等，網路教學的版本似乎都有點舊了，自己也是搞了很久...我懶得寫了，因為代碼高亮的問題一直無法順利解決，浪費太多時間了。一番折騰後我又換回NEXT...","tags":["hexo","github pages"],"categories":["Hexo"]},{"title":"Hexo on GitHub Pages:不蒜子統計失效","url":"/hexo-error-busuanzi/","content":"今天PO文後發現...所以我說那個文章閱讀次數呢?頁面底部的流量統計也消失了。\n<!--more-->\n推測是.js檔出了什麼問題，先到[不蒜子](https://busuanzi.ibruce.info)的頁面瞧瞧，發現一行小小的紅字，寫著「因七牛強制過期『dn-lbstatics.qbox.me』域名，與客服溝通無果，只能更換域名到『busuanzi.ibruce.info』!」，雖然不知道七牛到底是什麼牛，但可以確定問題來源是域名更換。\n\n## Solution\n<p>\n在NexT資料夾中找到不蒜子的設定檔，路徑為layout/_third-party/analytics/busuanzi-counter.swig\n![](https://i.imgur.com/rpVQnFj.png)\n\n修改.js路徑為:\n{% codeblock lang:html %}\n<script async src=\"https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js\"></script>\n{% endcodeblock %}\n\n\b重新\bdeploy後便會發現統計數字又回來啦。","tags":["hexo","github pages"],"categories":["Hexo"]},{"title":"Excel:公式、圖表與樞紐分析","url":"/excel-func-chart-pivot-table/","content":"常用公式、圖表與樞紐分析之基本操作。\n<!--more-->\n\n# 常用公式\n<br>\n## IF\n- 用法:IF(條件,符合條件,不符合條件)\n- 範例:判斷訂單金額是否大於70(億)\n![](https://i.imgur.com/wQeP7th.png)\n\n## 多重條件判斷\n- 用法:IF(條件,IF(...),不符合條件)\n- 範例:呈上例，進一步做訂單金額分級\n![](https://i.imgur.com/27kZEy2.png)\n\n## SUM\n- 用法:SUM(範圍1,範圍2...)\n- 範例:計算化學品與塑膠/橡膠年度訂單金額加總\n![](https://i.imgur.com/krLlYE2.png)\n\n## MAX\n- 用法:MAX(範圍1,範圍2...)\n- 範例:找出各類別每月訂單金額中最高者\n![](https://i.imgur.com/uDmIaxx.png)\n\n## INT/ROUND\n- 用法:INT(儲存格)/ROUND(儲存格,小數位數)\n- 範例:INT無條件捨去/ROUND四捨五入\n![](https://i.imgur.com/sZLMI11.png)\n\n## AVERAGE\n- 用法:AVERAGE(範圍1,範圍2...)\n- 範例:計算年度平均值之無條件捨去與四捨五入\n![](https://i.imgur.com/F8FyAzn.png)\n\n## SUMIF\n- 用法:SUMIF(條件範圍,條件,合計範圍)\n- 範例:計算各種商品之銷售總額\n![](https://i.imgur.com/xz1FZ5Z.png)\n\n## COUNTIF\n- 用法:COUNTIF(條件範圍,條件)\n- 範例:統計年度化學品訂單金額分級\n![](https://i.imgur.com/V7LXB0g.png)\n\n## VLOOKUP\n- 用法:VLOOKUP(搜尋條件,範圍,目標欄位,精確度)\n- 範例:搜尋指定月份訂單金額\n![](https://i.imgur.com/sa39mn2.png)\n\n## 多條件搜尋\n- 用法:LOOKUP(1,0/((條件1)*(條件2)*...),目標範圍)\n- 範例:尋找訂單金額分級為Ａ級且大於100(億)之月份\n![](https://i.imgur.com/kJxlPKI.png)\n\n## 重點整理\n\n公式     |說明  \n:------:|:------:\nIF      |條件式\nSUM     |加總\nMAX     |最大值\nINT     |無條件捨去\nROUND   |四捨五入\nAVERAGE |平均值\nSUMIF   |有條件加總\nCOUNTIF |有條件統計\nVLOOKUP |尋找      \n\n---\n# 常用圖表\n<br>\n## 錯誤範例\n說明:折線圖所表達的為<span style=\"color:red;\">趨勢、變化</span>，而下圖中\b\b\b\b\b\b水平軸項目為類別，離散型數據不具連續性，這樣的圖表**不具任何意義**，應使用直條圖比較各項目之大小，或使用圓形圖呈現各項目佔整體之比重。\n![](https://i.imgur.com/UswDs8J.png)\n\n## 基本設定\n- 圖表設計與格式設定在圖表工具的頁籤中\n- 圖表項目細部設定在圖表右側的\"＋\"號中\n![](https://i.imgur.com/67Z3T4H.png)\n\n## 直條圖\n- 使用時機:做<span style=\"color:red;\">比較</span>，呈現數據的「相對大小」\n- 範例:100年度化學品外銷月訂單金額比較\n![](https://i.imgur.com/sHPqEjn.png)\n\n## 堆疊直條圖\n- 範例說明:呈現整體營業額與個別業務人員表現，可明顯看出業務A(藍色區塊)與業務C(灰色區塊)的成長與衰退，以及對整體的影響。\n![](https://i.imgur.com/UcZuOEu.png)\n\n## 折線圖\n- 使用時機:讀<span style=\"color:red;\">趨勢</span>，呈現數據的「變化、走勢」\n- 範例:100年度化學品外銷月訂單金額走勢\n![](https://i.imgur.com/FATm3bE.png)\n\n## 圓形圖\n- 使用時機:看<span style=\"color:red;\">比例</span>，呈現數據的「相對比例」\n- 範例:\b100年度外銷訂單項目比重\n![](https://i.imgur.com/TBfdio3.png)\n\n## 重點整理\n\b數據視覺化須依據所欲呈現之數據統計摘要，進而選擇適當的圖表形式，避免<span style=\"color:red;\">誤用圖表、為分析而分析</span>。\n\n- 直條圖:做<span style=\"color:red;\">比較</span>\n- 折線圖:讀<span style=\"color:red;\">趨勢</span>\n- 圓形圖:看<span style=\"color:red;\">比例</span>\n\n---\n# 樞紐分析\n以經濟部101-106年外銷美國訂單統計資料為例。\n\n## Step 1:選取數據範圍\n**數據範圍中不允許空白欄位**\n\n![](https://i.imgur.com/joDfNB9.png)\n\n## 欄位說明\n- 篩選:報表之篩選條件\n- 欄  :樞紐分析表<span style=\"color:red;\">行</span>數據\n- 列  :樞紐分析表<span style=\"color:red;\">列</span>數據\n- 值  :欲統計之數據，例如加總、平均值\n\n![](https://i.imgur.com/UH01LrN.png)\n\n## Step 2:拖曳調整欄位與排列順序\n![](https://i.imgur.com/E8Alrt1.png)\n↓點選值欄位設定可選擇其他計算類型\n![](https://i.imgur.com/tEI1LCA.png)\n\n## Step 3:插入樞紐分析圖\n樞紐分析工具(頁籤) --> 分析 --> 樞紐分析圖\n\n![](https://i.imgur.com/2bgZqAX.png)\n\n## 樞紐分析-堆疊直條圖\n![](https://i.imgur.com/UGRPdUl.png)\n\n## 樞紐分析-圓形圖\n**注意圖表的行列數據呈現是否合適**\n\n![](https://i.imgur.com/B5bdN0S.png)\n↓調整行列數據\n![](https://i.imgur.com/0WAn7Aa.png)\n↓調整後\n![](https://i.imgur.com/itrWKwo.png)","tags":["excel","pivot table"],"categories":["Excel"]},{"title":"Django2.0筆記(3):軟體架構","url":"/django-software-architecture/","content":"模型、視圖與模板。\n<!--more-->\n\n## Model–View–Controller\n- Model: 資料庫存取\n- View:  使用者介面\n- Controller: 控制整合\n\n說到網頁開發，就不得不提一下MVC架構，維基百科如是說：MVC為軟體工程中的一種軟體架構，將軟體系統分為三個部分：模型(Model)、視圖(View)和控制器(Controller)，目的是為了實現一種<span style=\"color:red;\">動態</span>的程式設計，使後續對程式的修改及擴充簡化，並且使程式某一部分的重複利用成為可能。\n\nMVC是一種<span style=\"color:red;\">設計理念</span>而非技術，旨在提高開發項目的可擴展性及可維護性，而這樣一個從實際開發所歸納出來的抽象概念，事實上其定義是相當模糊的，尤其是在經過了多年發展後...\b在Django筆記就不多做探討了。\n\n## Model-Template-View\n- Model: 資料庫存取\n- Template: 使用者介面\n- View:  控制整合\n\nDjango雖然看似獨樹一格自定義了MTV架構，但MTV和MVC的概念是相同的，我嘗試畫了架構對照圖：\n![](https://i.imgur.com/vAeWv7K.png)\n以較為白話的方式來描述MTV架構，就是依開發需求去定義Model在資料庫中生成對應的Table，透過View所定義的程式邏輯去整合、控制數據，再交由負責前端的Template呈現給使用者，而使用者亦是透過Template和後端數據做互動。\n\n我認為Django初學者只是抽象地討論MTV是無法很好地理解其互動關係的，還是喜歡learning by doing。","tags":["python","django","web"],"categories":["Django"]},{"title":"Django2.0筆記(2):專案設定與應用程式","url":"/django-app-and-settings/","content":"專案下的環境設定、如何建立Django App。\n<!--more-->\n\n## Settings.py\n\n在Windows terminal透過tree指令可查看專案結構\n![](https://i.imgur.com/19G7Lvu.jpg)\nMac環境下要使用tree指令則需另外安裝package :\n{% codeblock lang:shell %}\nbrew install tree\n{% endcodeblock %}\n從專案結構可以發現，根目錄下有個和專案名稱相同的資料夾，其中主要有3個檔案:\n- settings.py : 專案設定檔\n- url.py      : 網頁路徑設定\n- wsgi.py     : 伺服器閘道介面設定\n\n＊ manage.py為負責專案管理的Python指令檔\n＊ 什麼是WSGI(Web Server Gateway Interface)? 簡而言之，WSGI就是Server與Web App之間的溝通介面\n\n開啟settings.py，可以看到官方註解寫得挺詳細的，主要設定：\n\n- 除錯模式設定為True表示網頁拋出Error會直接顯示錯誤訊息，正式發佈網站前務必記得關閉，以免網站弱點就這麼公開了(汗)\n{% codeblock lang:shell %}\n# SECURITY WARNING: don't run with debug turned on in production!\nDEBUG = True\n{% endcodeblock %}\n\n- 新建立的App必須在這裡被定義\n{% codeblock lang:python %}\n# Application definition\nINSTALLED_APPS = [\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n    ‘{app_name}’,\n]\n{% endcodeblock %}\n\n- 網頁模版路徑\n\n在專案目錄下建立templates資料夾:\n{% codeblock lang:shell %}\nmd templates  # build folder for web templates\n{% endcodeblock %}\n＊ Mac terminal建立資料夾指令和Linux同為mkdir\n\n接著在settings.py中設定路徑，於TEMPLATES中的'DIRS'加入：\n<span cstyle=\"color:red;\">os.path.join(BASE_DIR, 'templates')</span>\n{% codeblock lang:python %}\nTEMPLATES = [\n    {\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'DIRS': [os.path.join(BASE_DIR, 'templates')],\n        'APP_DIRS': True,\n        'OPTIONS': {\n            'context_processors': [\n                'django.template.context_processors.debug',\n                'django.template.context_processors.request',\n                'django.contrib.auth.context_processors.auth',\n                'django.contrib.messages.context_processors.messages',\n            ],\n        },\n    },\n]\n{% endcodeblock %}\n\n- 語系、時區\b:修改為繁體中文、台灣時區\n{% codeblock lang:python %}\nLANGUAGE_CODE = 'zh-Hant'\n\nTIME_ZONE = 'Asia/Taipei'\n{% endcodeblock %}\n\n- 靜態文件路徑\n\n在專案目錄下建立static資料夾:\n{% codeblock lang:shell %}\nmd static  # build folder for static files(e.g. css, images...)\n{% endcodeblock %}\n接著在settings.py中設定路徑，於\"STATIC_URL\"後面加上:\n{% codeblock lang:python %}\nSTATICFILES_DIRS = [\n    os.path.join(BASE_DIR, 'static'),\n]\n{% endcodeblock %}\n\n---\n## Django App\n建立應用程式，專案底下可建立多個App，而每個App都可以視為Package\n{% codeblock lang:shell %}\n# start virtual environment first\ncd {project_name}\npython manage.py startapp {app_name}  # build application\n\npython manage.py makemigrations {app_name(optional)}  # build data migration for database\npython manage.py migrate {app_name(optional)}  # data synchronization\n{% endcodeblock %}\n\n＊ makemigrations與migrate為資料庫同步設定，預設為對所有應用程式同步，因此應用程式名稱為選填","tags":["python","django","web"],"categories":["Django"]},{"title":"Django2.0筆記(1):初始化設定","url":"/django-start/","content":"近期耗費大量心力在學習Django，因為Google搜尋到的教學文多數版本停留在Django 1.x，對初學者來說略過太多細節。<!--more-->作為WEB初學者，Django有許多概念並不是很直觀，必須實際測試來幫助自己理解。目前所使用的版本為Django 2.1，於是我踩了相當、相當多的坑，感謝無數撰寫教學文的高手前輩讓自己學習了很多。在各種線索的拼湊之下、終於讓Django Project在Apache Server順利運作了(汗)。\n\n\n# Django:Virtual Environment & New Project\n雖然網路上有許多教學文，但最詳細也最可靠的還是官方文件：[Django2.1 Doc](https://docs.djangoproject.com/en/2.1/)。\n\n\n## Virtual Environment for Django\n開發Django Project建議另建一個乾淨的虛擬環境，只安裝專案所需套件，Python環境建置就不贅述，從安裝及建立虛擬環境開始:\n{% codeblock lang:shell %}\npip install virtualenv  # install virtual environment package\ncd c:\\\nvirtualenv {virtualenv_name}  # build virtual environment for Django\n\ncd {virtualenv_name}\nScripts\\activate  # start virtual environment\npip install django  # install Django package\ndeactivate  # stop virtual environment\n{% endcodeblock %}\n＊ 在Mac環境下啟動虛擬環境的指令為source bin/activate\n＊ 提示字元前面的(virtualenv_name)表示目前已啟動虛擬環境\n\n\n## Start New Django Project\n{% codeblock lang:shell %}\n# start virtual environment first\ndjango-admin startproject {project_name}  # build new project\n{% endcodeblock %}\n\n## Run Django Server\n{% codeblock lang:shell %}\n# start virtual environment first\ncd {project_name}\npython manage.py runserver\n{% endcodeblock %}\n\n＊ 在專案目錄下成功啟動測試Server後，在瀏覽器輸入127.0.0.1:8000，應該要看見以下畫面：\n![](https://i.imgur.com/9pdBamW.jpg)","tags":["python","django","web"],"categories":["Django"]},{"title":"兩個月後的魚缸","url":"/restart-planted-tank-2month/","content":"近況更新。\n\n- 前景的牛毛氈因為長得過高更換為很趴又很會爬的新大珍珠草\n- 綠宮廷一直縮頂...只好汰除...我還得多努力\n<!--more-->\n- 後景增加了紅雨傘...但好景不常，其實是我不會照顧呵，變成綠雨傘了ＱＱ\n- 藍綠藻解決後換黑毛藻...石頭全拿掉...開始投藥(TBS)，目前蝦子全掛ＱＱ\n- 珊瑚莫斯沈木因黑毛藻而被檸檬酸處理後看起來了無生機，目前有恢復的跡象\n\n\n↓紅雨傘剛種植＋紅宮廷重新種植後的樣子(汗)\n![](https://i.imgur.com/po1wwVW.jpg)\n\n![](https://i.imgur.com/UL8a4xC.jpg)\n\n我想，之後重新整理，可能會換成一呎的魚缸，然後底土一樣矽沙，但會嘗試鋪設基肥，大概會用洗衣袋裝著吧，免得造成日後矽沙要重複使用的麻煩。\n\n再努力。\n","tags":["aquarium","planted tank"],"categories":["Aquarium"]},{"title":"正則式與re模組","url":"/data-sci-re/","content":"什麼是正則式(Regex)？常見的說法有正規表示式、正則表達式...等等，維基百科是如此描述的：使用單個字串來描述、符合某個句法規則的字串。在很多文字編輯器裡，正則運算式通常被用來檢索、替換那些符合某個模式的文字，總之就是「描述某種規則的表達式」。\n<!--more-->\n舉例來說，email address其格式具有一定規則，假設要在一堆密密麻麻的html中尋找Gmail郵件地址，就必須使用正則式來描述過濾規則，讓程式能準確判斷出符合Gmail郵件地址格式的字串。\n![](https://i.imgur.com/lZufQJS.png)\n\n## Pythex\n上述示範如何用正則式表達Gmail郵件地址規則的網站為[pythex.org](https://pythex.org)，可以用來驗證Regex正確與否，因為Regex的符號有點複雜，該頁面也相當貼心地放了速查表呢～只要按下regular expression cheatsheet按鈕即可查看。\n![](https://i.imgur.com/DIorI8v.png)\n\n## re module\n在Python中使用正則式需要import re模組，常用的方法有search()、match()、findall()等，可參考[官方文件](https://docs.python.org/2/library/re.html)以取得更詳盡的說明。\n\n\b那麼，search跟match有什麼不同呢？這是我一開始對這兩個方法的疑問，那就[看看官方文件怎麼說](https://docs.python.org/2/library/re.html#search-vs-match)，但實際編寫程式碼會幫助自己理解兩者間的差異。\n\n根據官方文件的解釋：re.match() checks for a match only at the <span style=\"color:red;\">beginning</span> of the string, while re.search() checks for a match <span style=\"color:red;\">anywhere</span> in the string.\n\n- match的搜尋方式為「從字串起始開始搜索，遇到不符合的字元便停止」\n- search的搜尋方式為「整個字串」\n\n個人覺得最常用到的應該是findall()，比對所有符合規則的字串並返回串列：\n{% codeblock lang:py %}\nimport re\n\nstr_ =  '_.Aa123Bb456Cc789Dd3.14'\n\nfind_alphabet = re.findall(r'[A-Za-z]+', str_)\nprint(find_alphabet)  ＃ ['Aa', 'Bb', 'Cc', 'Dd']\n\nfind_rational = re.findall(r'[0-9]+\\.?[0-9]*', str_)\nprint(find_rational)  ＃ ['123', '456', '789', '3.14']\n{% endcodeblock %}\n\n## Code\n在Google首頁中尋找.jpg/.png，雖然只有一張圖片(笑)，另外，常用的Regex可以透過re.compile()轉換為Regex Object，以便於直接呼叫search()、match()、findall()，也可以在使用bs4模組解析網頁時使用:\n{% codeblock lang:py %}\n#!usr/bin/env python3\n# coding:utf-8\n\nimport re\nimport requests as rq\nfrom bs4 import BeautifulSoup as bs\n\npattern = re.compile(r'.+\\.jpg|.+\\.png')\nurl = 'https://www.google.com'\ntry:\n    res = rq.get(url)\n    res.raise_for_status()\nexcept rq.HTTPError:\n    print('HTTP Error!')\n\nsoup = bs(res.text, 'html.parser')\nimgs = soup.find_all(\"meta\", {\"content\":pattern})  # find all images in attr 'content' of tag 'meta'\nfor img in imgs:\n    print(img['content'])  # /images/branding/googleg/1x/googleg_standard_color_128dp.png\n{% endcodeblock %}","tags":["python","regex"],"categories":["Data Science"]},{"title":"以 Requests 取得 Google 搜尋結果","url":"/data-sci-google-search/","content":"## Web Analytics\n首先瞧瞧Google Search的網址，嘗試輸入任意關鍵字執行搜尋後可以發現，搜尋的網址是長這樣的：<!--more-->\n{% codeblock %}\nhttp://www.google.com.tw/search?q=\n{% endcodeblock %}\n\"=\"後面便是搜尋的關鍵字了，再觀察網頁原始碼，搜尋結果就在class=\"g\"的div區塊中。\n\n既然爬蟲能這樣到處玩耍，想必也會有不歡迎爬蟲的網站，畢竟要是放任大量爬蟲在自家網站撒野，可是會給伺服器帶來困擾的呢。所以Web Crawler也會有許多技巧來偽裝，讓自己在伺服器的認知裡看起來像是人為操作：例如，在request加上user agent偽裝成瀏覽器，或在多個request之間設置隨機延遲，除了模擬人為操作，亦避免造成他人伺服器的負擔...\n\n## Code\n{% codeblock lang:py %}\n#!/usr/bin/env python3\n# *** coding : utf-8 ***\n\nimport random\nimport requests as rq\nfrom bs4 import BeautifulSoup as bs\n\nuser_agent = [\"Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1\",\n            \"Mozilla/5.0 (Windows NT 10.0; WOW64; rv:38.0) Gecko/20100101 Firefox/38.0\",\n            \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0\",\n            \"Mozilla/5.0 (Macintosh; Intel Mac OS X x.y; rv:42.0) Gecko/20100101 Firefox/42.0\",\n            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:2.0.1) Gecko/20100101 Firefox/4.0.1\"]\n\ntarget = input('search:')\nurl = 'http://www.google.com.tw/search?q=' + target\ntry:\n    res = rq.get(url=url, headers={'User-Agent': random.choice(user_agent)})\n    res.raise_for_status()\nexcept rq.exceptions.HTTPError:\n    print('[HTTP_Error]')\n\nsoup = bs(res.text, 'html.parser')\nlink = soup.select('.g .r a')\n\nfor index in range(2):\n    print(link[index].string)   # title\n    print(link[index]['href'])  # link\n{% endcodeblock %}\n\n輸出結果：\n![](https://i.imgur.com/EcaezM5.png)","tags":["python","web crawler"],"categories":["Data Science"]},{"title":"以 BeautifulSoup 解析網頁內容","url":"/data-sci-bs4/","content":"發出請求取得網頁內容後，會得到密密麻麻的 HTML，此時便可以讓 BeautifulSoup 來協助解析網頁內容。\n<!--more-->\n## Install\n{% codeblock lang:shell %}\n$pip3 install bs4\n{% endcodeblock %}\n\n## Web Analytics\n寫個簡單的 Web Crawler 去 PTT 西斯版逛逛吧，但因為西斯版有年齡驗證，所以必須利用 Requests.Session()物件去做 post，按下大家在\b美好童年就已經按過的「我已滿18歲按鈕」，讓 Web Crawler 取得伺服器驗證後就可以在西斯版橫行無阻(嘿嘿)。\n\n從截圖可以看到，url 為 https://www.ptt.cc/ask/over18... 這就是取得驗證的網址，注意 url 後頭的 from=%2Fbbs%2Fsex...在 post 驗證的 payload 要寫入 from 這個 key，表示 post 來自西斯版。\n![](https://i.imgur.com/PAuJRHa.png)\n\n關於 BeautifulSoup 更多細節可參考[官方文件](https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.html)，這邊簡單說明，基本上就是把 request 取得的 html 丟給 Soup 去解析，接著可以使用 find(), find_all(), select()等方法來篩選尋找目標數據所在的區塊。\n\n舉例來說，若要讓 Web Crawler 去爬取西斯版的文章標題＆連結，觀察網頁原始碼後可以發現目標數據就在 class＝r-ent 的區塊裡面。\n![](https://i.imgur.com/56hpBfq.png)\n\n## Code\n{% codeblock lang:py %}\nimport requests as rq\nfrom bs4 import BeautifulSoup as bs\n\nurl = 'https://www.ptt.cc/bbs/sex/index.html'\npayload = {\n    'from':url,\n    'yes':'yes'\n}\n\nsession = rq.Session()\nsession.post('https://www.ptt.cc/ask/over18', data=payload)\nres = session.get(url)\n\nsoup = bs(res.text, 'html.parser')\nresult = soup.select('.r-ent .title a')\n\nfor title in result:\n    print(title.text, title['href'])\n{% endcodeblock %}\n\n輸出結果：\n![](https://i.imgur.com/NmCiRB0.png)","tags":["python","web crawler"],"categories":["Data Science"]},{"title":"Requests 模組測試","url":"/data-sci-requests/","content":"## Install\n{% codeblock lang:shell %}\n$pip3 install requests\n{% endcodeblock %}\n<!--more-->\n\n## Get\n範例程式為對網頁做基本請求＆接收回應，raise_for_status()為return檢查，若返回異常則拋出error\n{% codeblock lang:py %}\nimport requests as rq\n\nurl = 'http://www.google.com.tw/search?'  # target url\ntry:\n    res = rq.get(url)\n    res.raise_for_status()\nexcept rq.HTTPError:\n    print('HTTP Error!')\n\nprint(res.text)  # html\n{% endcodeblock %}\n\n## Payload\n必要時可以加上參數，例如Google Search:\n{% codeblock lang:py %}\npayload = {'q':'data science'}\nres = rq.get(url, params=payload)  # http://www.google.com.tw/search?q=data+science\n{% endcodeblock %}\n＊參數的部分為字典結構，key則視url結構而定\n\n## Post\n針對網頁中的表單，可以使用Post來傳送Payload\n{% codeblock lang:py %}\nres = rq.post(url, params=payload)\n{% endcodeblock %}\n\n但...對Google Search頁面做Post會得到這樣的回應：\n{% codeblock lang:html %}\n<a href=//www.google.com/><span id=logo aria-label=Google></span></a>\n<p><b>405.</b> <ins>That’s an error.</ins>\n<p>The request method <code>POST</code> is inappropriate for the URL <code>/search?q=data+science</code>.  \n<ins>That’s all we know.</ins>\n{% endcodeblock %}\n\nGoogle說這樣是不當的行為呢，我只是做個示範，好孩子不要學呀＾.<","tags":["python","web crawler"],"categories":["Data Science"]},{"title":"Hexo on GitHub Pages:從Win轉移到Mac","url":"/hexo-switching-from-win-to-mac/","content":"\n一直以來都有想換筆電的想法，但總是能撐則撐，畢竟會是不小的支出呢...不過前陣子需要帶著筆電趴趴造，而跟著我8年的老Win筆電過於笨重，這實在令人感到非常困擾，經考量後換了Mac Air，讓老Win正式退役。\n<!--more-->\n既然換了電腦換了系統，除了熟悉系統操作，再來就是開發環境的建置，趕緊先把Hexo環境先建置起來才能更新部落格。\n\n## Git\n<p>\n[官方載點](https://git-scm.com)，若是已安裝過自帶Git環境的XCode可以略過。\n\n## Node.js\n<p>\n[官方載點](https://nodejs.org/en/)\n\n## Hexo\n{% codeblock lang:shell %}\nsudo npm install -g hexo-cli\nsudo npm install hexo-deployer-git --save\ncd {blog_name}        # build folder of blog\nhexo init {blog_name}\nhexo\nnpm install\nhexo s --debug  # run local server(127.0.0.1:4000)\n{% endcodeblock %}\n![](https://i.imgur.com/iftnF8e.jpg)\n\n## Data\n<p>\n確定在本機可以正常運作後，接下來只要把根目錄下的_config.yml、scaffolds資料夾及source資料夾覆寫到Blog根目錄下就完成~\n\n## Note\n<p>\n1. 在發佈這篇文章後發現Blog分類及標籤頁面消失了...原來是我只把source底下的“_posts”複製到新的根目錄下，只要重新建立“categories”及\"tags\"兩個new page就行啦。\n2. 原本使用的NexT主題為舊版，這次乾脆就更新到v6.4.0啦，配置檔只有微幅的調整，需注意的是languages的部分，檔名中hyphen後的字改為大寫字母了，如果根目錄配置檔沒有修改，Blog預設語言就會因爲找不到對應檔案而變成英文。","tags":["hexo","github pages"],"categories":["Hexo"]},{"title":"Error:檔案無法載入，因為這個系統已停用指令碼執行","url":"/django-execution-of-scripts-is-disabled/","content":"問題來源 : 今日在Win10作業系統下建立Python virtual environment for Django，接著要用Scripts/activate指令啟動虛擬環境時，CLI顯示了這個令人錯愕的訊息:\n\n「檔案無法載入，因為這個系統已停用指令碼執行」\n\n<!--more-->\n代表目前作業系統的Execution Policy設定為Restricted\\(不允許執行\\)這是我在Win7作業系統下使用虛擬環境從沒遇過的狀況，而Google搜尋結果顯示有許多人在PowerShell執行Script遇到相同問題。\n\n## Solution\n以系統管理員權限執行PowerShell，執行以下指令:\n{% codeblock lang:shell %}\nSet-ExecutionPolicy RemoteSigned\n{% endcodeblock %}\n使作業系統接受所有自訂或信任來源的Script，如此問題便解決啦。","tags":["pyhton","django","error"],"categories":["Django"]},{"title":"VS Code快速建立Python開發環境","url":"/python-vscode-setup/","content":"個人從自學Python到現在，一直都是使用工具書所推薦的IDE:PyCharm，它確實是相當優秀的整合開發環境，但過胖這一點偶爾還是會令人感到困擾...每次打開程式就是要等它大爺暖身一下\\(白眼\\)。而開始學習在GitHub Pages寫Blog以來，我都是用VS Code發文，它的輕量化和豐富的擴充套件真是令人感到愉悅呢ヽ(●´∀`●)ﾉ 所以說，乾脆就在VS Code寫Python就好啦。\n<!--more-->\n## Download VS Code\n<p>\n[官方載點](https://code.visualstudio.com/download)\n\n## Install Python Extension for VS Code\n<p>\n↓點側邊工具列的'擴充功能'，然後搜尋'Python'，就會看到MS官方為Python開發的擴充套件，直接安裝即可。\n![](https://i.imgur.com/HD4254a.jpg)\n\n## Build Working Directory\n<p>\n建立一個工作目錄，理由後面會說明。\n\n## Run Python File\n<p>\n要在VS Code環境執行Python程式，可以直接右鍵-->在終端機\\(CLI\\)執行Python檔案，或者按下ctrl + `叫出CLI用'Python {file_path}'去執行也可以...但每次都這樣搞就太麻煩了，所以來建個任務組態檔吧。\n![](https://i.imgur.com/hT5hAXa.jpg)\n\n重點，首先點選上方工作列'檔案'-->'開啟資料夾'，選擇剛剛建立的工作目錄，若是沒有先選擇工作目錄，那麼接下來的步驟就會發生錯誤，VS Code會告訴你一句莫名其妙的話 :'這些工作只會出現在工作區資料夾中'。選擇好工作目錄後，按下ctrl + shift + P接著搜尋'task'，點選'工作:設定工作\\(Tasks:Configure Task\\)'，然後VS Code會在工作目錄下產生一個'tasks.json'，將下方內容直接覆蓋並存檔 :\n{% codeblock lang:json %}\n\"version\": \"2.0.0\",\n    \"tasks\": [\n            {\n                \"label\": \"Run Python Code\",\n                \"type\": \"shell\",\n                \"command\": \"python\",\n                \"args\": [\n                    \"${file}\"\n                ],\n                \"group\": {\n                    \"kind\": \"build\",\n                    \"isDefault\": true\n                },\n                \"presentation\": {\n                    \"echo\": true,\n                    \"reveal\": \"always\",\n                    \"focus\": true,\n                    \"panel\": \"shared\"\n                }\n            }\n        ]\n{% endcodeblock %}\n\n然後就可以透過快捷鍵'ctrl + shift + B'執行程式了，順帶一提，這是LineBot Web Crawler XD\n![](https://i.imgur.com/PZreIqo.jpg)","tags":["python","vs code"],"categories":["Python"]},{"title":"Hexo on GitHub Pages:發文","url":"/hexo-first-post/","content":"關於發文這件事，正所謂工欲善其事，必先利其器，就從選擇一個好用的文字編輯器或IDE開始，個人私心推薦VSCode。\n<!--more-->\n決定好工具後，首先看到blog根目錄底下有個叫'scaffolds'的資料夾，這裡面放的是Blog頁面模板。打開'post.md'會見到預先寫入的title、date等等，此為發文的模板，當然我們也可以編輯它。例如，模板預設是沒有寫入'categories'的，那我會把它加上去，就不必每次發文還得補上。\n![](https://i.imgur.com/TaK8Wzc.jpg)\n\n在Hexo框架下撰文是使用Markdown，不熟悉語法可以參考[官方文件](https://markdown.tw/)，很簡單的~ 接著就可以開始撰文了，相關指令如下:\n\n## Start New Post\n{% codeblock lang:shell %}\ncd blog\nhexo new post post-title  # 'post-title'請置換為自己的文章標題\n{% endcodeblock %}\n\n## Publish New Post\n{% codeblock lang:shell %}\nhexo d -g  # generate --> deploy\n{% endcodeblock %}\n\n## Note\n<p>\n1.categories是唯一、有序的，tags則沒有區分\\(關鍵字的概念\\)，意思是如果你的文章設定了A、B兩個類別，那麼這篇文章的分類就會變成'類別A底下的類別B'。\n2.在new post指令輸入文章標題時，因為標題也是.md的檔名，所以一開始我用underline做區隔(a_b_c)，但我發現Hexo會自動把underline轉成hyphen(a-b-c，順帶一提這條短線叫hyphen...dash是破折號呀)，所以就配合它啦，反正title可以建立文章後再修改為中文，檔名還是英文命名比較不會有什麼光怪陸離的事情發生(怕.jpg)","tags":["hexo","github pages"],"categories":["Hexo"]},{"title":"關於Python的變數範圍","url":"/python-scope-of-variables/","content":"在Python的世界裡，變數是不需要事先宣告就能直接賦値並使用的，而**變數的作用範圍會在賦値的時候建立**，除非你指定了global或nonlocal關鍵字。\n<!--more-->\n先看看[官方文件](https://docs.python.org/3/faq/programming.html#id9)怎麼說:\n{% blockquote %}\nIn Python, variables that are only referenced inside a function are implicitly global. If a variable is **assigned a value** anywhere within the function’s body, it’s assumed to be a local unless explicitly declared as global.\n\nThough a bit surprising at first, a moment’s consideration explains this. On one hand, requiring global for assigned variables provides a bar against unintended side-effects. On the other hand, if global was required for all global references, you’d be using global all the time. You’d have to declare as global every reference to a built-in function or to a component of an imported module. This clutter would defeat the usefulness of the global declaration for identifying side-effects.\n{% endblockquote %}\n\n簡而言之，在函式區塊內部賦値的變數即為區域變數\\(除非指定global或nonlocal\\)，於函式區塊之外賦値的便是全域變數。\n\n直接敲幾段code來看會更清楚 :\n\n{% codeblock lang:python %}\n#!/usr/bin/evn python3\n# *** coding : utf-8 ***\n\na, b = 1, 2  # Global Variable\n\n\ndef func_a():\n    global a  # Global Variable\n    print(a, \"# Global Variable a\")\n    a = 2\n\n\ndef func_b():\n    b = 3  # Local Variable in func_a()\n\n    def func_c():\n        nonlocal b  # Local Variable in func_a()\n        b = 4\n        print(b, \"# Local Variable b\")\n\n    print(b, \"# Local Variable b\")\n    func_c()\n\nfunc_a()\nfunc_b()\nprint(b, \"# Global Variable b\")\n{% endcodeblock %}\n\n**輸出結果:**\n{% codeblock lang:shell %}\n1 # Global Variable a\n3 # Local Variable b\n4 # Local Variable b\n2 # Global Variable b\n{% endcodeblock %}","tags":["python"],"categories":["Python"]},{"title":"在Heroku環境下使用自訂字型","url":"/line-use-custom-fonts-in-heroku-apps/","content":"事情是這樣子的，持續努力讓Bot能查教師課表的某一天，在經歷了數據蒐集、數據處理、介接imgur api...等等，終於讓Bot傳來了一張圖片啦~但仔細一看似乎不太對勁!\n<!--more-->\n## How to Use Custom Fonts in Heroku Apps?\n<p>\n我X，踩雷了，竟然出現中文亂碼的狀況，這課表鬼才看得懂\\(鬼:口口口口口這鬼也看不懂好嘛\\)於是又開始try&error loop...甚至讓Bot去下CLI指令刪除搬移檔案...繞了好一大圈，終於讓我找到答案了!!!令人難過的是，這方法非常簡單...雖然這是常有的事，可就是白耗了好多時間。但沒關係，讓碰見相同問題的人能快速找到解決方案，這就是學習筆記的意義所在。\n\n## Solution\n<p>\n1.準備好你要的字型，要<span style=\"color:red;\">特別注意</span>的是，該字型必須是Linux/Ubuntu所支援的字型。\n2.在專案根目錄下新增一個名稱為「.fonts」的資料夾\\(tips:在命名時輸入.fonts.\\)\n3.把字型檔案\\(.ttf\\)放到上述資料夾中\n4.重新push專案\n\n![](https://i.imgur.com/uxdEvJZ.png)\n\n\n關於中文亂碼，似乎是matplotlib無法在Heroku環境下找到可套用的中文字型，但我在本機測試是沒問題的...所以要自己提供字型就是了，真是踩了個莫名其妙的雷，總之中文亂碼問題就這麼解決了。","tags":["python","heroku","matplotlib"],"categories":["LineBot"]},{"title":"翻缸Day21:藍綠藻來襲","url":"/restart-planted-tank-day21/","content":"開始新工作，下了班想發文卻提不起勁...呵。但還是利用假日來紀錄一下魚缸的近況吧。\n<!--more-->\n↓上週三出門辦事發現水族店在隔壁，就進去逛了\n![](https://i.imgur.com/8QSsMfb.jpg)\n↓於是加入新成員\n![](https://i.imgur.com/himpyCZ.jpg)\n↓綠宮廷轉水中葉，全數拔起整理再植草\n![](https://i.imgur.com/k5Jxf0j.jpg)\n↓角螺開心地啃藻...這缸子該刷了\n![](https://i.imgur.com/lSF2Z0A.jpg)\n↓僱來一批除藻小幫手\n![](https://i.imgur.com/pkNizEv.jpg)\n\n\n然後呢，最近幾天發現藍綠藻持續蔓延，底砂、牛毛氈甚至入水口生化棉也染上了噁心的藍綠色...即使拔起來用檸檬酸浸泡清洗試圖阻止，依然無效。經過爬文吸收資訊，也確定不會對魚蝦造成傷害，決定直接使用紅黴素來處理。雖然不會對魚蝦造成影響，但對於硝化菌們來說可就不妙了，所以投藥前必須將濾材另行安置才行。\n\n↓到處生長的藍綠藻\n![](https://i.imgur.com/cEm4u6i.jpg)\n↓移出圓桶中的濾材並加強打氣維持好氧的硝化菌\n![](https://i.imgur.com/umj5hh7.jpg)\n↓然後紅黴素便可以登場了!(決鬥吧藍綠藻!抽牌!)\n![](https://i.imgur.com/X3OmePn.jpg)\n\n## ※關於投藥劑量\n根據[P大](https://www.paludarium.net/aquarium/48)所說的2.5ppm來計算，我的魚缸水量約23L:23000000 * 0.00025% = 57.5(mg)，一顆紅黴素膠囊為250mg，所以我只需要1/5顆左右的劑量、持續投藥四日。\n\n\n## 2018/7/23 連續投藥Day3\n除了每日換水1/2，光源也調整為上午與傍晚開啟、不連續合計8小時(有一說如此中斷能干擾藻類生長)，目前觀察到藍綠藻已停止蔓延，清洗後的入水口綿也沒有藍綠藻生長。\n\n## 2018/7/25 連續投藥Day5\n↓藍綠藻明顯消失，但我決定今日不換水，讓藥物的效用多殘留一天，確保能控制住...別再來啦，真的是挺麻煩的。\n![](https://i.imgur.com/wtmQzkE.jpg)","tags":["aquarium","planted tank","cyanobacteria"],"categories":["Aquarium"]},{"title":"先別管Hexo如何發文了，你聽過NexT嗎?","url":"/hexo-config/","content":"2020/05/29更新。\n部署完部落格別急著發文，先來找個喜歡的佈景主題。\n<!--more-->\nHexo如此熱門的框架，有許多[第三方主題](https://hexo.io/themes/)能套用，或者想[打造一個自己的主題](https://hexo.io/zh-tw/docs/themes.html)也行，而我選擇的是最熱門的經典主題──NexT。\n\n## 安裝NexT主題\n{% codeblock lang:shell %}\ncd blog    # 移動至Blog根目錄下 \ngit clone https://github.com/theme-next/hexo-theme-next themes/next\n{% endcodeblock %}\n\n### 設定主題\n<p>\n打開Blog根目錄下的root配置檔\\(_config.yml\\)，找到\\#Extensions區塊，將theme屬性設置為next\n{% codeblock lang:yml %}\n# Extensions\n## Plugins: https://hexo.io/plugins/\n## Themes: https://hexo.io/themes/\ntheme: next\n{% endcodeblock %}\n\n### Local Host測試\n{% codeblock lang:shell %}\nhexo clean        # 清除hexo cache\nhexo s --debug    # 以debug模式啟動local host server\n{% endcodeblock %}\n如果CLI沒有輸出錯誤訊息，應該會見到這段文字:\n{% codeblock lang:shell %}\nINFO  Hexo is running at http://localhost:4000/. Press Ctrl+C to stop.\n{% endcodeblock %}\n接著打開瀏覽器輸入localhost:4000便能在本機查看、測試Blog囉。\n\n## 配置檔(_config.yml)\n**詳細Config設定請參考官方文件，僅紀錄個人設定部分**\n\n*官方文件:\n  1.[Hexo docs](https://hexo.io/zh-tw/docs/)\n  2.[NexT docs](https://theme-next.org/docs/)\n\n### Root Config\n<p>\n檔案位址:~/_config.yml\n{% codeblock lang:yml %}\n# Site\ntitle:              # 網站標題\nsubtitle:           # 網站副標題\ndescription:        # 網站描述\nkeywords:           # 網站關鍵字\nauthor:             # 作者名稱\nlanguage:           # 網站語言\ntimezone:           # 時區\n\n# URL\n## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'\nurl: https://username.github.io/  # 網站首頁網址\nroot: /\npermalink: :title/                # 文章永久連結，基於SEO考量不建議使用預設值(:year/:month/:day/:title/)\npermalink_defaults:\n\n# Writing\nnew_post_name: :title.md # File name of new posts\ndefault_layout: post\ntitlecase: false # Transform title into titlecase\nexternal_link: true # Open external links in new tab\nfilename_case: 0\nrender_drafts: false\npost_asset_folder: false\nrelative_link: false\nfuture: true\nhighlight:          # 代碼高亮\n  enable: true\n  line_number: true\n  auto_detect: true\n  tab_replace:\n\n# Home page setting\n# path: Root path for your blogs index page. (default = '')\n# per_page: Posts displayed per page. (0 = disable pagination)\n# order_by: Posts order. (Order by date descending by default)\nindex_generator:\npath: ''\nper_page: 5      # 每頁顯示文章數(預設值為10)\norder_by: -date  # 排序\n\n# Deployment\n## Docs: https://hexo.io/docs/deployment.html\ndeploy:\n  type: git\n  repository: https://{username}:{password}@github.com/{username}/{username}.github.io.git\n  branch: master\n{% endcodeblock %}\n\nRoot Config沒什麼複雜設定，不過在\\#site設定部分，我以為subtitle文字會顯示在author下方(紅框處)...結果顯示的文字是description，所以我說內個subtitle呢???\n![](https://i.imgur.com/3YLGWXs.jpg)\n\n### Theme Config\n<p>\n檔案位址:~/themes/next/_config.yml\n\n{% codeblock lang:yml %}\n# Allow to cache content generation. Introduced in NexT v6.0.0.\ncache:\n  enable: false    #啟用cache可改善網站載入速度\n{% endcodeblock %}\n\n#### favicon\n<p>\n尺寸調整好後，修改為同樣的檔名直接取代掉就行(懶)\n圖片位址:~/themes/next/source/images\n{% codeblock lang:yml %}\nfavicon:\nsmall: /images/favicon-16x16-next.png\nmedium: /images/favicon-32x32-next.png\napple_touch_icon: /images/apple-touch-icon-next.png\nsafari_pinned_tab: /images/logo.svg\n#android_manifest: /images/manifest.json\n#ms_browserconfig: /images/browserconfig.xml\n{% endcodeblock %}\n↓SVG Editor\n![](https://i.imgur.com/u9lSfGq.png)\n\n#### subtitle\nindex_with_subtitle改為true依然不見subtitle顯示於何處。\n{% codeblock lang:yml %}\n# If true, will add site-subtitle to index page, added in main hexo config.\n#subtitle: Subtitle\nindex_with_subtitle: false\n{% endcodeblock %}\n\n#### footer\n網站底部顯示起始年份、icon、版權宣告、框架＆主題版本等設定，Config註解相當詳細。\n##### 自定義footer文字\n{% codeblock lang:yml %}\n# Any custom text can be defined here.\n  custom_text: >\n    <span style=\"color:#3b5998;\"><i class=\"fa fa-hand-o-right fa-lg\"></i></span>&nbsp;All articles in this blog are \n    licensed under <a href=\"https://creativecommons.org/licenses/by/4.0/\">CC BY 4.0</a> \n    unless stating additionally.\n{% endcodeblock %}\n#### creative commons\n覺得有點礙眼所以將side bar跟文末的版權宣告拿掉，直接寫在footer。\n{% codeblock lang:yml %}\n# Creative Commons 4.0 International License.\n# See: https://creativecommons.org/share-your-work/licensing-types-examples\n# Available values of license: by | by-nc | by-nc-nd | by-nc-sa | by-nd | by-sa | zero\n# You can set a language value if you prefer a translated version of CC license.\n# CC licenses are available in 39 languages, where you can find the specific and correct abbreviation you need.\n# Valid values of language: deed.zh, deed.fr, deed.de, etc.\ncreative_commons:\n  license: by\n  sidebar: false\n  post: false\n  language:\n{% endcodeblock %}\n\n#### scheme settings\nNexT主題目前有四種[外觀模式](https://github.com/theme-next/hexo-theme-next)可選擇，將偏好的模式取消註解即可。\n{% codeblock lang:yml %}\n# ---------------------------------------------------------------\n# Scheme Settings\n# ---------------------------------------------------------------\n\n# Schemes\n#scheme: Muse\n#scheme: Mist\n#scheme: Pisces\nscheme: Gemini\n{% endcodeblock %}\n\n#### sidebar settings\n側邊欄依設定的Scheme不同，細部設定會有些微差異。\n{% codeblock lang:yml %}\n# ---------------------------------------------------------------\n# Sidebar Settings\n# See: https://theme-next.org/docs/theme-settings/sidebar\n# ---------------------------------------------------------------\n\n# Posts / Categories / Tags in sidebar.  #sidebar顯示統計(文章/分類/標籤)\nsite_state: true\n\n# Social Links                           ＃社群連結設置\n# Usage: `Key: permalink || icon`\n# Key is the link label showing to end users.\n# Value before `||` delimeter is the target permalink.\n# Value after `||` delimeter is the name of FontAwesome icon. If icon (with or without delimeter) is not specified, globe icon will be loaded.\nsocial:\n  GitHub: https://github.com/{username} || github\n  Linkedin: https://www.linkedin.com/ || linkedin-square  #可自行增加項目\n  Twitter: https://twitter.com/ || twitter\n  E-Mail: mailto:{username}@gmail.com || envelope\n  #Weibo: https://weibo.com/yourname || weibo\n  #Google: https://plus.google.com/yourname || google\n  #Twitter: https://twitter.com/yourname || twitter\n  #FB Page: https://www.facebook.com/yourname || facebook\n  #VK Group: https://vk.com/yourname || vk\n  #StackOverflow: https://stackoverflow.com/yourname || stack-overflow\n  #YouTube: https://youtube.com/yourname || youtube\n  #Instagram: https://instagram.com/yourname || instagram\n  #Skype: skype:yourname?call|chat || skype\n\nsocial_icons:\n  enable: true\n  icons_only: true  #省略文字僅顯示社群icon\n  transition: false\n\n# Blog rolls        #友情連結設置\nlinks_icon: link\nlinks_title: Links\n#links_layout: block\nlinks_layout: inline\nlinks:\n  #Title1: http://example.com\n\n# Sidebar Avatar  #頭像設置(方框或圓框/放大倍率/滑鼠游標碰觸旋轉XD)\navatar:\n  # In theme directory (source/images): /images/avatar.gif\n  # In site directory (source/uploads): /uploads/avatar.gif\n  # You can also use other linking images.\n  url: /images/avatar.png\n  # If true, the avatar would be dispalyed in circle.\n  rounded: true\n  # The value of opacity should be choose from 0 to 1 to set the opacity of the avatar.\n  opacity: 1\n  # If true, the avatar would be rotated with the cursor.\n  rotated: true\n\n# Table Of Contents in the Sidebar  ＃文章目錄顯示設置\ntoc:\n  enable: true\n  # Automatically add list number to toc.\n  number: true\n  # If true, all words will placed on next lines if header width longer then sidebar width.\n  wrap: false    #false＝truncate\n  # If true, all level of TOC in a post will be displayed, rather than the activated part of it.\n  expand_all: false\n  # Maximum heading depth of generated toc. You can set it in one post through `toc_max_depth` in Front Matter.\n  max_depth: 6\n\nsidebar:\n  # Sidebar Position, available values: left | right (only for Pisces | Gemini).\n  position: left\n  #position: right\n\n  # Manual define the sidebar width. If commented, will be default for:\n  # Muse | Mist: 320\n  # Pisces | Gemini: 240\n  #width: 300\n\n  # Sidebar Display, available values (only for Muse | Mist):    #sidebar顯示時機設置\n  #  - post    expand on posts automatically. Default.\n  #  - always  expand for all pages automatically.\n  #  - hide    expand only when click on the sidebar toggle icon.\n  #  - remove  totally remove sidebar including sidebar toggle.\n  display: post\n\n  # Sidebar offset from top menubar in pixels (only for Pisces | Gemini).\n  offset: 12\n  # Enable sidebar on narrow view (only for Muse | Mist).\n  onmobile: true\n  # Click any blank part of the page to close sidebar (only for Muse | Mist).\n  dimmer: false\n\nback2top:    #返回頂部按鈕設置\n  enable: true\n  # Back to top in sidebar.\n  sidebar: false\n  # Scroll percent label in b2t button.\n  scrollpercent: true\n{% endcodeblock %}\n\n#### code highlight\n<span style=\"color:red;\">代碼高亮問題</span>讓我困擾了好一段時間，也就是部落格更改為ICARUS主題的時候(只設置了一週又換回NexT)，因此才開始追究代碼高亮無作用的原因。實測後我的結論是，在Hexo框架下使用內建的[Tag Plugins](https://hexo.io/zh-tw/docs/tag-plugins.html)來標記程式碼區塊，最能確保代碼高亮的顯示，縮進跟反引號(backtick)的用法都不是很可靠。另外，自動偵測語言也並非完全準確，建議程式區塊要註記[language](https://highlightjs.readthedocs.io/en/latest/css-classes-reference.html)。\n{% codeblock lang:yml%}\n# Tag Plugins - code block語法\n# {% codeblock [title] [lang:language] [url] [link text] %}\n# your code here\n# {% endcodeblock %}\n\n# Code Highlight theme  #代碼高亮主題設置\n# Available values: normal | night | night eighties | night blue | night bright\n# https://github.com/chriskempson/tomorrow-theme\nhighlight_theme: night eighties\n{% endcodeblock %}\n\n#### mathjax\n{% codeblock lang:yml %}\n# Math Equations Render Support\nmath:\n  enable: True\n\n  # Default (true) will load mathjax / katex script on demand.\n  # That is it only render those page which has `mathjax: true` in Front Matter.\n  # If you set it to false, it will load mathjax / katex srcipt EVERY PAGE.\n  per_page: true\n\n  engine: mathjax\n  #engine: katex\n{% endcodeblock %}\n\nper_page預設值為true，也就是針對個別頁面啟用，不需要對所有頁面進行Latex語法渲染，加速頁面載入。\n所以欲啟用Latex語法渲染的文章須在[Front-matter](https://hexo.io/zh-tw/docs/front-matter)加入：\n{% codeblock lang:md %}\nmathjax: true\n{% endcodeblock %}\n\n#### third party services\n關於NexT所支援之第三方服務可參考[官方文件說明](https://theme-next.org/docs/third-party-services/)\n\n#### note\nNexT config隨著版本演進，設定項目變得更多、更細，就不逐項列出了，只寫重點。","tags":["hexo","github pages"],"categories":["Hexo"]},{"title":"翻缸Day8:除藻生物","url":"/restart-planted-tank-day8/","content":"目前光照時間已拉長至8小時，光源為Johnlen LED 1.5呎19W水草自然混光燈、色溫4000k&7000k的燈珠各3顆，CO2則是24小時不間斷，唯夜間會降低出氣量。重新翻缸後，底床僅有舊矽砂無鋪設基肥，依植草位置適量埋入ISTA水草根肥，因此在每週換水1/2後會酌量添加TBS綠色&紅色水草液肥。雖然目前並無藻類大量滋生的跡象，但除藻生物可是水草缸不可或缺的小幫手呢。\n<!--more-->\n\n因為前景的牛毛氈仍是以相當緩慢的生長速度在蔓延中，大概還要兩三週我才敢放入黑殼蝦...以免維護中的草皮被連根拔起!而說到除藻生物，我偏好可愛的小精靈~但水族店老闆表示折損率太高沒有再引進T.T 看來小精靈真的不好飼養，個人經驗...撐不過半年就上天堂了，我也是搞不懂問題出在哪。唉，只好退而求其次以小猴飛狐代替，以及好飼養又很勤奮工作的角螺~\n\n\n↓換了新環境的小猴飛狐目前看來有點膽小\n![restart_day8_01](https://i.imgur.com/rmBmzwM.jpg)\n\n↓小而圓的綠宮廷水上葉逐漸轉化為細長的水中葉了\n![restart_day8_02](https://i.imgur.com/9C9KqUd.jpg)\n\n\n今早一看，小猴飛狐已經跟黑燈們開始混熟了...再觀察觀察吧，因為北辰大有提過[小猴飛狐的危險性](http://northernstar-aquarium.blogspot.com/2011/09/blog-post.html)，希望這傢伙安份點。","tags":["aquarium","planted tank","algae control"],"categories":["Aquarium"]},{"title":"只要6塊錢~第一次自拍證件照就上手","url":"/take-a-headshot-yourself/","content":"說到 **大頭照** 這個東西，其實使用到的機會不多，但要用的時候總是被要求繳交 **6個月內**的證件照...照相館動輒兩三百塊，拍出來的大頭照多麼不堪我就不說了，大家應該都很有經驗\\(菸\\)。雖說市面上已有證件快照的機器，但也不是說很普及，收費大約是$150，於是我想起有看過在家自拍大頭照的教學，就決定來試試了，也讓我的700D在平淡無奇的日常生活中能有登場的機會。\n<!--more-->\n\n首先呢，找面明亮、乾淨的牆當背景，然後想辦法架好相機，手邊有腳架的話當然是最方便啦...如果相機螢幕能翻轉那就更好囉 : )\n![](https://i.imgur.com/IYuC7Q9.jpg)\n\n接下來就是設定倒數連拍，我覺得10秒比較夠用XD 證件照的規定可以參考[外交部領事局](https://www.boca.gov.tw/cp-16-4123-c2932-1.html)的說明，我就不贅述，總之，拍出理想的照片後就是去背、裁剪。若是不會使用專業的修圖軟體，可以參考[這篇](http://gigikaren1104.pixnet.net/blog/post/383578103)用PPT處理大頭照的教學，還能調膚色呢XD\n\n說到裁剪照片呢，這個**2吋**到底是多大呢?拜了Google大神後得到很多答案...眾說紛紜!我個人認為看起來最順眼、最2吋的是像素寬高比為433x581 pixel、實際寬高比為3.5x5.08的大小，提供參考。\n\n裁剪完成後，在修圖軟體上開一張4x6的畫布...小畫家也是可以，那麼4x6是多大呢?\\(尺寸什麼的好煩\\)像素寬高比為1795x1205 pixel，然後把大頭照貼滿整個畫布吧!\\(說貼滿其實也不過8張啦XD\\)\n![](https://i.imgur.com/7WE4wAb.jpg)\n\n上述準備就緒，[尋找](http://www.likoda.com.tw/info/store/)你附近的 **立可得** 吧~ 許多便利商店及大賣場都有設置喔，可以透過APP將照片傳輸至機器來列印照片，非常方便。\n![](https://i.imgur.com/3Dg9R1U.jpg)\n![](https://i.imgur.com/gZpfIw5.jpg)\n\n我是在便利商店的立可得列印的，傳輸照片、設定列印選項後，機器會列印繳費單，4x6一張6元，拿著它去櫃檯繳費後就可以回到機器前面取照片囉。\n![](https://i.imgur.com/a246LAA.jpg)\n![](https://i.imgur.com/kHUHVTO.jpg)\n\n\n第一次自拍證件照就上手，成功~","tags":["DIY","headshot"],"categories":["Daily"]},{"title":"部署失敗:Failed to Execute Prompt Script","url":"/hexo-failed-to-execute-prompt-script/","content":"在搭建好部落格、龜毛地設定了root配置檔，然後抱持著既期待又怕受傷害的心情，在CLI敲下部署指令後，得到了error: failed to execute prompt script (exit code 1)這這般無情的回應...嗯，部署失敗！ 我X，都還沒發文呢。\n<!--more-->\n\n## Solution\n<p>\n找到Blog根目錄下的root配置檔_config.yml，修正部署設定。\n\n原始設定:\n{% codeblock lang:yml %}\ndeploy:\n  type: git\n  repository: https://github.com/username/username.github.io.git\n  branch: master\n{% endcodeblock %}\n\n修改為:\n{% codeblock lang:yml %}\ndeploy:\n  type: git\n  repository: https://username:userpassword@github.com/username/username.github.io.git\n  branch: master\n{% endcodeblock %}\n\n部署成功 : )\n\n*[參考資料](https://www.zhihu.com/question/38219432)","tags":["error","hexo","github pages"],"categories":["Hexo"]},{"title":"Hexo on GitHub Pages:從零開始","url":"/hexo-on-github-pages/","content":"程式寫了幾年，遇到Bug總是靠著拜Google大神，就這麼一路走來，看過無數高手們手把手的教學文，心裡想著自己哪天也來寫寫學習筆記，紀錄學習歷程以及遇到的問題(以及至今仍在摸索中的水草缸...)，也許在某個夜深人靜的時刻，能幫助到和我一樣經常廢寢忘食、苦苦追尋解決方案的某個誰。於是部落格就這麼建起來了，學習筆記就從部落格的搭建過程開始紀錄吧。\n<!--more-->\n\n## 前置作業\n<br>\n### 安裝Node.js\n<p>\n[官網載點](https://nodejs.org/en/)\n\n接著執行作業系統CLI\\(command-line interface\\)輸入以下安裝指令\n\n### 安裝Hexo\n{% codeblock lang:shell %}\nnpm install hexo-cli -g\nhexo version            # 若安裝成功可查看Hexo版本\n{% endcodeblock %}\n\n### 安裝Hexo Git\n{% codeblock lang:shell %}\nnpm install hexo-deployer-git --save\n{% endcodeblock %}\n\n### 註冊GitHub帳號\n<p>\n[GitHub官網](https://github.com)\n<span style=\"color:red;\">特別注意 : </span>為避免某些文件配置錯誤的發生，使用者名稱(username)務必設定為小寫，使用者名稱也將成為部落格網址的主要部分\n\n### 新增GitHub專案\n* 按下New repository\n![](https://i.imgur.com/hoQ0WZP.jpg)\n* 輸入專案名稱username.github.io，username請填寫自己的使用者名稱，接著按下create repository，前置作業到此告一段落\n![](https://i.imgur.com/wHAh9q5.jpg)\n\n---\n### 開始建置\n<br>\n#### 初始化\n回到CLI輸入以下指令開始建立部落格\n\n{% codeblock lang:shell %}\nhexo init blog    # 初始化\ncd blog           # 移動至上一步所建立的blog資料夾\nnpm install       # 安裝blog相關套件\n{% endcodeblock %}\n\n#### 部署\n至blog資料夾底下找到Hexo root配置檔，文件名稱為_config.yml，打開文件找到部署設定區塊填入相關資訊\n<span style=\"color:red;\">特別注意 </span>: 每個項目的冒號後面一定要空格，username一樣改寫為自己的使用者名稱\n\n{% codeblock lang:yml %}\ndeploy:\n    type: git\n    repository: https://github.com/username/username.github.io.git\n    branch: master\n{% endcodeblock %}\n\n接著就可以部署到GitHub : )\n\n{% codeblock lang:shell %}\nhexo d -g    # generate --> deploy\n{% endcodeblock %}\n\n部署成功後在瀏覽器輸入網址 https://{username}.github.io/ 就可以看到自己的部落格囉~\n\n---\n### 更新版本\n{% codeblock lang:shell%}\ncd hexo root  # CLI移至hexo根目錄\nnpm outdated  # 檢查版本\n{% endcodeblock %}\n\n將package.json相關的package版本號修改為最新然後安裝即可\n{% codeblock lang:shell%}\nnpm install --save\n{% endcodeblock %}\n\n![](https://i.imgur.com/B6Z6Hee.png)\n\n＊CLI如有顯示類似的錯誤訊息\n{% codeblock lang:shell%}\nnpm WARN babel-eslint@10.0.1 requires a peer of eslint@>= 4.12.1 but none is installed. You must install peer dependencies yourself.\n{% endcodeblock %}\n\npeer dependencies是已發佈套件的相依關係，表示使用者需自行安裝額外的相依套件\n{% codeblock lang:shell%}\nnpm install eslint@4.12.1 --save-dev\n{% endcodeblock %}\n\n- [Hexo官網](https://hexo.io/zh-tw/)","tags":["hexo","gitHub pages"],"categories":["Hexo"]},{"title":"1.5呎翻缸重整","url":"/restart-my-1.5ft-planted-tank/","content":"## 放置play很久很久的魚缸\n本來是想撤掉了，因為需要定期維護清洗設備...但又覺得可惜。<!--more-->後來又想改設置好整理的一呎缸，不過又考慮到水體小、水質相對難維持穩定的問題。經過一番掙扎，還是決定翻缸重新設景\\(天啊，水草缸都成了 **水藻缸**，這工程之浩大用想的就覺得累了...\\)。\n因為，我還是想要一個很療癒的水草缸啊。\n\n↓魚缸刷洗完成\n![刷洗後的魚缸](https://i.imgur.com/riEPpd9.jpg)\n↓重新設景、植草\n![植草設景完成](https://i.imgur.com/le3gi6j.jpg)\n\n\n## 設備更換\n  1.不鏽鋼出入水口\\(玻璃美觀但...易髒難洗\\)\n  2.外置CO2霧化器\\(放在缸內各種藻類實在困擾\\)\n  3.致冷晶片冷水機\\(嗯，為了讓水草度過夏天，但經費有限...\\)\n\n↓外置CO2霧化器\n![外置CO2霧化器](https://i.imgur.com/Dd3j2RI.jpg)\n↓本次升級的重磅武器(?)─致冷晶片冷水機\n![致冷晶片冷水機](https://i.imgur.com/F4EQYpT.jpg)\n\n\n↓重新設缸Day3，僅保留一株的溫蒂椒草已經開始冒出新葉了...生長速度如此之快，我用了個養樂多瓶底當草盆再植入底床，希望能限制它的植株大小，當個稱職的中景草。\n![溫蒂椒草](https://i.imgur.com/lmTVpf9.jpg)\n\n\n期盼能順利成景，尤其是前景的草皮。\n※GitHub Pages首PO!! \\(灑花\\)","tags":["aquarium","planted tank"],"categories":["Aquarium"]}]